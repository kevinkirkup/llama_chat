{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111f59f2",
   "metadata": {},
   "source": [
    "# Postgres RAG\n",
    "\n",
    "## Define the  Service Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf3efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from llama_index import SimpleDirectoryReader\n",
    "\n",
    "input_path = os.path.expanduser(\"~/iCloud/nvAlt/\")\n",
    "# documents_path = os.path.expanduser(\"~/Desktop/tmp/nvAlt/\")\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=input_path,\n",
    "    exclude_hidden=True,\n",
    "    exclude=[\"Notes & Settings\"]\n",
    ").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b40abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/kevinkirkup/ai/models/llama2/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  241 tensors\n",
      "llama_model_loader: - type q6_K:   41 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 8801.75 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 363.88 MB\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  8802.34 MB, ( 8802.97 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3202.00 MB, (12004.97 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   358.02 MB, (12362.98 / 49152.00)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_index import (\n",
    "  LangchainEmbedding,\n",
    "  ServiceContext,\n",
    "  VectorStoreIndex,\n",
    "  set_global_service_context,\n",
    ")\n",
    "from llama_index.llms import LlamaCPP\n",
    "from llama_index.llms.llama_utils import (\n",
    "    messages_to_prompt,\n",
    "    completion_to_prompt,\n",
    ")\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "model_path = os.path.expanduser(\"~/ai/models/llama2/llama-2-13b-chat.Q5_K_M.gguf\")\n",
    "llm = LlamaCPP(\n",
    "    model_path=model_path,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens\n",
    "    context_window=4096,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 1},\n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "embed_model = LangchainEmbedding(\n",
    "  HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e1352",
   "metadata": {},
   "source": [
    "## Create the Vector Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d8f899",
   "metadata": {},
   "source": [
    "### Make sure we set the PGVector Vector Size since we are using HuggingFaceEmbedding\n",
    "\n",
    "https://github.com/langchain-ai/langchain/pull/3964"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f48d608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PGVECTOR_VECTOR_SIZE\"] = \"768\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "788bdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "from llama_index.vector_stores import PGVectorStore\n",
    "from llama_index import StorageContext\n",
    "\n",
    "CONNECTION_STRING = \"postgresql://mercury:m3ssenger@localhost:5432/postgres\"\n",
    "DATABASE_NAME = \"nvalt_vector_db\"\n",
    "\n",
    "conn = psycopg2.connect(CONNECTION_STRING)\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {DATABASE_NAME}\")\n",
    "    c.execute(f\"CREATE DATABASE {DATABASE_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a019b48",
   "metadata": {},
   "source": [
    "## Create the Vector Storage context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85fca6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "\n",
    "url = make_url(CONNECTION_STRING)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=DATABASE_NAME,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port,\n",
    "    user=url.username,\n",
    "    table_name=\"vector_data\",\n",
    "    embed_dim=768,  # openai embedding dimension\n",
    ")\n",
    "\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df804a9",
   "metadata": {},
   "source": [
    "# Create Tools for extracting Text\n",
    "\n",
    "## Create the Metadata Extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02298783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Could not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\n",
      "Original error:\n",
      "No API key found for OpenAI.\n",
      "Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\n",
      "API keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\n",
      "******\n",
      "******\n",
      "Could not load OpenAI model. Using default LlamaCPP=llama2-13b-chat. If you intended to use OpenAI, please check your OPENAI_API_KEY.\n",
      "Original error:\n",
      "No API key found for OpenAI.\n",
      "Please set either the OPENAI_API_KEY environment variable or openai.api_key prior to initialization.\n",
      "API keys can be found or created at https://platform.openai.com/account/api-keys\n",
      "\n",
      "******\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/kevinkirkup/ai/models/llama2/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q5_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q5_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q6_K     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q5_K     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q5_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q6_K     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q5_K:  241 tensors\n",
      "llama_model_loader: - type q6_K:   41 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q5_K - Medium\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 8801.75 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 3200.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Max\n",
      "ggml_metal_init: picking default device: Apple M2 Max\n",
      "ggml_metal_init: loading '/opt/homebrew/anaconda3/envs/langchain/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x16ad3c980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                        0x16ad387c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                            0x16ad3e100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x16ad58920 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                          0x16ad58b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                           0x16ad58dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                           0x16ad59010 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                           0x16ad59260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x16ad594b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_4                     0x16ad59700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x16ad59950 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                0x16ad59ba0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                   0x16ad59df0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x16ad5a040 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x16ad5a290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x16ad5a4e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                  0x16ad5a730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x16ad5a980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x16ad5abd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x16ad5ae20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x16ad5b070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x16ad5b2c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x16ad5b510 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                           0x16ad5b760 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f32_f32                0x16ad5b9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x16ad5bc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_1row           0x16ad5be50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_l4             0x16ad5c0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x16ad5c2f0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x16ad5c540 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q8_0_f32               0x16ad5c790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x16ad5c9e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x16ad5cc30 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x16ad5ce80 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x16ad5d0d0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x16ad5d320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                 0x16ad5d570 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                 0x16ad5d7c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                0x16ad5da10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                0x16ad5dc60 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                0x16ad5deb0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                0x16ad5e100 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                0x16ad5e350 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                0x16ad5e5a0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                0x16ad5e7f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                0x16ad5ea40 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f32                       0x16ad5ec90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f16                       0x16ad5eee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x16ad5f130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x16ad5f380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x16ad5f5d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x16ad5f820 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 49152.00 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 363.88 MB\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  8802.34 MB, (21165.33 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3202.00 MB, (24367.33 / 49152.00)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   358.02 MB, (24725.34 / 49152.00)\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/kevinkirkup/Library/Caches/llama_index/models/llama-2-13b-chat.Q4_0.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 7024.01 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3900\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 3046.88 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Max\n",
      "ggml_metal_init: picking default device: Apple M2 Max\n",
      "ggml_metal_init: loading '/opt/homebrew/anaconda3/envs/langchain/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x5b57d9c60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                        0x5b57db720 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                            0x5b57dad20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x5b57da590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                          0x5b57dbcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                           0x5b57dbf20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                           0x5b57dc170 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                           0x5b57dc3c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x5b57dc610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_4                     0x5b57dc860 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x5b57dcab0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                0x5b57dcd00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                   0x5b57dcf50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x5b57dd1a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x5b57dd3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x5b57dd640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                  0x5b57dd890 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x5b57ddae0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x5b57ddd30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x5b57ddf80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x5b57de1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x5b57de420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x5b57de670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                           0x5b57de8c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f32_f32                0x5b57deb10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x5b57ded60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_1row           0x5b57defb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_l4             0x5b57df300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x5b57df550 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x5b57df7a0 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q8_0_f32               0x5b57df9f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x5b57dfc40 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x5b57dfe90 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x5b57e00e0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x5b57e0330 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x5b57e0580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                 0x5b57e07d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                 0x5b57e0a20 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                0x5b57e0c70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                0x5b57e0ec0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                0x5b57e1110 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                0x5b57e1360 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                0x5b57e15b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                0x5b57e1800 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                0x5b57e1a50 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                0x5b57e1ca0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f32                       0x5b57e1ef0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f16                       0x5b57e2140 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x5b57e2390 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x5b57e25e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x5b57e2830 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x5b57e2a80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 49152.00 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 348.18 MB\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  7024.61 MB, (31749.95 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3048.88 MB, (34798.83 / 49152.00)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   342.31 MB, (35141.14 / 49152.00)\n",
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/kevinkirkup/Library/Caches/llama_index/models/llama-2-13b-chat.Q4_0.gguf (version GGUF V2 (latest))\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q4_0     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:          blk.10.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:           blk.10.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:           blk.10.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:             blk.10.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:           blk.10.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:             blk.10.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:        blk.10.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:             blk.10.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:             blk.10.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:          blk.11.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:           blk.11.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:           blk.11.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:             blk.11.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:           blk.11.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:             blk.11.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:        blk.11.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:             blk.11.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:             blk.11.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:          blk.12.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:           blk.12.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:           blk.12.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:             blk.12.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:           blk.12.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:             blk.12.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:        blk.12.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:             blk.12.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:             blk.12.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:          blk.13.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:           blk.13.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:           blk.13.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:             blk.13.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:           blk.13.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:             blk.13.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:        blk.13.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:             blk.13.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:             blk.13.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:          blk.14.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:           blk.14.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:           blk.14.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:             blk.14.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:           blk.14.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:             blk.14.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:        blk.14.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:             blk.14.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:             blk.14.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:             blk.15.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:             blk.15.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:           blk.2.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:            blk.2.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.2.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.2.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:            blk.2.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.2.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:         blk.2.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.2.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:              blk.2.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:           blk.3.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:            blk.3.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:            blk.3.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:              blk.3.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:            blk.3.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:              blk.3.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:         blk.3.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:              blk.3.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:              blk.3.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:           blk.4.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:            blk.4.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:            blk.4.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:              blk.4.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:            blk.4.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:              blk.4.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:         blk.4.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:              blk.4.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:              blk.4.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:           blk.5.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:            blk.5.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:            blk.5.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:              blk.5.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:            blk.5.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:              blk.5.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:         blk.5.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:              blk.5.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:              blk.5.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:           blk.6.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.6.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:            blk.6.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:              blk.6.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:            blk.6.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:              blk.6.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:         blk.6.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.6.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:              blk.6.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:           blk.7.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:            blk.7.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:            blk.7.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.7.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:            blk.7.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:              blk.7.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:         blk.7.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:              blk.7.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:              blk.7.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.8.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:            blk.8.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:            blk.8.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:              blk.8.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:            blk.8.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:              blk.8.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:         blk.8.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:              blk.8.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:              blk.8.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.9.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:            blk.9.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:            blk.9.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:              blk.9.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:            blk.9.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:              blk.9.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:         blk.9.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:              blk.9.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:              blk.9.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:          blk.15.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:           blk.15.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:           blk.15.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:        blk.15.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:          blk.17.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:           blk.17.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:           blk.17.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:           blk.17.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:             blk.17.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:        blk.17.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:             blk.17.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:          blk.21.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:           blk.21.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:           blk.21.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:             blk.21.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:           blk.21.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:        blk.21.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:             blk.21.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:             blk.21.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:          blk.26.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:           blk.26.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:           blk.26.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:           blk.26.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:             blk.26.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:        blk.26.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:             blk.26.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q6_K     [  5120, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:          blk.32.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  291:           blk.32.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  292:           blk.32.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  293:             blk.32.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  294:           blk.32.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  295:             blk.32.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  296:        blk.32.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  297:             blk.32.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  298:             blk.32.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  299:          blk.33.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  300:           blk.33.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  301:           blk.33.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  302:             blk.33.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  303:           blk.33.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  304:             blk.33.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  305:        blk.33.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  306:             blk.33.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  307:             blk.33.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  308:          blk.34.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  309:           blk.34.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  310:           blk.34.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  311:             blk.34.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  312:           blk.34.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  313:             blk.34.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  314:        blk.34.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  315:             blk.34.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  316:             blk.34.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  317:          blk.35.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  318:           blk.35.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  319:           blk.35.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  320:             blk.35.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  321:           blk.35.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  322:             blk.35.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  323:        blk.35.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  324:             blk.35.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  325:             blk.35.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  326:          blk.36.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  327:           blk.36.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  328:           blk.36.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  329:             blk.36.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  330:           blk.36.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  331:             blk.36.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  332:        blk.36.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  333:             blk.36.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  334:             blk.36.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  335:          blk.37.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  336:           blk.37.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  337:           blk.37.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  338:             blk.37.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  339:           blk.37.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  340:             blk.37.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  341:        blk.37.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  342:             blk.37.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  343:             blk.37.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  344:          blk.38.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  345:           blk.38.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  346:           blk.38.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  347:             blk.38.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  348:           blk.38.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  349:             blk.38.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  350:        blk.38.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  351:             blk.38.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  352:             blk.38.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  353:          blk.39.attn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  354:           blk.39.ffn_down.weight q4_0     [ 13824,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  355:           blk.39.ffn_gate.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  356:             blk.39.ffn_up.weight q4_0     [  5120, 13824,     1,     1 ]\n",
      "llama_model_loader: - tensor  357:           blk.39.ffn_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  358:             blk.39.attn_k.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  359:        blk.39.attn_output.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  360:             blk.39.attn_q.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  361:             blk.39.attn_v.weight q4_0     [  5120,  5120,     1,     1 ]\n",
      "llama_model_loader: - tensor  362:               output_norm.weight f32      [  5120,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                          general.file_type u32     \n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  18:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_print_meta: format           = GGUF V2 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = mostly Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name   = LLaMA v2\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.12 MB\n",
      "llm_load_tensors: mem required  = 7024.01 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3900\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  = 3046.88 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Max\n",
      "ggml_metal_init: picking default device: Apple M2 Max\n",
      "ggml_metal_init: loading '/opt/homebrew/anaconda3/envs/langchain/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x5f1414750 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                        0x5f1421030 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                            0x5f140be30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x5f1421690 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                          0x5f14219f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                           0x5f1421c40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                           0x5f1421e90 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                           0x5f14220e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x5f1422330 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_4                     0x5f1422580 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x5f14227d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                0x5f1422a20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                   0x5f1422c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x5f1422ec0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x5f1423110 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x5f1423360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                  0x5f14235b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x5f1423800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x5f1423a50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x5f1423ca0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x5c20ea700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x5c2710ce0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x5c2712730 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                           0x5c2712980 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f32_f32                0x5c2712bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x5c2712e20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_1row           0x5c2713070 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32_l4             0x5c27132c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x5c2713510 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x5c2713760 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q8_0_f32               0x5c27139b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x5c2713c00 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x5c2713e50 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x5c27140a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x5c27142f0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x5c2714540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                 0x5c2714790 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                 0x5c27149e0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                0x5c2714c30 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                0x5c2714e80 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                0x5c27150d0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                0x5c2715320 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                0x5c2715570 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                0x5c27157c0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                0x5c2715a10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                0x5c2715c60 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f32                       0x5c2715eb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_f16                       0x5c2716100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x5c2716350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x5c2716630 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x5c2716880 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x5c2716ad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 49152.00 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "llama_new_context_with_model: compute buffer total size = 348.18 MB\n",
      "llama_new_context_with_model: max tensor size =   128.17 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  7024.61 MB, (42165.75 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  3048.88 MB, (45214.62 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   342.31 MB, (45556.94 / 49152.00)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.node_parser.extractors import (\n",
    "    KeywordExtractor,\n",
    "    MetadataExtractor,\n",
    "    TitleExtractor,\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor\n",
    ")\n",
    "from llama_index.text_splitter import TokenTextSplitter\n",
    "\n",
    "model_path = os.path.expanduser(\"~/ai/models/llama2/llama-2-13b-chat.Q5_K_M.gguf\")\n",
    "summary_llm = LlamaCPP(\n",
    "    model_path=model_path,\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens\n",
    "    context_window=4096,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 1},\n",
    "    # transform inputs into Llama2 format\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "metadata_extractor = MetadataExtractor(\n",
    "    extractors=[\n",
    "        TitleExtractor(nodes=5),\n",
    "        # QuestionsAnsweredExtractor(questions=3),\n",
    "        SummaryExtractor(llm=summary_llm),\n",
    "        KeywordExtractor(keywords=5),\n",
    "    ],\n",
    ")\n",
    "text_splitter = TokenTextSplitter(separator=\" \", chunk_size=512, chunk_overlap=128)\n",
    "\n",
    "node_parser = SimpleNodeParser.from_defaults(\n",
    "    metadata_extractor=metadata_extractor,\n",
    "    text_splitter=text_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39f19d7",
   "metadata": {},
   "source": [
    "## Parse the doucuments we want to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6586da45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6c9ec420d2444eac2e849c1178b475",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing documents into nodes:   0%|          | 0/192 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    20.78 ms /    32 runs   (    0.65 ms per token,  1539.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2296.48 ms /   658 tokens (    3.49 ms per token,   286.53 tokens per second)\n",
      "llama_print_timings:        eval time =   916.53 ms /    31 runs   (   29.57 ms per token,    33.82 tokens per second)\n",
      "llama_print_timings:       total time =  3269.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    42.49 ms /    66 runs   (    0.64 ms per token,  1553.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1770.87 ms /   542 tokens (    3.27 ms per token,   306.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1907.06 ms /    65 runs   (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_print_timings:       total time =  3784.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    58.79 ms /    91 runs   (    0.65 ms per token,  1547.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1845.30 ms /   551 tokens (    3.35 ms per token,   298.60 tokens per second)\n",
      "llama_print_timings:        eval time =  2653.25 ms /    90 runs   (   29.48 ms per token,    33.92 tokens per second)\n",
      "llama_print_timings:       total time =  4645.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    90.03 ms /   139 runs   (    0.65 ms per token,  1543.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1849.15 ms /   562 tokens (    3.29 ms per token,   303.92 tokens per second)\n",
      "llama_print_timings:        eval time =  4093.96 ms /   138 runs   (   29.67 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:       total time =  6170.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    46.32 ms /    67 runs   (    0.69 ms per token,  1446.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1758.46 ms /   520 tokens (    3.38 ms per token,   295.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1965.41 ms /    66 runs   (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_print_timings:       total time =  3839.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1763.77 ms\n",
      "llama_print_timings:      sample time =    94.22 ms /   137 runs   (    0.69 ms per token,  1454.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1275.54 ms /   414 tokens (    3.08 ms per token,   324.57 tokens per second)\n",
      "llama_print_timings:        eval time =  3995.91 ms /   136 runs   (   29.38 ms per token,    34.03 tokens per second)\n",
      "llama_print_timings:       total time =  5510.26 ms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073d2af6c43f40e496c6e8cdb05fc1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting summaries:   0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.51 ms /   125 runs   (    0.70 ms per token,  1428.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3309.41 ms /   800 tokens (    4.14 ms per token,   241.74 tokens per second)\n",
      "llama_print_timings:        eval time =  5030.92 ms /   124 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:       total time =  8565.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.42 ms /   173 runs   (    0.70 ms per token,  1436.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2240.64 ms /   536 tokens (    4.18 ms per token,   239.22 tokens per second)\n",
      "llama_print_timings:        eval time =  6948.50 ms /   172 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:       total time =  9500.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.91 ms /   190 runs   (    0.69 ms per token,  1440.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2325.35 ms /   546 tokens (    4.26 ms per token,   234.80 tokens per second)\n",
      "llama_print_timings:        eval time =  7656.56 ms /   189 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:       total time = 10323.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   175.12 ms /   251 runs   (    0.70 ms per token,  1433.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2332.77 ms /   556 tokens (    4.20 ms per token,   238.34 tokens per second)\n",
      "llama_print_timings:        eval time = 10203.58 ms /   250 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time = 12995.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    86.84 ms /   128 runs   (    0.68 ms per token,  1473.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2200.33 ms /   514 tokens (    4.28 ms per token,   233.60 tokens per second)\n",
      "llama_print_timings:        eval time =  5138.03 ms /   127 runs   (   40.46 ms per token,    24.72 tokens per second)\n",
      "llama_print_timings:       total time =  7562.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    88.69 ms /   128 runs   (    0.69 ms per token,  1443.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1008.66 ms /   252 tokens (    4.00 ms per token,   249.84 tokens per second)\n",
      "llama_print_timings:        eval time =  4979.13 ms /   127 runs   (   39.21 ms per token,    25.51 tokens per second)\n",
      "llama_print_timings:       total time =  6215.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.95 ms /   148 runs   (    0.70 ms per token,  1437.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   401.88 ms /    68 tokens (    5.91 ms per token,   169.20 tokens per second)\n",
      "llama_print_timings:        eval time =  5652.43 ms /   147 runs   (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_print_timings:       total time =  6320.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.77 ms /   256 runs   (    0.69 ms per token,  1440.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2565.28 ms /   586 tokens (    4.38 ms per token,   228.43 tokens per second)\n",
      "llama_print_timings:        eval time = 10462.22 ms /   255 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time = 13492.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   164.94 ms /   236 runs   (    0.70 ms per token,  1430.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2349.01 ms /   548 tokens (    4.29 ms per token,   233.29 tokens per second)\n",
      "llama_print_timings:        eval time =  9566.56 ms /   235 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time = 12347.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.55 ms /   256 runs   (    0.69 ms per token,  1441.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2237.16 ms /   532 tokens (    4.21 ms per token,   237.80 tokens per second)\n",
      "llama_print_timings:        eval time = 10388.96 ms /   255 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time = 13090.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   178.17 ms /   256 runs   (    0.70 ms per token,  1436.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2241.52 ms /   538 tokens (    4.17 ms per token,   240.02 tokens per second)\n",
      "llama_print_timings:        eval time = 10388.49 ms /   255 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time = 13093.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.09 ms /   195 runs   (    0.70 ms per token,  1432.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2241.99 ms /   538 tokens (    4.17 ms per token,   239.97 tokens per second)\n",
      "llama_print_timings:        eval time =  7865.50 ms /   194 runs   (   40.54 ms per token,    24.66 tokens per second)\n",
      "llama_print_timings:       total time = 10457.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.62 ms /   198 runs   (    0.71 ms per token,  1418.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2245.65 ms /   540 tokens (    4.16 ms per token,   240.46 tokens per second)\n",
      "llama_print_timings:        eval time =  7979.14 ms /   197 runs   (   40.50 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time = 10586.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.16 ms /   191 runs   (    0.69 ms per token,  1456.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1867.12 ms /   458 tokens (    4.08 ms per token,   245.30 tokens per second)\n",
      "llama_print_timings:        eval time =  7660.65 ms /   190 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =  9865.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.46 ms /   256 runs   (    0.69 ms per token,  1442.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2330.25 ms /   552 tokens (    4.22 ms per token,   236.88 tokens per second)\n",
      "llama_print_timings:        eval time = 10432.42 ms /   255 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time = 13224.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.82 ms /   256 runs   (    0.69 ms per token,  1439.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2236.02 ms /   529 tokens (    4.23 ms per token,   236.58 tokens per second)\n",
      "llama_print_timings:        eval time = 10426.58 ms /   255 runs   (   40.89 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time = 13127.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.65 ms /   243 runs   (    0.69 ms per token,  1449.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2259.79 ms /   543 tokens (    4.16 ms per token,   240.29 tokens per second)\n",
      "llama_print_timings:        eval time =  9926.80 ms /   242 runs   (   41.02 ms per token,    24.38 tokens per second)\n",
      "llama_print_timings:       total time = 12622.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   121.66 ms /   176 runs   (    0.69 ms per token,  1446.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2256.09 ms /   543 tokens (    4.15 ms per token,   240.68 tokens per second)\n",
      "llama_print_timings:        eval time =  7146.50 ms /   175 runs   (   40.84 ms per token,    24.49 tokens per second)\n",
      "llama_print_timings:       total time =  9715.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   165.33 ms /   238 runs   (    0.69 ms per token,  1439.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2239.95 ms /   532 tokens (    4.21 ms per token,   237.51 tokens per second)\n",
      "llama_print_timings:        eval time =  9669.01 ms /   237 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time = 12340.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.57 ms /   256 runs   (    0.69 ms per token,  1441.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2046.30 ms /   512 tokens (    4.00 ms per token,   250.21 tokens per second)\n",
      "llama_print_timings:        eval time = 10378.74 ms /   255 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time = 12884.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.85 ms /   256 runs   (    0.69 ms per token,  1439.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2235.73 ms /   521 tokens (    4.29 ms per token,   233.03 tokens per second)\n",
      "llama_print_timings:        eval time = 10388.16 ms /   255 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time = 13090.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.69 ms /   221 runs   (    0.70 ms per token,  1437.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2331.78 ms /   557 tokens (    4.19 ms per token,   238.87 tokens per second)\n",
      "llama_print_timings:        eval time =  8964.95 ms /   220 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:       total time = 11698.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   175.75 ms /   256 runs   (    0.69 ms per token,  1456.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2224.30 ms /   515 tokens (    4.32 ms per token,   231.53 tokens per second)\n",
      "llama_print_timings:        eval time = 10378.38 ms /   255 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time = 13064.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.04 ms /   256 runs   (    0.69 ms per token,  1454.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   915.71 ms /   235 tokens (    3.90 ms per token,   256.63 tokens per second)\n",
      "llama_print_timings:        eval time = 10039.91 ms /   255 runs   (   39.37 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:       total time = 11428.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   175.94 ms /   255 runs   (    0.69 ms per token,  1449.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2351.68 ms /   567 tokens (    4.15 ms per token,   241.10 tokens per second)\n",
      "llama_print_timings:        eval time = 10384.74 ms /   254 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time = 13200.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.33 ms /   230 runs   (    0.69 ms per token,  1443.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2225.62 ms /   516 tokens (    4.31 ms per token,   231.85 tokens per second)\n",
      "llama_print_timings:        eval time =  9308.89 ms /   229 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time = 11950.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.92 ms /   256 runs   (    0.69 ms per token,  1447.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2334.11 ms /   546 tokens (    4.27 ms per token,   233.92 tokens per second)\n",
      "llama_print_timings:        eval time = 10416.00 ms /   255 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time = 13216.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   114.47 ms /   165 runs   (    0.69 ms per token,  1441.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1238.40 ms /   316 tokens (    3.92 ms per token,   255.17 tokens per second)\n",
      "llama_print_timings:        eval time =  6493.11 ms /   164 runs   (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_print_timings:       total time =  8028.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.83 ms /   256 runs   (    0.69 ms per token,  1447.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1103.18 ms /   270 tokens (    4.09 ms per token,   244.75 tokens per second)\n",
      "llama_print_timings:        eval time = 10100.18 ms /   255 runs   (   39.61 ms per token,    25.25 tokens per second)\n",
      "llama_print_timings:       total time = 11665.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   172.50 ms /   251 runs   (    0.69 ms per token,  1455.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1095.91 ms /   276 tokens (    3.97 ms per token,   251.84 tokens per second)\n",
      "llama_print_timings:        eval time =  9912.00 ms /   250 runs   (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:       total time = 11460.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   178.47 ms /   256 runs   (    0.70 ms per token,  1434.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2351.23 ms /   554 tokens (    4.24 ms per token,   235.62 tokens per second)\n",
      "llama_print_timings:        eval time = 10409.11 ms /   255 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time = 13232.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.00 ms /   200 runs   (    0.69 ms per token,  1449.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2508.39 ms /   593 tokens (    4.23 ms per token,   236.41 tokens per second)\n",
      "llama_print_timings:        eval time =  8150.78 ms /   199 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
      "llama_print_timings:       total time = 11018.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.74 ms /   156 runs   (    0.69 ms per token,  1447.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2497.23 ms /   590 tokens (    4.23 ms per token,   236.26 tokens per second)\n",
      "llama_print_timings:        eval time =  6331.66 ms /   155 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  9106.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.74 ms /   211 runs   (    0.70 ms per token,  1437.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2351.52 ms /   566 tokens (    4.15 ms per token,   240.70 tokens per second)\n",
      "llama_print_timings:        eval time =  8589.69 ms /   210 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time = 11321.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.72 ms /   154 runs   (    0.70 ms per token,  1429.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2354.71 ms /   567 tokens (    4.15 ms per token,   240.79 tokens per second)\n",
      "llama_print_timings:        eval time =  6220.52 ms /   153 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  8855.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   112.22 ms /   160 runs   (    0.70 ms per token,  1425.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2489.27 ms /   577 tokens (    4.31 ms per token,   231.79 tokens per second)\n",
      "llama_print_timings:        eval time =  6453.42 ms /   159 runs   (   40.59 ms per token,    24.64 tokens per second)\n",
      "llama_print_timings:       total time =  9234.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.81 ms /   256 runs   (    0.71 ms per token,  1408.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2362.34 ms /   572 tokens (    4.13 ms per token,   242.13 tokens per second)\n",
      "llama_print_timings:        eval time = 10403.01 ms /   255 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time = 13242.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.99 ms /   171 runs   (    0.70 ms per token,  1425.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2490.47 ms /   580 tokens (    4.29 ms per token,   232.89 tokens per second)\n",
      "llama_print_timings:        eval time =  6906.26 ms /   170 runs   (   40.63 ms per token,    24.62 tokens per second)\n",
      "llama_print_timings:       total time =  9705.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.78 ms /   209 runs   (    0.71 ms per token,  1414.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2510.26 ms /   586 tokens (    4.28 ms per token,   233.44 tokens per second)\n",
      "llama_print_timings:        eval time =  8469.66 ms /   208 runs   (   40.72 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time = 11366.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.90 ms /   159 runs   (    0.70 ms per token,  1420.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2499.85 ms /   583 tokens (    4.29 ms per token,   233.21 tokens per second)\n",
      "llama_print_timings:        eval time =  6422.97 ms /   158 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  9208.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.64 ms /   229 runs   (    0.69 ms per token,  1452.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2357.30 ms /   568 tokens (    4.15 ms per token,   240.95 tokens per second)\n",
      "llama_print_timings:        eval time =  9325.20 ms /   228 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time = 12094.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   106.48 ms /   155 runs   (    0.69 ms per token,  1455.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2507.88 ms /   586 tokens (    4.28 ms per token,   233.66 tokens per second)\n",
      "llama_print_timings:        eval time =  6288.41 ms /   154 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
      "llama_print_timings:       total time =  9069.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   106.09 ms /   154 runs   (    0.69 ms per token,  1451.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   851.33 ms /   195 tokens (    4.37 ms per token,   229.05 tokens per second)\n",
      "llama_print_timings:        eval time =  5977.89 ms /   153 runs   (   39.07 ms per token,    25.59 tokens per second)\n",
      "llama_print_timings:       total time =  7101.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   163.07 ms /   236 runs   (    0.69 ms per token,  1447.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2276.05 ms /   541 tokens (    4.21 ms per token,   237.69 tokens per second)\n",
      "llama_print_timings:        eval time =  9632.26 ms /   235 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
      "llama_print_timings:       total time = 12328.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.08 ms /   210 runs   (    0.70 ms per token,  1437.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1229.36 ms /   309 tokens (    3.98 ms per token,   251.35 tokens per second)\n",
      "llama_print_timings:        eval time =  8383.24 ms /   209 runs   (   40.11 ms per token,    24.93 tokens per second)\n",
      "llama_print_timings:       total time =  9986.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    97.44 ms /   142 runs   (    0.69 ms per token,  1457.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2668.98 ms /   617 tokens (    4.33 ms per token,   231.17 tokens per second)\n",
      "llama_print_timings:        eval time =  5808.05 ms /   141 runs   (   41.19 ms per token,    24.28 tokens per second)\n",
      "llama_print_timings:       total time =  8726.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    81.52 ms /   118 runs   (    0.69 ms per token,  1447.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2731.48 ms /   643 tokens (    4.25 ms per token,   235.40 tokens per second)\n",
      "llama_print_timings:        eval time =  4835.99 ms /   117 runs   (   41.33 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =  7775.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    82.00 ms /   117 runs   (    0.70 ms per token,  1426.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2517.43 ms /   595 tokens (    4.23 ms per token,   236.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4735.80 ms /   116 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
      "llama_print_timings:       total time =  7463.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.17 ms /   149 runs   (    0.69 ms per token,  1444.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2733.32 ms /   649 tokens (    4.21 ms per token,   237.44 tokens per second)\n",
      "llama_print_timings:        eval time =  6102.20 ms /   148 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time =  9098.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    98.09 ms /   142 runs   (    0.69 ms per token,  1447.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2247.15 ms /   531 tokens (    4.23 ms per token,   236.30 tokens per second)\n",
      "llama_print_timings:        eval time =  5732.15 ms /   141 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  8227.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   109.28 ms /   158 runs   (    0.69 ms per token,  1445.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2506.71 ms /   593 tokens (    4.23 ms per token,   236.56 tokens per second)\n",
      "llama_print_timings:        eval time =  6430.90 ms /   157 runs   (   40.96 ms per token,    24.41 tokens per second)\n",
      "llama_print_timings:       total time =  9214.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    81.77 ms /   118 runs   (    0.69 ms per token,  1443.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2490.55 ms /   579 tokens (    4.30 ms per token,   232.48 tokens per second)\n",
      "llama_print_timings:        eval time =  4775.43 ms /   117 runs   (   40.82 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =  7472.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.76 ms /   158 runs   (    0.70 ms per token,  1426.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2364.44 ms /   570 tokens (    4.15 ms per token,   241.07 tokens per second)\n",
      "llama_print_timings:        eval time =  6406.38 ms /   157 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  9052.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    95.82 ms /   139 runs   (    0.69 ms per token,  1450.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2604.33 ms /   613 tokens (    4.25 ms per token,   235.38 tokens per second)\n",
      "llama_print_timings:        eval time =  5640.46 ms /   138 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:       total time =  8490.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.67 ms /   128 runs   (    0.68 ms per token,  1460.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2507.09 ms /   596 tokens (    4.21 ms per token,   237.73 tokens per second)\n",
      "llama_print_timings:        eval time =  5187.31 ms /   127 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  7917.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.15 ms /   166 runs   (    0.69 ms per token,  1441.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2357.99 ms /   564 tokens (    4.18 ms per token,   239.19 tokens per second)\n",
      "llama_print_timings:        eval time =  6741.51 ms /   165 runs   (   40.86 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  9392.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    82.64 ms /   120 runs   (    0.69 ms per token,  1452.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2503.51 ms /   580 tokens (    4.32 ms per token,   231.68 tokens per second)\n",
      "llama_print_timings:        eval time =  4856.63 ms /   119 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =  7570.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    80.76 ms /   118 runs   (    0.68 ms per token,  1461.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2520.75 ms /   600 tokens (    4.20 ms per token,   238.02 tokens per second)\n",
      "llama_print_timings:        eval time =  4779.81 ms /   117 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  7505.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    81.69 ms /   119 runs   (    0.69 ms per token,  1456.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2357.01 ms /   561 tokens (    4.20 ms per token,   238.01 tokens per second)\n",
      "llama_print_timings:        eval time =  4797.72 ms /   118 runs   (   40.66 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  7361.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.66 ms /   158 runs   (    0.68 ms per token,  1467.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2518.07 ms /   589 tokens (    4.28 ms per token,   233.91 tokens per second)\n",
      "llama_print_timings:        eval time =  6437.59 ms /   157 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:       total time =  9233.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.11 ms /   148 runs   (    0.72 ms per token,  1381.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2493.73 ms /   579 tokens (    4.31 ms per token,   232.18 tokens per second)\n",
      "llama_print_timings:        eval time =  6012.38 ms /   147 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =  8773.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   108.28 ms /   148 runs   (    0.73 ms per token,  1366.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2257.51 ms /   541 tokens (    4.17 ms per token,   239.64 tokens per second)\n",
      "llama_print_timings:        eval time =  5988.38 ms /   147 runs   (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =  8512.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    93.35 ms /   126 runs   (    0.74 ms per token,  1349.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2344.51 ms /   556 tokens (    4.22 ms per token,   237.15 tokens per second)\n",
      "llama_print_timings:        eval time =  5091.28 ms /   125 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =  7663.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.92 ms /   158 runs   (    0.75 ms per token,  1339.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2487.06 ms /   586 tokens (    4.24 ms per token,   235.62 tokens per second)\n",
      "llama_print_timings:        eval time =  6423.51 ms /   157 runs   (   40.91 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =  9202.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    95.49 ms /   142 runs   (    0.67 ms per token,  1487.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2346.79 ms /   576 tokens (    4.07 ms per token,   245.44 tokens per second)\n",
      "llama_print_timings:        eval time =  5747.24 ms /   141 runs   (   40.76 ms per token,    24.53 tokens per second)\n",
      "llama_print_timings:       total time =  8339.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    82.57 ms /   119 runs   (    0.69 ms per token,  1441.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2251.45 ms /   543 tokens (    4.15 ms per token,   241.18 tokens per second)\n",
      "llama_print_timings:        eval time =  4779.63 ms /   118 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time =  7245.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    95.64 ms /   142 runs   (    0.67 ms per token,  1484.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2241.90 ms /   523 tokens (    4.29 ms per token,   233.28 tokens per second)\n",
      "llama_print_timings:        eval time =  5700.57 ms /   141 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:       total time =  8190.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    88.40 ms /   132 runs   (    0.67 ms per token,  1493.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2348.37 ms /   560 tokens (    4.19 ms per token,   238.46 tokens per second)\n",
      "llama_print_timings:        eval time =  5332.40 ms /   131 runs   (   40.71 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =  7908.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.29 ms /   148 runs   (    0.67 ms per token,  1490.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2354.12 ms /   568 tokens (    4.14 ms per token,   241.28 tokens per second)\n",
      "llama_print_timings:        eval time =  5993.51 ms /   147 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
      "llama_print_timings:       total time =  8607.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    79.06 ms /   118 runs   (    0.67 ms per token,  1492.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2025.40 ms /   483 tokens (    4.19 ms per token,   238.47 tokens per second)\n",
      "llama_print_timings:        eval time =  4722.94 ms /   117 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
      "llama_print_timings:       total time =  6950.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.89 ms /   158 runs   (    0.68 ms per token,  1464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1907.42 ms /   473 tokens (    4.03 ms per token,   247.98 tokens per second)\n",
      "llama_print_timings:        eval time =  6330.11 ms /   157 runs   (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:       total time =  8513.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   100.75 ms /   148 runs   (    0.68 ms per token,  1468.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2364.82 ms /   575 tokens (    4.11 ms per token,   243.15 tokens per second)\n",
      "llama_print_timings:        eval time =  5995.23 ms /   147 runs   (   40.78 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =  8618.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.03 ms /   148 runs   (    0.67 ms per token,  1494.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2350.27 ms /   561 tokens (    4.19 ms per token,   238.70 tokens per second)\n",
      "llama_print_timings:        eval time =  5982.37 ms /   147 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =  8588.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.06 ms /   148 runs   (    0.67 ms per token,  1494.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2348.49 ms /   567 tokens (    4.14 ms per token,   241.43 tokens per second)\n",
      "llama_print_timings:        eval time =  5990.45 ms /   147 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:       total time =  8595.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    79.04 ms /   118 runs   (    0.67 ms per token,  1492.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2503.69 ms /   597 tokens (    4.19 ms per token,   238.45 tokens per second)\n",
      "llama_print_timings:        eval time =  4783.68 ms /   117 runs   (   40.89 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  7490.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.28 ms /   148 runs   (    0.67 ms per token,  1490.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2478.03 ms /   580 tokens (    4.27 ms per token,   234.06 tokens per second)\n",
      "llama_print_timings:        eval time =  6003.99 ms /   147 runs   (   40.84 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  8737.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   124.25 ms /   186 runs   (    0.67 ms per token,  1497.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2334.31 ms /   556 tokens (    4.20 ms per token,   238.19 tokens per second)\n",
      "llama_print_timings:        eval time =  7546.18 ms /   185 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time = 10202.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   142.76 ms /   213 runs   (    0.67 ms per token,  1492.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2490.12 ms /   586 tokens (    4.25 ms per token,   235.33 tokens per second)\n",
      "llama_print_timings:        eval time =  8692.00 ms /   212 runs   (   41.00 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:       total time = 11556.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.65 ms /   158 runs   (    0.67 ms per token,  1495.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2493.40 ms /   588 tokens (    4.24 ms per token,   235.82 tokens per second)\n",
      "llama_print_timings:        eval time =  6397.21 ms /   157 runs   (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:       total time =  9165.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.32 ms /   156 runs   (    0.67 ms per token,  1495.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2505.56 ms /   597 tokens (    4.20 ms per token,   238.27 tokens per second)\n",
      "llama_print_timings:        eval time =  6377.48 ms /   155 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
      "llama_print_timings:       total time =  9153.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.80 ms /   138 runs   (    0.67 ms per token,  1487.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2584.35 ms /   612 tokens (    4.22 ms per token,   236.81 tokens per second)\n",
      "llama_print_timings:        eval time =  5647.38 ms /   137 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time =  8471.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    78.73 ms /   118 runs   (    0.67 ms per token,  1498.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2471.97 ms /   578 tokens (    4.28 ms per token,   233.82 tokens per second)\n",
      "llama_print_timings:        eval time =  4789.54 ms /   117 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =  7464.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.23 ms /   158 runs   (    0.67 ms per token,  1501.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2351.63 ms /   574 tokens (    4.10 ms per token,   244.09 tokens per second)\n",
      "llama_print_timings:        eval time =  6410.90 ms /   157 runs   (   40.83 ms per token,    24.49 tokens per second)\n",
      "llama_print_timings:       total time =  9036.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    74.55 ms /   111 runs   (    0.67 ms per token,  1488.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2519.14 ms /   607 tokens (    4.15 ms per token,   240.96 tokens per second)\n",
      "llama_print_timings:        eval time =  4494.39 ms /   110 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:       total time =  7204.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.12 ms /   148 runs   (    0.67 ms per token,  1493.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2497.88 ms /   588 tokens (    4.25 ms per token,   235.40 tokens per second)\n",
      "llama_print_timings:        eval time =  6005.61 ms /   147 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  8759.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   171.47 ms /   256 runs   (    0.67 ms per token,  1492.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2504.90 ms /   597 tokens (    4.20 ms per token,   238.33 tokens per second)\n",
      "llama_print_timings:        eval time = 10499.36 ms /   255 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
      "llama_print_timings:       total time = 13456.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.97 ms /   158 runs   (    0.67 ms per token,  1490.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2485.67 ms /   588 tokens (    4.23 ms per token,   236.56 tokens per second)\n",
      "llama_print_timings:        eval time =  6421.87 ms /   157 runs   (   40.90 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:       total time =  9181.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    88.31 ms /   132 runs   (    0.67 ms per token,  1494.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2499.59 ms /   602 tokens (    4.15 ms per token,   240.84 tokens per second)\n",
      "llama_print_timings:        eval time =  5354.50 ms /   131 runs   (   40.87 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:       total time =  8082.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    96.50 ms /   143 runs   (    0.67 ms per token,  1481.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   983.47 ms /   247 tokens (    3.98 ms per token,   251.15 tokens per second)\n",
      "llama_print_timings:        eval time =  5562.13 ms /   142 runs   (   39.17 ms per token,    25.53 tokens per second)\n",
      "llama_print_timings:       total time =  6794.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.72 ms /   206 runs   (    0.67 ms per token,  1484.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   613.75 ms /   142 tokens (    4.32 ms per token,   231.36 tokens per second)\n",
      "llama_print_timings:        eval time =  7980.56 ms /   205 runs   (   38.93 ms per token,    25.69 tokens per second)\n",
      "llama_print_timings:       total time =  8956.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   171.42 ms /   256 runs   (    0.67 ms per token,  1493.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2584.81 ms /   609 tokens (    4.24 ms per token,   235.61 tokens per second)\n",
      "llama_print_timings:        eval time = 10483.59 ms /   255 runs   (   41.11 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:       total time = 13523.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.04 ms /   173 runs   (    0.67 ms per token,  1490.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2485.55 ms /   578 tokens (    4.30 ms per token,   232.54 tokens per second)\n",
      "llama_print_timings:        eval time =  7037.70 ms /   172 runs   (   40.92 ms per token,    24.44 tokens per second)\n",
      "llama_print_timings:       total time =  9824.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   172.21 ms /   256 runs   (    0.67 ms per token,  1486.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2734.28 ms /   662 tokens (    4.13 ms per token,   242.11 tokens per second)\n",
      "llama_print_timings:        eval time = 10564.42 ms /   255 runs   (   41.43 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:       total time = 13752.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.35 ms /   256 runs   (    0.68 ms per token,  1476.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2903.95 ms /   701 tokens (    4.14 ms per token,   241.40 tokens per second)\n",
      "llama_print_timings:        eval time = 10602.61 ms /   255 runs   (   41.58 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time = 13965.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.74 ms /   256 runs   (    0.68 ms per token,  1473.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2890.72 ms /   694 tokens (    4.17 ms per token,   240.08 tokens per second)\n",
      "llama_print_timings:        eval time = 10605.02 ms /   255 runs   (   41.59 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time = 13953.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   171.43 ms /   256 runs   (    0.67 ms per token,  1493.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2881.52 ms /   684 tokens (    4.21 ms per token,   237.37 tokens per second)\n",
      "llama_print_timings:        eval time = 10612.85 ms /   255 runs   (   41.62 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time = 13945.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   122.67 ms /   183 runs   (    0.67 ms per token,  1491.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2340.68 ms /   567 tokens (    4.13 ms per token,   242.24 tokens per second)\n",
      "llama_print_timings:        eval time =  7450.95 ms /   182 runs   (   40.94 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time = 10109.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.81 ms /   191 runs   (    0.67 ms per token,  1494.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   496.38 ms /   108 tokens (    4.60 ms per token,   217.58 tokens per second)\n",
      "llama_print_timings:        eval time =  7361.64 ms /   190 runs   (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_print_timings:       total time =  8195.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.43 ms /   158 runs   (    0.67 ms per token,  1498.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   273.69 ms /    56 tokens (    4.89 ms per token,   204.61 tokens per second)\n",
      "llama_print_timings:        eval time =  6039.28 ms /   157 runs   (   38.47 ms per token,    26.00 tokens per second)\n",
      "llama_print_timings:       total time =  6585.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.18 ms /   201 runs   (    0.68 ms per token,  1475.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2259.92 ms /   532 tokens (    4.25 ms per token,   235.41 tokens per second)\n",
      "llama_print_timings:        eval time =  8139.35 ms /   200 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time = 10757.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.84 ms /   183 runs   (    0.68 ms per token,  1477.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2038.67 ms /   499 tokens (    4.09 ms per token,   244.77 tokens per second)\n",
      "llama_print_timings:        eval time =  7373.19 ms /   182 runs   (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:       total time =  9730.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   174.60 ms /   256 runs   (    0.68 ms per token,  1466.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1758.10 ms /   428 tokens (    4.11 ms per token,   243.45 tokens per second)\n",
      "llama_print_timings:        eval time = 10343.03 ms /   255 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:       total time = 12573.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.65 ms /   198 runs   (    0.71 ms per token,  1417.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1783.34 ms /   418 tokens (    4.27 ms per token,   234.39 tokens per second)\n",
      "llama_print_timings:        eval time =  7922.34 ms /   197 runs   (   40.21 ms per token,    24.87 tokens per second)\n",
      "llama_print_timings:       total time = 10070.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   203.00 ms /   256 runs   (    0.79 ms per token,  1261.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2046.11 ms /   488 tokens (    4.19 ms per token,   238.50 tokens per second)\n",
      "llama_print_timings:        eval time = 10476.23 ms /   255 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time = 13067.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.10 ms /   256 runs   (    0.71 ms per token,  1413.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2327.36 ms /   517 tokens (    4.50 ms per token,   222.14 tokens per second)\n",
      "llama_print_timings:        eval time = 10513.55 ms /   255 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time = 13329.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.63 ms /   256 runs   (    0.69 ms per token,  1449.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2090.99 ms /   501 tokens (    4.17 ms per token,   239.60 tokens per second)\n",
      "llama_print_timings:        eval time = 10416.35 ms /   255 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time = 12977.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   155.25 ms /   223 runs   (    0.70 ms per token,  1436.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1678.15 ms /   409 tokens (    4.10 ms per token,   243.72 tokens per second)\n",
      "llama_print_timings:        eval time =  8955.46 ms /   222 runs   (   40.34 ms per token,    24.79 tokens per second)\n",
      "llama_print_timings:       total time = 11061.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   134.00 ms /   194 runs   (    0.69 ms per token,  1447.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   422.16 ms /    89 tokens (    4.74 ms per token,   210.82 tokens per second)\n",
      "llama_print_timings:        eval time =  7487.78 ms /   193 runs   (   38.80 ms per token,    25.78 tokens per second)\n",
      "llama_print_timings:       total time =  8270.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.40 ms /   160 runs   (    0.70 ms per token,  1436.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1573.33 ms /   381 tokens (    4.13 ms per token,   242.16 tokens per second)\n",
      "llama_print_timings:        eval time =  6333.07 ms /   159 runs   (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:       total time =  8208.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.84 ms /   175 runs   (    0.69 ms per token,  1448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2126.17 ms /   492 tokens (    4.32 ms per token,   231.40 tokens per second)\n",
      "llama_print_timings:        eval time =  7034.07 ms /   174 runs   (   40.43 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:       total time =  9484.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   101.04 ms /   144 runs   (    0.70 ms per token,  1425.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2337.17 ms /   527 tokens (    4.43 ms per token,   225.49 tokens per second)\n",
      "llama_print_timings:        eval time =  5772.94 ms /   143 runs   (   40.37 ms per token,    24.77 tokens per second)\n",
      "llama_print_timings:       total time =  8373.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.55 ms /   184 runs   (    0.69 ms per token,  1442.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2308.41 ms /   515 tokens (    4.48 ms per token,   223.10 tokens per second)\n",
      "llama_print_timings:        eval time =  7441.33 ms /   183 runs   (   40.66 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:       total time = 10085.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.61 ms /   151 runs   (    0.69 ms per token,  1443.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1962.09 ms /   466 tokens (    4.21 ms per token,   237.50 tokens per second)\n",
      "llama_print_timings:        eval time =  6066.27 ms /   150 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:       total time =  8299.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.63 ms /   172 runs   (    0.70 ms per token,  1437.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2087.96 ms /   500 tokens (    4.18 ms per token,   239.47 tokens per second)\n",
      "llama_print_timings:        eval time =  7047.16 ms /   171 runs   (   41.21 ms per token,    24.27 tokens per second)\n",
      "llama_print_timings:       total time =  9454.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   178.24 ms /   256 runs   (    0.70 ms per token,  1436.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1626.80 ms /   377 tokens (    4.32 ms per token,   231.74 tokens per second)\n",
      "llama_print_timings:        eval time = 10582.26 ms /   255 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
      "llama_print_timings:       total time = 12691.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.91 ms /   170 runs   (    0.69 ms per token,  1441.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1136.42 ms /   260 tokens (    4.37 ms per token,   228.79 tokens per second)\n",
      "llama_print_timings:        eval time =  6835.07 ms /   169 runs   (   40.44 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:       total time =  8290.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   114.41 ms /   162 runs   (    0.71 ms per token,  1415.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =   424.32 ms /    89 tokens (    4.77 ms per token,   209.74 tokens per second)\n",
      "llama_print_timings:        eval time =  6548.91 ms /   161 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =  7287.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.22 ms /   256 runs   (    0.72 ms per token,  1397.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =   933.82 ms /   198 tokens (    4.72 ms per token,   212.03 tokens per second)\n",
      "llama_print_timings:        eval time = 10336.83 ms /   255 runs   (   40.54 ms per token,    24.67 tokens per second)\n",
      "llama_print_timings:       total time = 11750.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   121.29 ms /   172 runs   (    0.71 ms per token,  1418.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   444.91 ms /    78 tokens (    5.70 ms per token,   175.32 tokens per second)\n",
      "llama_print_timings:        eval time =  6841.51 ms /   171 runs   (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:       total time =  7603.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.79 ms /   256 runs   (    0.72 ms per token,  1392.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2588.85 ms /   531 tokens (    4.88 ms per token,   205.11 tokens per second)\n",
      "llama_print_timings:        eval time = 10754.02 ms /   255 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time = 13830.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.20 ms /   202 runs   (    0.71 ms per token,  1400.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1685.94 ms /   372 tokens (    4.53 ms per token,   220.65 tokens per second)\n",
      "llama_print_timings:        eval time =  8316.43 ms /   201 runs   (   41.38 ms per token,    24.17 tokens per second)\n",
      "llama_print_timings:       total time = 10376.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.25 ms /   156 runs   (    0.74 ms per token,  1353.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   872.00 ms /   182 tokens (    4.79 ms per token,   208.72 tokens per second)\n",
      "llama_print_timings:        eval time =  6323.61 ms /   155 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  7480.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.73 ms /   256 runs   (    0.71 ms per token,  1416.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2205.87 ms /   469 tokens (    4.70 ms per token,   212.61 tokens per second)\n",
      "llama_print_timings:        eval time = 10922.47 ms /   255 runs   (   42.83 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time = 13618.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.03 ms /   205 runs   (    0.71 ms per token,  1403.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2408.39 ms /   503 tokens (    4.79 ms per token,   208.85 tokens per second)\n",
      "llama_print_timings:        eval time =  8732.90 ms /   204 runs   (   42.81 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time = 11533.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.76 ms /   185 runs   (    0.71 ms per token,  1404.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1019.64 ms /   209 tokens (    4.88 ms per token,   204.97 tokens per second)\n",
      "llama_print_timings:        eval time =  7760.87 ms /   184 runs   (   42.18 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time =  9134.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.94 ms /   175 runs   (    0.72 ms per token,  1389.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1943.49 ms /   404 tokens (    4.81 ms per token,   207.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7353.82 ms /   174 runs   (   42.26 ms per token,    23.66 tokens per second)\n",
      "llama_print_timings:       total time =  9628.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.20 ms /   255 runs   (    0.71 ms per token,  1399.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1196.26 ms /   233 tokens (    5.13 ms per token,   194.77 tokens per second)\n",
      "llama_print_timings:        eval time = 10838.31 ms /   254 runs   (   42.67 ms per token,    23.44 tokens per second)\n",
      "llama_print_timings:       total time = 12528.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.73 ms /   159 runs   (    0.72 ms per token,  1397.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   590.68 ms /   119 tokens (    4.96 ms per token,   201.46 tokens per second)\n",
      "llama_print_timings:        eval time =  6573.98 ms /   158 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time =  7454.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.95 ms /   157 runs   (    0.71 ms per token,  1402.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   320.00 ms /    64 tokens (    5.00 ms per token,   200.00 tokens per second)\n",
      "llama_print_timings:        eval time =  6512.53 ms /   156 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time =  7121.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.40 ms /   128 runs   (    0.72 ms per token,  1385.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3045.22 ms /   562 tokens (    5.42 ms per token,   184.55 tokens per second)\n",
      "llama_print_timings:        eval time =  5479.46 ms /   127 runs   (   43.15 ms per token,    23.18 tokens per second)\n",
      "llama_print_timings:       total time =  8771.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.05 ms /   250 runs   (    0.72 ms per token,  1380.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2820.09 ms /   557 tokens (    5.06 ms per token,   197.51 tokens per second)\n",
      "llama_print_timings:        eval time = 10899.87 ms /   249 runs   (   43.77 ms per token,    22.84 tokens per second)\n",
      "llama_print_timings:       total time = 14205.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.76 ms /   256 runs   (    0.73 ms per token,  1370.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2699.05 ms /   540 tokens (    5.00 ms per token,   200.07 tokens per second)\n",
      "llama_print_timings:        eval time = 11118.27 ms /   255 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time = 14303.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.68 ms /   157 runs   (    0.74 ms per token,  1357.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3202.18 ms /   644 tokens (    4.97 ms per token,   201.11 tokens per second)\n",
      "llama_print_timings:        eval time =  6643.60 ms /   156 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_print_timings:       total time = 10137.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.09 ms /   183 runs   (    0.72 ms per token,  1395.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2099.41 ms /   426 tokens (    4.93 ms per token,   202.91 tokens per second)\n",
      "llama_print_timings:        eval time =  7732.39 ms /   182 runs   (   42.49 ms per token,    23.54 tokens per second)\n",
      "llama_print_timings:       total time = 10170.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   150.97 ms /   209 runs   (    0.72 ms per token,  1384.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2422.73 ms /   499 tokens (    4.86 ms per token,   205.97 tokens per second)\n",
      "llama_print_timings:        eval time =  9055.12 ms /   208 runs   (   43.53 ms per token,    22.97 tokens per second)\n",
      "llama_print_timings:       total time = 11875.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.04 ms /   151 runs   (    0.71 ms per token,  1410.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2743.61 ms /   540 tokens (    5.08 ms per token,   196.82 tokens per second)\n",
      "llama_print_timings:        eval time =  6305.83 ms /   150 runs   (   42.04 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =  9329.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.90 ms /   196 runs   (    0.71 ms per token,  1411.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2743.55 ms /   544 tokens (    5.04 ms per token,   198.28 tokens per second)\n",
      "llama_print_timings:        eval time =  8484.30 ms /   195 runs   (   43.51 ms per token,    22.98 tokens per second)\n",
      "llama_print_timings:       total time = 11602.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   137.84 ms /   190 runs   (    0.73 ms per token,  1378.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2774.55 ms /   557 tokens (    4.98 ms per token,   200.75 tokens per second)\n",
      "llama_print_timings:        eval time =  8278.12 ms /   189 runs   (   43.80 ms per token,    22.83 tokens per second)\n",
      "llama_print_timings:       total time = 11426.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.23 ms /   256 runs   (    0.72 ms per token,  1389.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2850.28 ms /   547 tokens (    5.21 ms per token,   191.91 tokens per second)\n",
      "llama_print_timings:        eval time = 10945.26 ms /   255 runs   (   42.92 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time = 14273.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.51 ms /   155 runs   (    0.72 ms per token,  1389.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2052.26 ms /   438 tokens (    4.69 ms per token,   213.42 tokens per second)\n",
      "llama_print_timings:        eval time =  6487.27 ms /   154 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time =  8827.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.29 ms /   155 runs   (    0.72 ms per token,  1392.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1853.18 ms /   384 tokens (    4.83 ms per token,   207.21 tokens per second)\n",
      "llama_print_timings:        eval time =  6395.15 ms /   154 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
      "llama_print_timings:       total time =  8529.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   218.07 ms /   244 runs   (    0.89 ms per token,  1118.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1427.92 ms /   289 tokens (    4.94 ms per token,   202.39 tokens per second)\n",
      "llama_print_timings:        eval time = 10657.22 ms /   243 runs   (   43.86 ms per token,    22.80 tokens per second)\n",
      "llama_print_timings:       total time = 12690.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   155.74 ms /   218 runs   (    0.71 ms per token,  1399.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2344.51 ms /   482 tokens (    4.86 ms per token,   205.59 tokens per second)\n",
      "llama_print_timings:        eval time =  9121.50 ms /   217 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time = 11865.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.07 ms /   143 runs   (    0.73 ms per token,  1374.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   556.69 ms /   106 tokens (    5.25 ms per token,   190.41 tokens per second)\n",
      "llama_print_timings:        eval time =  5761.58 ms /   142 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:       total time =  6577.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.64 ms /   182 runs   (    0.72 ms per token,  1382.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1002.82 ms /   224 tokens (    4.48 ms per token,   223.37 tokens per second)\n",
      "llama_print_timings:        eval time =  7399.16 ms /   181 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  8733.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.73 ms /   199 runs   (    0.72 ms per token,  1384.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   460.65 ms /    77 tokens (    5.98 ms per token,   167.16 tokens per second)\n",
      "llama_print_timings:        eval time =  8053.79 ms /   198 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =  8877.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   101.98 ms /   141 runs   (    0.72 ms per token,  1382.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   289.49 ms /    35 tokens (    8.27 ms per token,   120.90 tokens per second)\n",
      "llama_print_timings:        eval time =  5643.42 ms /   140 runs   (   40.31 ms per token,    24.81 tokens per second)\n",
      "llama_print_timings:       total time =  6186.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.79 ms /   165 runs   (    0.73 ms per token,  1377.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2001.68 ms /   421 tokens (    4.75 ms per token,   210.32 tokens per second)\n",
      "llama_print_timings:        eval time =  6740.45 ms /   164 runs   (   41.10 ms per token,    24.33 tokens per second)\n",
      "llama_print_timings:       total time =  9042.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   106.19 ms /   151 runs   (    0.70 ms per token,  1421.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2083.63 ms /   446 tokens (    4.67 ms per token,   214.05 tokens per second)\n",
      "llama_print_timings:        eval time =  6253.75 ms /   150 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time =  8614.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.62 ms /   256 runs   (    0.71 ms per token,  1409.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1731.17 ms /   355 tokens (    4.88 ms per token,   205.06 tokens per second)\n",
      "llama_print_timings:        eval time = 10762.77 ms /   255 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time = 12979.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.41 ms /   255 runs   (    0.72 ms per token,  1390.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2605.89 ms /   542 tokens (    4.81 ms per token,   207.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10828.24 ms /   254 runs   (   42.63 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time = 13925.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   152.82 ms /   211 runs   (    0.72 ms per token,  1380.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1532.94 ms /   328 tokens (    4.67 ms per token,   213.97 tokens per second)\n",
      "llama_print_timings:        eval time =  8648.73 ms /   210 runs   (   41.18 ms per token,    24.28 tokens per second)\n",
      "llama_print_timings:       total time = 10568.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.35 ms /   256 runs   (    0.71 ms per token,  1403.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1721.17 ms /   368 tokens (    4.68 ms per token,   213.81 tokens per second)\n",
      "llama_print_timings:        eval time = 10899.76 ms /   255 runs   (   42.74 ms per token,    23.40 tokens per second)\n",
      "llama_print_timings:       total time = 13115.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.45 ms /   256 runs   (    0.73 ms per token,  1373.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2695.64 ms /   545 tokens (    4.95 ms per token,   202.18 tokens per second)\n",
      "llama_print_timings:        eval time = 10681.74 ms /   255 runs   (   41.89 ms per token,    23.87 tokens per second)\n",
      "llama_print_timings:       total time = 13862.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.17 ms /   232 runs   (    0.72 ms per token,  1387.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2694.35 ms /   556 tokens (    4.85 ms per token,   206.36 tokens per second)\n",
      "llama_print_timings:        eval time =  9709.87 ms /   231 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time = 12841.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.30 ms /   168 runs   (    0.70 ms per token,  1420.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2606.01 ms /   528 tokens (    4.94 ms per token,   202.61 tokens per second)\n",
      "llama_print_timings:        eval time =  7206.69 ms /   167 runs   (   43.15 ms per token,    23.17 tokens per second)\n",
      "llama_print_timings:       total time = 10140.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.17 ms /   256 runs   (    0.71 ms per token,  1405.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2964.97 ms /   571 tokens (    5.19 ms per token,   192.58 tokens per second)\n",
      "llama_print_timings:        eval time = 10985.08 ms /   255 runs   (   43.08 ms per token,    23.21 tokens per second)\n",
      "llama_print_timings:       total time = 14440.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.89 ms /   166 runs   (    0.71 ms per token,  1408.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2413.39 ms /   487 tokens (    4.96 ms per token,   201.79 tokens per second)\n",
      "llama_print_timings:        eval time =  7027.91 ms /   165 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_print_timings:       total time =  9758.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.03 ms /   136 runs   (    0.73 ms per token,  1373.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2893.67 ms /   588 tokens (    4.92 ms per token,   203.20 tokens per second)\n",
      "llama_print_timings:        eval time =  5560.90 ms /   135 runs   (   41.19 ms per token,    24.28 tokens per second)\n",
      "llama_print_timings:       total time =  8708.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.74 ms /   205 runs   (    0.72 ms per token,  1387.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2959.72 ms /   621 tokens (    4.77 ms per token,   209.82 tokens per second)\n",
      "llama_print_timings:        eval time =  8581.55 ms /   204 runs   (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time = 11935.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   114.18 ms /   157 runs   (    0.73 ms per token,  1374.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2738.59 ms /   576 tokens (    4.75 ms per token,   210.33 tokens per second)\n",
      "llama_print_timings:        eval time =  6459.69 ms /   156 runs   (   41.41 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =  9503.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   151.37 ms /   211 runs   (    0.72 ms per token,  1393.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2804.35 ms /   561 tokens (    5.00 ms per token,   200.05 tokens per second)\n",
      "llama_print_timings:        eval time =  8915.32 ms /   210 runs   (   42.45 ms per token,    23.55 tokens per second)\n",
      "llama_print_timings:       total time = 12126.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    93.79 ms /   132 runs   (    0.71 ms per token,  1407.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2348.22 ms /   485 tokens (    4.84 ms per token,   206.54 tokens per second)\n",
      "llama_print_timings:        eval time =  5464.42 ms /   131 runs   (   41.71 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =  8057.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    94.78 ms /   132 runs   (    0.72 ms per token,  1392.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2021.66 ms /   436 tokens (    4.64 ms per token,   215.66 tokens per second)\n",
      "llama_print_timings:        eval time =  5403.60 ms /   131 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
      "llama_print_timings:       total time =  7675.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   168.60 ms /   239 runs   (    0.71 ms per token,  1417.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1304.89 ms /   281 tokens (    4.64 ms per token,   215.34 tokens per second)\n",
      "llama_print_timings:        eval time = 10149.29 ms /   238 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time = 11920.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.71 ms /   190 runs   (    0.72 ms per token,  1389.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2425.56 ms /   498 tokens (    4.87 ms per token,   205.31 tokens per second)\n",
      "llama_print_timings:        eval time =  7997.23 ms /   189 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time = 10783.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.80 ms /   216 runs   (    0.73 ms per token,  1377.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2196.55 ms /   460 tokens (    4.78 ms per token,   209.42 tokens per second)\n",
      "llama_print_timings:        eval time =  9063.72 ms /   215 runs   (   42.16 ms per token,    23.72 tokens per second)\n",
      "llama_print_timings:       total time = 11670.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   187.42 ms /   256 runs   (    0.73 ms per token,  1365.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1408.89 ms /   296 tokens (    4.76 ms per token,   210.09 tokens per second)\n",
      "llama_print_timings:        eval time = 10535.88 ms /   255 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_print_timings:       total time = 12418.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.19 ms /   195 runs   (    0.71 ms per token,  1400.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2576.07 ms /   540 tokens (    4.77 ms per token,   209.62 tokens per second)\n",
      "llama_print_timings:        eval time =  8063.68 ms /   194 runs   (   41.57 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time = 10993.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.31 ms /   169 runs   (    0.73 ms per token,  1370.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   444.67 ms /    68 tokens (    6.54 ms per token,   152.92 tokens per second)\n",
      "llama_print_timings:        eval time =  6814.52 ms /   168 runs   (   40.56 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:       total time =  7570.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   135.53 ms /   189 runs   (    0.72 ms per token,  1394.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2365.39 ms /   512 tokens (    4.62 ms per token,   216.46 tokens per second)\n",
      "llama_print_timings:        eval time =  8063.75 ms /   188 runs   (   42.89 ms per token,    23.31 tokens per second)\n",
      "llama_print_timings:       total time = 10793.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.62 ms /   254 runs   (    0.73 ms per token,  1375.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2630.68 ms /   530 tokens (    4.96 ms per token,   201.47 tokens per second)\n",
      "llama_print_timings:        eval time = 10707.89 ms /   253 runs   (   42.32 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time = 13821.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   188.03 ms /   256 runs   (    0.73 ms per token,  1361.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2032.90 ms /   438 tokens (    4.64 ms per token,   215.46 tokens per second)\n",
      "llama_print_timings:        eval time = 10736.26 ms /   255 runs   (   42.10 ms per token,    23.75 tokens per second)\n",
      "llama_print_timings:       total time = 13251.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   142.95 ms /   200 runs   (    0.71 ms per token,  1399.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2215.44 ms /   460 tokens (    4.82 ms per token,   207.63 tokens per second)\n",
      "llama_print_timings:        eval time =  8531.57 ms /   199 runs   (   42.87 ms per token,    23.33 tokens per second)\n",
      "llama_print_timings:       total time = 11133.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   145.47 ms /   200 runs   (    0.73 ms per token,  1374.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2779.42 ms /   549 tokens (    5.06 ms per token,   197.52 tokens per second)\n",
      "llama_print_timings:        eval time =  8339.76 ms /   199 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time = 11490.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.71 ms /   165 runs   (    0.72 ms per token,  1389.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   862.06 ms /   175 tokens (    4.93 ms per token,   203.00 tokens per second)\n",
      "llama_print_timings:        eval time =  6893.08 ms /   164 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =  8072.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.91 ms /   162 runs   (    0.73 ms per token,  1373.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   711.03 ms /   154 tokens (    4.62 ms per token,   216.59 tokens per second)\n",
      "llama_print_timings:        eval time =  6603.31 ms /   161 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
      "llama_print_timings:       total time =  7617.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   165.01 ms /   225 runs   (    0.73 ms per token,  1363.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   691.84 ms /   135 tokens (    5.12 ms per token,   195.13 tokens per second)\n",
      "llama_print_timings:        eval time =  9203.81 ms /   224 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time = 10315.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.52 ms /   169 runs   (    0.71 ms per token,  1402.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1884.79 ms /   392 tokens (    4.81 ms per token,   207.98 tokens per second)\n",
      "llama_print_timings:        eval time =  7052.88 ms /   168 runs   (   41.98 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time =  9251.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   126.32 ms /   172 runs   (    0.73 ms per token,  1361.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1014.78 ms /   216 tokens (    4.70 ms per token,   212.85 tokens per second)\n",
      "llama_print_timings:        eval time =  7030.52 ms /   171 runs   (   41.11 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:       total time =  8365.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   168.93 ms /   236 runs   (    0.72 ms per token,  1397.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2371.45 ms /   501 tokens (    4.73 ms per token,   211.26 tokens per second)\n",
      "llama_print_timings:        eval time =  9893.07 ms /   235 runs   (   42.10 ms per token,    23.75 tokens per second)\n",
      "llama_print_timings:       total time = 12699.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.70 ms /   215 runs   (    0.73 ms per token,  1372.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2149.10 ms /   456 tokens (    4.71 ms per token,   212.18 tokens per second)\n",
      "llama_print_timings:        eval time =  8937.13 ms /   214 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time = 11485.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   126.14 ms /   175 runs   (    0.72 ms per token,  1387.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   603.14 ms /   127 tokens (    4.75 ms per token,   210.57 tokens per second)\n",
      "llama_print_timings:        eval time =  7280.37 ms /   174 runs   (   41.84 ms per token,    23.90 tokens per second)\n",
      "llama_print_timings:       total time =  8211.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   170.29 ms /   233 runs   (    0.73 ms per token,  1368.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2222.15 ms /   464 tokens (    4.79 ms per token,   208.81 tokens per second)\n",
      "llama_print_timings:        eval time =  9770.79 ms /   232 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time = 12434.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.95 ms /   171 runs   (    0.72 ms per token,  1379.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   563.07 ms /   116 tokens (    4.85 ms per token,   206.01 tokens per second)\n",
      "llama_print_timings:        eval time =  6937.46 ms /   170 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =  7814.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   108.24 ms /   149 runs   (    0.73 ms per token,  1376.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1145.83 ms /   250 tokens (    4.58 ms per token,   218.18 tokens per second)\n",
      "llama_print_timings:        eval time =  6049.93 ms /   148 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  7473.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.91 ms /   177 runs   (    0.73 ms per token,  1373.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2627.02 ms /   530 tokens (    4.96 ms per token,   201.75 tokens per second)\n",
      "llama_print_timings:        eval time =  7321.09 ms /   176 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time = 10281.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.87 ms /   200 runs   (    0.72 ms per token,  1390.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   993.86 ms /   194 tokens (    5.12 ms per token,   195.20 tokens per second)\n",
      "llama_print_timings:        eval time =  8174.69 ms /   199 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =  9546.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.78 ms /   241 runs   (    0.72 ms per token,  1386.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2623.87 ms /   521 tokens (    5.04 ms per token,   198.56 tokens per second)\n",
      "llama_print_timings:        eval time = 10091.44 ms /   240 runs   (   42.05 ms per token,    23.78 tokens per second)\n",
      "llama_print_timings:       total time = 13178.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.96 ms /   250 runs   (    0.74 ms per token,  1359.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2198.78 ms /   460 tokens (    4.78 ms per token,   209.21 tokens per second)\n",
      "llama_print_timings:        eval time = 10426.17 ms /   249 runs   (   41.87 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time = 13100.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.69 ms /   203 runs   (    0.72 ms per token,  1383.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2022.70 ms /   418 tokens (    4.84 ms per token,   206.65 tokens per second)\n",
      "llama_print_timings:        eval time =  8343.44 ms /   202 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
      "llama_print_timings:       total time = 10741.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.56 ms /   202 runs   (    0.73 ms per token,  1378.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1737.00 ms /   380 tokens (    4.57 ms per token,   218.77 tokens per second)\n",
      "llama_print_timings:        eval time =  8288.53 ms /   201 runs   (   41.24 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time = 10399.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.78 ms /   197 runs   (    0.73 ms per token,  1370.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1550.81 ms /   326 tokens (    4.76 ms per token,   210.21 tokens per second)\n",
      "llama_print_timings:        eval time =  8057.30 ms /   196 runs   (   41.11 ms per token,    24.33 tokens per second)\n",
      "llama_print_timings:       total time =  9971.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   132.71 ms /   180 runs   (    0.74 ms per token,  1356.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1286.91 ms /   284 tokens (    4.53 ms per token,   220.68 tokens per second)\n",
      "llama_print_timings:        eval time =  7344.44 ms /   179 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =  8964.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   188.03 ms /   256 runs   (    0.73 ms per token,  1361.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1422.19 ms /   305 tokens (    4.66 ms per token,   214.46 tokens per second)\n",
      "llama_print_timings:        eval time = 10560.88 ms /   255 runs   (   41.42 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time = 12465.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   137.17 ms /   191 runs   (    0.72 ms per token,  1392.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2214.11 ms /   477 tokens (    4.64 ms per token,   215.44 tokens per second)\n",
      "llama_print_timings:        eval time =  7908.53 ms /   190 runs   (   41.62 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time = 10479.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.36 ms /   216 runs   (    0.72 ms per token,  1381.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2597.56 ms /   526 tokens (    4.94 ms per token,   202.50 tokens per second)\n",
      "llama_print_timings:        eval time =  9006.60 ms /   215 runs   (   41.89 ms per token,    23.87 tokens per second)\n",
      "llama_print_timings:       total time = 12018.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.39 ms /   191 runs   (    0.71 ms per token,  1400.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1134.75 ms /   246 tokens (    4.61 ms per token,   216.79 tokens per second)\n",
      "llama_print_timings:        eval time =  7822.82 ms /   190 runs   (   41.17 ms per token,    24.29 tokens per second)\n",
      "llama_print_timings:       total time =  9315.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   148.51 ms /   212 runs   (    0.70 ms per token,  1427.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1008.48 ms /   201 tokens (    5.02 ms per token,   199.31 tokens per second)\n",
      "llama_print_timings:        eval time =  8822.91 ms /   211 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time = 10241.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.58 ms /   163 runs   (    0.70 ms per token,  1435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =   310.38 ms /    60 tokens (    5.17 ms per token,   193.31 tokens per second)\n",
      "llama_print_timings:        eval time =  6679.94 ms /   162 runs   (   41.23 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time =  7310.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.37 ms /   127 runs   (    0.69 ms per token,  1453.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   501.28 ms /    65 tokens (    7.71 ms per token,   129.67 tokens per second)\n",
      "llama_print_timings:        eval time =  5346.55 ms /   126 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time =  6094.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   133.92 ms /   190 runs   (    0.70 ms per token,  1418.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   465.37 ms /    67 tokens (    6.95 ms per token,   143.97 tokens per second)\n",
      "llama_print_timings:        eval time =  7842.95 ms /   189 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
      "llama_print_timings:       total time =  8679.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.87 ms /   247 runs   (    0.72 ms per token,  1388.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2656.37 ms /   543 tokens (    4.89 ms per token,   204.41 tokens per second)\n",
      "llama_print_timings:        eval time = 10477.99 ms /   246 runs   (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_print_timings:       total time = 13612.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   137.70 ms /   192 runs   (    0.72 ms per token,  1394.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1884.72 ms /   396 tokens (    4.76 ms per token,   210.11 tokens per second)\n",
      "llama_print_timings:        eval time =  7926.95 ms /   191 runs   (   41.50 ms per token,    24.10 tokens per second)\n",
      "llama_print_timings:       total time = 10160.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.38 ms /   256 runs   (    0.73 ms per token,  1373.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   991.63 ms /   202 tokens (    4.91 ms per token,   203.71 tokens per second)\n",
      "llama_print_timings:        eval time = 10528.84 ms /   255 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time = 11992.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.75 ms /   175 runs   (    0.72 ms per token,  1391.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =   701.04 ms /   160 tokens (    4.38 ms per token,   228.23 tokens per second)\n",
      "llama_print_timings:        eval time =  7109.78 ms /   174 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:       total time =  8128.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.50 ms /   153 runs   (    0.72 ms per token,  1384.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   994.08 ms /   194 tokens (    5.12 ms per token,   195.15 tokens per second)\n",
      "llama_print_timings:        eval time =  6196.74 ms /   152 runs   (   40.77 ms per token,    24.53 tokens per second)\n",
      "llama_print_timings:       total time =  7468.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.23 ms /   150 runs   (    0.71 ms per token,  1398.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   204.79 ms /    26 tokens (    7.88 ms per token,   126.96 tokens per second)\n",
      "llama_print_timings:        eval time =  6050.91 ms /   149 runs   (   40.61 ms per token,    24.62 tokens per second)\n",
      "llama_print_timings:       total time =  6529.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.18 ms /   171 runs   (    0.70 ms per token,  1422.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   557.33 ms /   103 tokens (    5.41 ms per token,   184.81 tokens per second)\n",
      "llama_print_timings:        eval time =  7008.19 ms /   170 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time =  7896.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.59 ms /   256 runs   (    0.72 ms per token,  1386.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2752.84 ms /   562 tokens (    4.90 ms per token,   204.15 tokens per second)\n",
      "llama_print_timings:        eval time = 10819.07 ms /   255 runs   (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_print_timings:       total time = 14082.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.01 ms /   256 runs   (    0.71 ms per token,  1398.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3129.34 ms /   627 tokens (    4.99 ms per token,   200.36 tokens per second)\n",
      "llama_print_timings:        eval time = 10959.33 ms /   255 runs   (   42.98 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time = 14575.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.17 ms /   122 runs   (    0.71 ms per token,  1399.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3026.74 ms /   628 tokens (    4.82 ms per token,   207.48 tokens per second)\n",
      "llama_print_timings:        eval time =  5067.41 ms /   121 runs   (   41.88 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time =  8323.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.42 ms /   162 runs   (    0.72 ms per token,  1391.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2861.60 ms /   580 tokens (    4.93 ms per token,   202.68 tokens per second)\n",
      "llama_print_timings:        eval time =  6679.65 ms /   161 runs   (   41.49 ms per token,    24.10 tokens per second)\n",
      "llama_print_timings:       total time =  9836.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.95 ms /   175 runs   (    0.71 ms per token,  1411.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2150.74 ms /   449 tokens (    4.79 ms per token,   208.77 tokens per second)\n",
      "llama_print_timings:        eval time =  7221.58 ms /   174 runs   (   41.50 ms per token,    24.09 tokens per second)\n",
      "llama_print_timings:       total time =  9695.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    90.56 ms /   127 runs   (    0.71 ms per token,  1402.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   303.04 ms /    51 tokens (    5.94 ms per token,   168.29 tokens per second)\n",
      "llama_print_timings:        eval time =  5282.96 ms /   126 runs   (   41.93 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time =  5827.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.44 ms /   256 runs   (    0.71 ms per token,  1403.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2757.08 ms /   565 tokens (    4.88 ms per token,   204.93 tokens per second)\n",
      "llama_print_timings:        eval time = 11002.34 ms /   255 runs   (   43.15 ms per token,    23.18 tokens per second)\n",
      "llama_print_timings:       total time = 14251.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   152.37 ms /   212 runs   (    0.72 ms per token,  1391.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1193.26 ms /   243 tokens (    4.91 ms per token,   203.64 tokens per second)\n",
      "llama_print_timings:        eval time =  8837.25 ms /   211 runs   (   41.88 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time = 10428.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.35 ms /   192 runs   (    0.72 ms per token,  1387.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   471.54 ms /    84 tokens (    5.61 ms per token,   178.14 tokens per second)\n",
      "llama_print_timings:        eval time =  7886.61 ms /   191 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =  8716.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   101.37 ms /   141 runs   (    0.72 ms per token,  1390.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   982.25 ms /   196 tokens (    5.01 ms per token,   199.54 tokens per second)\n",
      "llama_print_timings:        eval time =  5729.65 ms /   140 runs   (   40.93 ms per token,    24.43 tokens per second)\n",
      "llama_print_timings:       total time =  6976.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.15 ms /   221 runs   (    0.72 ms per token,  1388.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   314.13 ms /    64 tokens (    4.91 ms per token,   203.74 tokens per second)\n",
      "llama_print_timings:        eval time =  9108.26 ms /   220 runs   (   41.40 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =  9834.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.62 ms /   217 runs   (    0.72 ms per token,  1385.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   706.47 ms /   142 tokens (    4.98 ms per token,   201.00 tokens per second)\n",
      "llama_print_timings:        eval time =  8904.21 ms /   216 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time = 10010.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   158.78 ms /   221 runs   (    0.72 ms per token,  1391.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1334.45 ms /   299 tokens (    4.46 ms per token,   224.06 tokens per second)\n",
      "llama_print_timings:        eval time =  9140.28 ms /   220 runs   (   41.55 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time = 10882.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    93.53 ms /   130 runs   (    0.72 ms per token,  1389.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =   690.68 ms /   129 tokens (    5.35 ms per token,   186.77 tokens per second)\n",
      "llama_print_timings:        eval time =  5269.94 ms /   129 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  6198.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   185.27 ms /   256 runs   (    0.72 ms per token,  1381.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2722.46 ms /   545 tokens (    5.00 ms per token,   200.19 tokens per second)\n",
      "llama_print_timings:        eval time = 10838.15 ms /   255 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time = 14037.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.37 ms /   243 runs   (    0.71 ms per token,  1401.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2605.85 ms /   522 tokens (    4.99 ms per token,   200.32 tokens per second)\n",
      "llama_print_timings:        eval time = 10516.61 ms /   242 runs   (   43.46 ms per token,    23.01 tokens per second)\n",
      "llama_print_timings:       total time = 13589.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   179.44 ms /   251 runs   (    0.71 ms per token,  1398.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2704.63 ms /   548 tokens (    4.94 ms per token,   202.62 tokens per second)\n",
      "llama_print_timings:        eval time = 10644.33 ms /   250 runs   (   42.58 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 13820.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   185.08 ms /   256 runs   (    0.72 ms per token,  1383.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2632.01 ms /   544 tokens (    4.84 ms per token,   206.69 tokens per second)\n",
      "llama_print_timings:        eval time = 10846.81 ms /   255 runs   (   42.54 ms per token,    23.51 tokens per second)\n",
      "llama_print_timings:       total time = 13967.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.94 ms /   256 runs   (    0.71 ms per token,  1399.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2746.64 ms /   567 tokens (    4.84 ms per token,   206.43 tokens per second)\n",
      "llama_print_timings:        eval time = 10889.54 ms /   255 runs   (   42.70 ms per token,    23.42 tokens per second)\n",
      "llama_print_timings:       total time = 14122.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.71 ms /   186 runs   (    0.73 ms per token,  1360.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2884.84 ms /   589 tokens (    4.90 ms per token,   204.17 tokens per second)\n",
      "llama_print_timings:        eval time =  7751.34 ms /   185 runs   (   41.90 ms per token,    23.87 tokens per second)\n",
      "llama_print_timings:       total time = 10989.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.99 ms /   256 runs   (    0.71 ms per token,  1399.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1579.76 ms /   325 tokens (    4.86 ms per token,   205.73 tokens per second)\n",
      "llama_print_timings:        eval time = 10808.15 ms /   255 runs   (   42.38 ms per token,    23.59 tokens per second)\n",
      "llama_print_timings:       total time = 12881.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   140.11 ms /   192 runs   (    0.73 ms per token,  1370.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2183.22 ms /   472 tokens (    4.63 ms per token,   216.19 tokens per second)\n",
      "llama_print_timings:        eval time =  8035.73 ms /   191 runs   (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time = 10584.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.10 ms /   256 runs   (    0.71 ms per token,  1405.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2380.91 ms /   479 tokens (    4.97 ms per token,   201.18 tokens per second)\n",
      "llama_print_timings:        eval time = 10955.38 ms /   255 runs   (   42.96 ms per token,    23.28 tokens per second)\n",
      "llama_print_timings:       total time = 13830.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   158.82 ms /   226 runs   (    0.70 ms per token,  1423.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2617.64 ms /   524 tokens (    5.00 ms per token,   200.18 tokens per second)\n",
      "llama_print_timings:        eval time =  9485.71 ms /   225 runs   (   42.16 ms per token,    23.72 tokens per second)\n",
      "llama_print_timings:       total time = 12530.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   149.35 ms /   206 runs   (    0.72 ms per token,  1379.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2609.64 ms /   524 tokens (    4.98 ms per token,   200.79 tokens per second)\n",
      "llama_print_timings:        eval time =  8527.40 ms /   205 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time = 11521.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   160.16 ms /   224 runs   (    0.71 ms per token,  1398.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2199.45 ms /   474 tokens (    4.64 ms per token,   215.51 tokens per second)\n",
      "llama_print_timings:        eval time =  9312.34 ms /   223 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time = 11930.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.49 ms /   189 runs   (    0.72 ms per token,  1384.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1128.80 ms /   241 tokens (    4.68 ms per token,   213.50 tokens per second)\n",
      "llama_print_timings:        eval time =  7713.55 ms /   188 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =  9191.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.98 ms /   188 runs   (    0.73 ms per token,  1372.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1719.15 ms /   371 tokens (    4.63 ms per token,   215.80 tokens per second)\n",
      "llama_print_timings:        eval time =  7716.95 ms /   187 runs   (   41.27 ms per token,    24.23 tokens per second)\n",
      "llama_print_timings:       total time =  9780.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.76 ms /   177 runs   (    0.72 ms per token,  1385.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   704.89 ms /   153 tokens (    4.61 ms per token,   217.05 tokens per second)\n",
      "llama_print_timings:        eval time =  7181.02 ms /   176 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  8213.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   168.43 ms /   233 runs   (    0.72 ms per token,  1383.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1125.72 ms /   244 tokens (    4.61 ms per token,   216.75 tokens per second)\n",
      "llama_print_timings:        eval time =  9536.97 ms /   232 runs   (   41.11 ms per token,    24.33 tokens per second)\n",
      "llama_print_timings:       total time = 11097.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.79 ms /   240 runs   (    0.72 ms per token,  1380.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2703.73 ms /   574 tokens (    4.71 ms per token,   212.30 tokens per second)\n",
      "llama_print_timings:        eval time = 10016.04 ms /   239 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time = 13175.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   168.07 ms /   235 runs   (    0.72 ms per token,  1398.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1549.45 ms /   325 tokens (    4.77 ms per token,   209.75 tokens per second)\n",
      "llama_print_timings:        eval time =  9667.27 ms /   234 runs   (   41.31 ms per token,    24.21 tokens per second)\n",
      "llama_print_timings:       total time = 11657.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.05 ms /   202 runs   (    0.73 ms per token,  1373.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   688.00 ms /   148 tokens (    4.65 ms per token,   215.12 tokens per second)\n",
      "llama_print_timings:        eval time =  8210.20 ms /   201 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  9274.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.85 ms /   253 runs   (    0.73 ms per token,  1376.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2347.67 ms /   492 tokens (    4.77 ms per token,   209.57 tokens per second)\n",
      "llama_print_timings:        eval time = 10564.21 ms /   252 runs   (   41.92 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time = 13379.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.40 ms /   256 runs   (    0.71 ms per token,  1403.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1148.89 ms /   244 tokens (    4.71 ms per token,   212.38 tokens per second)\n",
      "llama_print_timings:        eval time = 10632.25 ms /   255 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time = 12268.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.05 ms /   167 runs   (    0.70 ms per token,  1426.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1763.54 ms /   377 tokens (    4.68 ms per token,   213.77 tokens per second)\n",
      "llama_print_timings:        eval time =  6900.92 ms /   166 runs   (   41.57 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time =  8970.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   112.67 ms /   158 runs   (    0.71 ms per token,  1402.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2769.75 ms /   565 tokens (    4.90 ms per token,   203.99 tokens per second)\n",
      "llama_print_timings:        eval time =  6700.66 ms /   157 runs   (   42.68 ms per token,    23.43 tokens per second)\n",
      "llama_print_timings:       total time =  9778.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.96 ms /   159 runs   (    0.72 ms per token,  1395.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2973.75 ms /   559 tokens (    5.32 ms per token,   187.98 tokens per second)\n",
      "llama_print_timings:        eval time =  6591.96 ms /   158 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time =  9866.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.80 ms /   214 runs   (    0.72 ms per token,  1391.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1286.20 ms /   270 tokens (    4.76 ms per token,   209.92 tokens per second)\n",
      "llama_print_timings:        eval time =  8779.95 ms /   213 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time = 10463.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.57 ms /   171 runs   (    0.72 ms per token,  1383.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   968.50 ms /   195 tokens (    4.97 ms per token,   201.34 tokens per second)\n",
      "llama_print_timings:        eval time =  6934.50 ms /   170 runs   (   40.79 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:       total time =  8219.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   148.09 ms /   209 runs   (    0.71 ms per token,  1411.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2728.12 ms /   576 tokens (    4.74 ms per token,   211.13 tokens per second)\n",
      "llama_print_timings:        eval time =  8723.26 ms /   208 runs   (   41.94 ms per token,    23.84 tokens per second)\n",
      "llama_print_timings:       total time = 11849.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   185.42 ms /   256 runs   (    0.72 ms per token,  1380.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2918.15 ms /   557 tokens (    5.24 ms per token,   190.87 tokens per second)\n",
      "llama_print_timings:        eval time = 11037.91 ms /   255 runs   (   43.29 ms per token,    23.10 tokens per second)\n",
      "llama_print_timings:       total time = 14463.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   149.75 ms /   205 runs   (    0.73 ms per token,  1368.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3407.89 ms /   718 tokens (    4.75 ms per token,   210.69 tokens per second)\n",
      "llama_print_timings:        eval time =  8626.94 ms /   204 runs   (   42.29 ms per token,    23.65 tokens per second)\n",
      "llama_print_timings:       total time = 12418.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   162.58 ms /   224 runs   (    0.73 ms per token,  1377.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2874.80 ms /   597 tokens (    4.82 ms per token,   207.67 tokens per second)\n",
      "llama_print_timings:        eval time =  9374.97 ms /   223 runs   (   42.04 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time = 12669.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    90.82 ms /   127 runs   (    0.72 ms per token,  1398.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2617.04 ms /   519 tokens (    5.04 ms per token,   198.32 tokens per second)\n",
      "llama_print_timings:        eval time =  5164.16 ms /   126 runs   (   40.99 ms per token,    24.40 tokens per second)\n",
      "llama_print_timings:       total time =  8019.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   185.26 ms /   256 runs   (    0.72 ms per token,  1381.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2870.04 ms /   589 tokens (    4.87 ms per token,   205.22 tokens per second)\n",
      "llama_print_timings:        eval time = 10786.26 ms /   255 runs   (   42.30 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time = 14146.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   124.07 ms /   172 runs   (    0.72 ms per token,  1386.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2735.55 ms /   570 tokens (    4.80 ms per token,   208.37 tokens per second)\n",
      "llama_print_timings:        eval time =  7248.66 ms /   171 runs   (   42.39 ms per token,    23.59 tokens per second)\n",
      "llama_print_timings:       total time = 10311.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.94 ms /   256 runs   (    0.71 ms per token,  1399.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2869.61 ms /   583 tokens (    4.92 ms per token,   203.16 tokens per second)\n",
      "llama_print_timings:        eval time = 10789.85 ms /   255 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time = 14142.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.68 ms /   241 runs   (    0.72 ms per token,  1387.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2876.30 ms /   577 tokens (    4.98 ms per token,   200.61 tokens per second)\n",
      "llama_print_timings:        eval time = 10137.76 ms /   240 runs   (   42.24 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time = 13461.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   132.67 ms /   183 runs   (    0.72 ms per token,  1379.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2405.70 ms /   512 tokens (    4.70 ms per token,   212.83 tokens per second)\n",
      "llama_print_timings:        eval time =  7679.58 ms /   183 runs   (   41.96 ms per token,    23.83 tokens per second)\n",
      "llama_print_timings:       total time = 10428.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.73 ms /   195 runs   (    0.71 ms per token,  1405.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2614.08 ms /   525 tokens (    4.98 ms per token,   200.84 tokens per second)\n",
      "llama_print_timings:        eval time =  8101.61 ms /   194 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time = 11076.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.11 ms /   216 runs   (    0.73 ms per token,  1374.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2621.17 ms /   525 tokens (    4.99 ms per token,   200.29 tokens per second)\n",
      "llama_print_timings:        eval time =  8983.62 ms /   215 runs   (   41.78 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time = 12005.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.51 ms /   143 runs   (    0.73 ms per token,  1368.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2578.17 ms /   515 tokens (    5.01 ms per token,   199.75 tokens per second)\n",
      "llama_print_timings:        eval time =  5827.36 ms /   142 runs   (   41.04 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =  8667.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   140.96 ms /   194 runs   (    0.73 ms per token,  1376.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2340.91 ms /   500 tokens (    4.68 ms per token,   213.59 tokens per second)\n",
      "llama_print_timings:        eval time =  8047.50 ms /   193 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time = 10747.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.58 ms /   174 runs   (    0.72 ms per token,  1385.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1707.86 ms /   372 tokens (    4.59 ms per token,   217.82 tokens per second)\n",
      "llama_print_timings:        eval time =  7302.01 ms /   173 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time =  9344.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.17 ms /   256 runs   (    0.72 ms per token,  1390.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1636.02 ms /   327 tokens (    5.00 ms per token,   199.87 tokens per second)\n",
      "llama_print_timings:        eval time = 10632.87 ms /   255 runs   (   41.70 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time = 12759.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   135.44 ms /   187 runs   (    0.72 ms per token,  1380.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1473.02 ms /   315 tokens (    4.68 ms per token,   213.85 tokens per second)\n",
      "llama_print_timings:        eval time =  7757.92 ms /   186 runs   (   41.71 ms per token,    23.98 tokens per second)\n",
      "llama_print_timings:       total time =  9587.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   135.35 ms /   183 runs   (    0.74 ms per token,  1352.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1297.06 ms /   280 tokens (    4.63 ms per token,   215.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7501.33 ms /   182 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time =  9141.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.67 ms /   192 runs   (    0.75 ms per token,  1336.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1573.17 ms /   328 tokens (    4.80 ms per token,   208.50 tokens per second)\n",
      "llama_print_timings:        eval time =  7901.44 ms /   191 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
      "llama_print_timings:       total time =  9840.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.27 ms /   171 runs   (    0.75 ms per token,  1333.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2896.09 ms /   590 tokens (    4.91 ms per token,   203.72 tokens per second)\n",
      "llama_print_timings:        eval time =  7079.30 ms /   170 runs   (   41.64 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time = 10301.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.94 ms /   187 runs   (    0.78 ms per token,  1290.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2626.81 ms /   534 tokens (    4.92 ms per token,   203.29 tokens per second)\n",
      "llama_print_timings:        eval time =  7765.82 ms /   186 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time = 10766.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    97.31 ms /   125 runs   (    0.78 ms per token,  1284.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   298.01 ms /    34 tokens (    8.76 ms per token,   114.09 tokens per second)\n",
      "llama_print_timings:        eval time =  5050.77 ms /   124 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =  5595.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   132.43 ms /   173 runs   (    0.77 ms per token,  1306.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1586.09 ms /   341 tokens (    4.65 ms per token,   214.99 tokens per second)\n",
      "llama_print_timings:        eval time =  7130.27 ms /   172 runs   (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_print_timings:       total time =  9058.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.93 ms /   256 runs   (    0.71 ms per token,  1399.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1870.06 ms /   389 tokens (    4.81 ms per token,   208.01 tokens per second)\n",
      "llama_print_timings:        eval time = 10877.31 ms /   255 runs   (   42.66 ms per token,    23.44 tokens per second)\n",
      "llama_print_timings:       total time = 13238.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   133.88 ms /   186 runs   (    0.72 ms per token,  1389.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1016.63 ms /   198 tokens (    5.13 ms per token,   194.76 tokens per second)\n",
      "llama_print_timings:        eval time =  7660.38 ms /   185 runs   (   41.41 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =  9023.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.86 ms /   196 runs   (    0.71 ms per token,  1401.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2052.86 ms /   427 tokens (    4.81 ms per token,   208.00 tokens per second)\n",
      "llama_print_timings:        eval time =  8170.50 ms /   195 runs   (   41.90 ms per token,    23.87 tokens per second)\n",
      "llama_print_timings:       total time = 10587.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   132.17 ms /   186 runs   (    0.71 ms per token,  1407.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1015.38 ms /   197 tokens (    5.15 ms per token,   194.02 tokens per second)\n",
      "llama_print_timings:        eval time =  7841.73 ms /   185 runs   (   42.39 ms per token,    23.59 tokens per second)\n",
      "llama_print_timings:       total time =  9206.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.82 ms /   256 runs   (    0.72 ms per token,  1392.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2055.23 ms /   427 tokens (    4.81 ms per token,   207.76 tokens per second)\n",
      "llama_print_timings:        eval time = 10714.57 ms /   255 runs   (   42.02 ms per token,    23.80 tokens per second)\n",
      "llama_print_timings:       total time = 13239.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.12 ms /   223 runs   (    0.71 ms per token,  1401.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   561.49 ms /   112 tokens (    5.01 ms per token,   199.47 tokens per second)\n",
      "llama_print_timings:        eval time =  9215.61 ms /   222 runs   (   41.51 ms per token,    24.09 tokens per second)\n",
      "llama_print_timings:       total time = 10192.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.02 ms /   173 runs   (    0.71 ms per token,  1406.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2770.56 ms /   555 tokens (    4.99 ms per token,   200.32 tokens per second)\n",
      "llama_print_timings:        eval time =  7522.92 ms /   172 runs   (   43.74 ms per token,    22.86 tokens per second)\n",
      "llama_print_timings:       total time = 10630.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.41 ms /   141 runs   (    0.73 ms per token,  1376.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   550.20 ms /   103 tokens (    5.34 ms per token,   187.20 tokens per second)\n",
      "llama_print_timings:        eval time =  5684.94 ms /   140 runs   (   40.61 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =  6492.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   100.98 ms /   140 runs   (    0.72 ms per token,  1386.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   869.09 ms /   187 tokens (    4.65 ms per token,   215.17 tokens per second)\n",
      "llama_print_timings:        eval time =  5671.06 ms /   139 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  6794.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.31 ms /   127 runs   (    0.73 ms per token,  1375.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   301.51 ms /    52 tokens (    5.80 ms per token,   172.47 tokens per second)\n",
      "llama_print_timings:        eval time =  5115.45 ms /   126 runs   (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:       total time =  5646.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.23 ms /   256 runs   (    0.72 ms per token,  1389.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2416.87 ms /   500 tokens (    4.83 ms per token,   206.88 tokens per second)\n",
      "llama_print_timings:        eval time = 10840.30 ms /   255 runs   (   42.51 ms per token,    23.52 tokens per second)\n",
      "llama_print_timings:       total time = 13743.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   100.52 ms /   143 runs   (    0.70 ms per token,  1422.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2803.41 ms /   563 tokens (    4.98 ms per token,   200.83 tokens per second)\n",
      "llama_print_timings:        eval time =  5908.07 ms /   142 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time =  8977.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.12 ms /   222 runs   (    0.71 ms per token,  1412.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2732.01 ms /   545 tokens (    5.01 ms per token,   199.49 tokens per second)\n",
      "llama_print_timings:        eval time =  9340.36 ms /   221 runs   (   42.26 ms per token,    23.66 tokens per second)\n",
      "llama_print_timings:       total time = 12499.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   192.56 ms /   256 runs   (    0.75 ms per token,  1329.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2593.28 ms /   523 tokens (    4.96 ms per token,   201.68 tokens per second)\n",
      "llama_print_timings:        eval time = 10761.77 ms /   255 runs   (   42.20 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time = 13856.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.63 ms /   234 runs   (    0.72 ms per token,  1395.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2587.76 ms /   533 tokens (    4.86 ms per token,   205.97 tokens per second)\n",
      "llama_print_timings:        eval time =  9824.15 ms /   233 runs   (   42.16 ms per token,    23.72 tokens per second)\n",
      "llama_print_timings:       total time = 12842.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.66 ms /   240 runs   (    0.72 ms per token,  1381.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2616.13 ms /   535 tokens (    4.89 ms per token,   204.50 tokens per second)\n",
      "llama_print_timings:        eval time = 10080.96 ms /   239 runs   (   42.18 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time = 13138.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   163.65 ms /   225 runs   (    0.73 ms per token,  1374.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2325.64 ms /   484 tokens (    4.81 ms per token,   208.11 tokens per second)\n",
      "llama_print_timings:        eval time =  9422.16 ms /   224 runs   (   42.06 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time = 12161.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.48 ms /   144 runs   (    0.72 ms per token,  1391.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2069.42 ms /   430 tokens (    4.81 ms per token,   207.79 tokens per second)\n",
      "llama_print_timings:        eval time =  5894.15 ms /   143 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time =  8223.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.36 ms /   145 runs   (    0.73 ms per token,  1376.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1920.38 ms /   416 tokens (    4.62 ms per token,   216.62 tokens per second)\n",
      "llama_print_timings:        eval time =  5959.72 ms /   144 runs   (   41.39 ms per token,    24.16 tokens per second)\n",
      "llama_print_timings:       total time =  8142.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.28 ms /   179 runs   (    0.72 ms per token,  1395.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1926.99 ms /   409 tokens (    4.71 ms per token,   212.25 tokens per second)\n",
      "llama_print_timings:        eval time =  7449.62 ms /   178 runs   (   41.85 ms per token,    23.89 tokens per second)\n",
      "llama_print_timings:       total time =  9710.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    88.65 ms /   126 runs   (    0.70 ms per token,  1421.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2518.17 ms /   502 tokens (    5.02 ms per token,   199.35 tokens per second)\n",
      "llama_print_timings:        eval time =  5195.86 ms /   125 runs   (   41.57 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:       total time =  7942.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.67 ms /   157 runs   (    0.71 ms per token,  1405.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1146.80 ms /   250 tokens (    4.59 ms per token,   218.00 tokens per second)\n",
      "llama_print_timings:        eval time =  6516.10 ms /   156 runs   (   41.77 ms per token,    23.94 tokens per second)\n",
      "llama_print_timings:       total time =  7960.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   100.55 ms /   141 runs   (    0.71 ms per token,  1402.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   305.69 ms /    52 tokens (    5.88 ms per token,   170.10 tokens per second)\n",
      "llama_print_timings:        eval time =  5718.65 ms /   140 runs   (   40.85 ms per token,    24.48 tokens per second)\n",
      "llama_print_timings:       total time =  6277.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   172.41 ms /   239 runs   (    0.72 ms per token,  1386.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2719.20 ms /   556 tokens (    4.89 ms per token,   204.47 tokens per second)\n",
      "llama_print_timings:        eval time = 10068.41 ms /   238 runs   (   42.30 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time = 13232.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.82 ms /   256 runs   (    0.71 ms per token,  1407.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2607.69 ms /   540 tokens (    4.83 ms per token,   207.08 tokens per second)\n",
      "llama_print_timings:        eval time = 10841.49 ms /   255 runs   (   42.52 ms per token,    23.52 tokens per second)\n",
      "llama_print_timings:       total time = 13940.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.50 ms /   250 runs   (    0.71 ms per token,  1408.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2608.55 ms /   532 tokens (    4.90 ms per token,   203.94 tokens per second)\n",
      "llama_print_timings:        eval time = 10617.50 ms /   249 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time = 13699.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.09 ms /   178 runs   (    0.71 ms per token,  1400.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1144.81 ms /   245 tokens (    4.67 ms per token,   214.01 tokens per second)\n",
      "llama_print_timings:        eval time =  7340.41 ms /   177 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =  8816.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.23 ms /   222 runs   (    0.72 ms per token,  1394.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2726.70 ms /   553 tokens (    4.93 ms per token,   202.81 tokens per second)\n",
      "llama_print_timings:        eval time =  9561.09 ms /   221 runs   (   43.26 ms per token,    23.11 tokens per second)\n",
      "llama_print_timings:       total time = 12711.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.33 ms /   256 runs   (    0.70 ms per token,  1419.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1292.20 ms /   284 tokens (    4.55 ms per token,   219.78 tokens per second)\n",
      "llama_print_timings:        eval time = 10855.71 ms /   255 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 12638.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.83 ms /   256 runs   (    0.71 ms per token,  1407.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2454.34 ms /   500 tokens (    4.91 ms per token,   203.72 tokens per second)\n",
      "llama_print_timings:        eval time = 10907.24 ms /   255 runs   (   42.77 ms per token,    23.38 tokens per second)\n",
      "llama_print_timings:       total time = 13842.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   160.61 ms /   222 runs   (    0.72 ms per token,  1382.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   877.11 ms /   187 tokens (    4.69 ms per token,   213.20 tokens per second)\n",
      "llama_print_timings:        eval time =  9127.82 ms /   221 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
      "llama_print_timings:       total time = 10412.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   100.56 ms /   137 runs   (    0.73 ms per token,  1362.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   310.14 ms /    59 tokens (    5.26 ms per token,   190.24 tokens per second)\n",
      "llama_print_timings:        eval time =  5549.47 ms /   136 runs   (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  6108.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.18 ms /   184 runs   (    0.71 ms per token,  1402.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   575.89 ms /   123 tokens (    4.68 ms per token,   213.58 tokens per second)\n",
      "llama_print_timings:        eval time =  7591.18 ms /   183 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =  8507.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.05 ms /   149 runs   (    0.71 ms per token,  1418.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2666.98 ms /   540 tokens (    4.94 ms per token,   202.48 tokens per second)\n",
      "llama_print_timings:        eval time =  6241.72 ms /   148 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time =  9187.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.36 ms /   204 runs   (    0.70 ms per token,  1423.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2183.51 ms /   441 tokens (    4.95 ms per token,   201.97 tokens per second)\n",
      "llama_print_timings:        eval time =  8705.24 ms /   203 runs   (   42.88 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time = 11272.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.60 ms /   184 runs   (    0.70 ms per token,  1419.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3016.55 ms /   595 tokens (    5.07 ms per token,   197.25 tokens per second)\n",
      "llama_print_timings:        eval time =  7837.44 ms /   183 runs   (   42.83 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time = 11202.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   137.07 ms /   193 runs   (    0.71 ms per token,  1408.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2964.69 ms /   600 tokens (    4.94 ms per token,   202.38 tokens per second)\n",
      "llama_print_timings:        eval time =  8120.69 ms /   192 runs   (   42.30 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time = 11443.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.49 ms /   168 runs   (    0.71 ms per token,  1405.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3046.65 ms /   596 tokens (    5.11 ms per token,   195.62 tokens per second)\n",
      "llama_print_timings:        eval time =  7245.18 ms /   167 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
      "llama_print_timings:       total time = 10617.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.78 ms /   167 runs   (    0.71 ms per token,  1417.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2941.34 ms /   596 tokens (    4.94 ms per token,   202.63 tokens per second)\n",
      "llama_print_timings:        eval time =  7000.37 ms /   166 runs   (   42.17 ms per token,    23.71 tokens per second)\n",
      "llama_print_timings:       total time = 10252.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   152.56 ms /   215 runs   (    0.71 ms per token,  1409.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2972.76 ms /   606 tokens (    4.91 ms per token,   203.85 tokens per second)\n",
      "llama_print_timings:        eval time =  9116.95 ms /   214 runs   (   42.60 ms per token,    23.47 tokens per second)\n",
      "llama_print_timings:       total time = 12491.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.11 ms /   176 runs   (    0.70 ms per token,  1429.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3681.20 ms /   765 tokens (    4.81 ms per token,   207.81 tokens per second)\n",
      "llama_print_timings:        eval time =  7728.38 ms /   175 runs   (   44.16 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time = 11740.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   122.23 ms /   172 runs   (    0.71 ms per token,  1407.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3498.22 ms /   711 tokens (    4.92 ms per token,   203.25 tokens per second)\n",
      "llama_print_timings:        eval time =  7454.89 ms /   171 runs   (   43.60 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time = 11285.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.09 ms /   155 runs   (    0.72 ms per token,  1395.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2719.18 ms /   537 tokens (    5.06 ms per token,   197.49 tokens per second)\n",
      "llama_print_timings:        eval time =  6445.12 ms /   154 runs   (   41.85 ms per token,    23.89 tokens per second)\n",
      "llama_print_timings:       total time =  9447.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.46 ms /   178 runs   (    0.70 ms per token,  1418.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   855.59 ms /   170 tokens (    5.03 ms per token,   198.69 tokens per second)\n",
      "llama_print_timings:        eval time =  7439.22 ms /   177 runs   (   42.03 ms per token,    23.79 tokens per second)\n",
      "llama_print_timings:       total time =  8628.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.24 ms /   256 runs   (    0.70 ms per token,  1420.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1910.17 ms /   405 tokens (    4.72 ms per token,   212.02 tokens per second)\n",
      "llama_print_timings:        eval time = 10876.26 ms /   255 runs   (   42.65 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time = 13273.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.23 ms /   256 runs   (    0.71 ms per token,  1404.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2095.28 ms /   438 tokens (    4.78 ms per token,   209.04 tokens per second)\n",
      "llama_print_timings:        eval time = 10873.97 ms /   255 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time = 13454.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.95 ms /   256 runs   (    0.71 ms per token,  1399.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2064.62 ms /   419 tokens (    4.93 ms per token,   202.94 tokens per second)\n",
      "llama_print_timings:        eval time = 10856.62 ms /   255 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 13407.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   179.63 ms /   255 runs   (    0.70 ms per token,  1419.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1421.84 ms /   302 tokens (    4.71 ms per token,   212.40 tokens per second)\n",
      "llama_print_timings:        eval time = 10649.98 ms /   254 runs   (   41.93 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time = 12556.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   126.47 ms /   179 runs   (    0.71 ms per token,  1415.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   575.87 ms /    98 tokens (    5.88 ms per token,   170.18 tokens per second)\n",
      "llama_print_timings:        eval time =  7410.16 ms /   178 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =  8323.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.43 ms /   256 runs   (    0.71 ms per token,  1403.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1160.16 ms /   238 tokens (    4.87 ms per token,   205.14 tokens per second)\n",
      "llama_print_timings:        eval time = 10625.84 ms /   255 runs   (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_print_timings:       total time = 12267.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.28 ms /   256 runs   (    0.71 ms per token,  1412.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1738.90 ms /   369 tokens (    4.71 ms per token,   212.20 tokens per second)\n",
      "llama_print_timings:        eval time = 10692.87 ms /   255 runs   (   41.93 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time = 12917.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.51 ms /   209 runs   (    0.70 ms per token,  1426.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2835.04 ms /   565 tokens (    5.02 ms per token,   199.29 tokens per second)\n",
      "llama_print_timings:        eval time =  8874.96 ms /   208 runs   (   42.67 ms per token,    23.44 tokens per second)\n",
      "llama_print_timings:       total time = 12105.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   140.20 ms /   197 runs   (    0.71 ms per token,  1405.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1732.30 ms /   376 tokens (    4.61 ms per token,   217.05 tokens per second)\n",
      "llama_print_timings:        eval time =  8156.31 ms /   196 runs   (   41.61 ms per token,    24.03 tokens per second)\n",
      "llama_print_timings:       total time = 10250.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   112.90 ms /   159 runs   (    0.71 ms per token,  1408.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   578.10 ms /   127 tokens (    4.55 ms per token,   219.69 tokens per second)\n",
      "llama_print_timings:        eval time =  6528.01 ms /   158 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_print_timings:       total time =  7403.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.74 ms /   217 runs   (    0.71 ms per token,  1411.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2957.07 ms /   597 tokens (    4.95 ms per token,   201.89 tokens per second)\n",
      "llama_print_timings:        eval time =  9139.59 ms /   216 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time = 12499.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.35 ms /   256 runs   (    0.71 ms per token,  1411.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2977.30 ms /   581 tokens (    5.12 ms per token,   195.14 tokens per second)\n",
      "llama_print_timings:        eval time = 10854.48 ms /   255 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 14316.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   124.07 ms /   173 runs   (    0.72 ms per token,  1394.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1010.12 ms /   218 tokens (    4.63 ms per token,   215.82 tokens per second)\n",
      "llama_print_timings:        eval time =  7071.36 ms /   172 runs   (   41.11 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:       total time =  8406.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.43 ms /   256 runs   (    0.71 ms per token,  1403.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2403.38 ms /   505 tokens (    4.76 ms per token,   210.12 tokens per second)\n",
      "llama_print_timings:        eval time = 10856.49 ms /   255 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 13740.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   158.13 ms /   221 runs   (    0.72 ms per token,  1397.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1590.97 ms /   333 tokens (    4.78 ms per token,   209.31 tokens per second)\n",
      "llama_print_timings:        eval time =  9187.16 ms /   220 runs   (   41.76 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time = 11187.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   179.29 ms /   256 runs   (    0.70 ms per token,  1427.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1301.68 ms /   268 tokens (    4.86 ms per token,   205.89 tokens per second)\n",
      "llama_print_timings:        eval time = 10674.60 ms /   255 runs   (   41.86 ms per token,    23.89 tokens per second)\n",
      "llama_print_timings:       total time = 12453.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   179.77 ms /   256 runs   (    0.70 ms per token,  1424.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1437.98 ms /   300 tokens (    4.79 ms per token,   208.63 tokens per second)\n",
      "llama_print_timings:        eval time = 10769.40 ms /   255 runs   (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_print_timings:       total time = 12693.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.83 ms /   179 runs   (    0.71 ms per token,  1400.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1613.64 ms /   346 tokens (    4.66 ms per token,   214.42 tokens per second)\n",
      "llama_print_timings:        eval time =  7370.49 ms /   178 runs   (   41.41 ms per token,    24.15 tokens per second)\n",
      "llama_print_timings:       total time =  9310.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.90 ms /   182 runs   (    0.71 ms per token,  1401.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   985.04 ms /   195 tokens (    5.05 ms per token,   197.96 tokens per second)\n",
      "llama_print_timings:        eval time =  7441.57 ms /   181 runs   (   41.11 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:       total time =  8757.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   136.27 ms /   194 runs   (    0.70 ms per token,  1423.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2383.60 ms /   505 tokens (    4.72 ms per token,   211.86 tokens per second)\n",
      "llama_print_timings:        eval time =  8073.68 ms /   193 runs   (   41.83 ms per token,    23.90 tokens per second)\n",
      "llama_print_timings:       total time = 10808.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.43 ms /   256 runs   (    0.72 ms per token,  1395.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1599.13 ms /   339 tokens (    4.72 ms per token,   211.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10660.45 ms /   255 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time = 12737.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.61 ms /   248 runs   (    0.71 ms per token,  1404.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2858.92 ms /   578 tokens (    4.95 ms per token,   202.17 tokens per second)\n",
      "llama_print_timings:        eval time = 10508.45 ms /   247 runs   (   42.54 ms per token,    23.50 tokens per second)\n",
      "llama_print_timings:       total time = 13836.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   175.74 ms /   245 runs   (    0.72 ms per token,  1394.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1749.22 ms /   379 tokens (    4.62 ms per token,   216.67 tokens per second)\n",
      "llama_print_timings:        eval time = 10224.76 ms /   244 runs   (   41.90 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time = 12424.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    91.03 ms /   130 runs   (    0.70 ms per token,  1428.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   443.85 ms /    65 tokens (    6.83 ms per token,   146.45 tokens per second)\n",
      "llama_print_timings:        eval time =  5243.53 ms /   129 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  5923.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.50 ms /   168 runs   (    0.71 ms per token,  1417.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1027.79 ms /   219 tokens (    4.69 ms per token,   213.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6922.14 ms /   167 runs   (   41.45 ms per token,    24.13 tokens per second)\n",
      "llama_print_timings:       total time =  8263.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.30 ms /   181 runs   (    0.71 ms per token,  1399.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2947.25 ms /   591 tokens (    4.99 ms per token,   200.53 tokens per second)\n",
      "llama_print_timings:        eval time =  7605.80 ms /   180 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time = 10886.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.38 ms /   256 runs   (    0.70 ms per token,  1419.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2925.67 ms /   604 tokens (    4.84 ms per token,   206.45 tokens per second)\n",
      "llama_print_timings:        eval time = 10987.81 ms /   255 runs   (   43.09 ms per token,    23.21 tokens per second)\n",
      "llama_print_timings:       total time = 14396.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.15 ms /   256 runs   (    0.72 ms per token,  1397.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2800.59 ms /   568 tokens (    4.93 ms per token,   202.81 tokens per second)\n",
      "llama_print_timings:        eval time = 10902.15 ms /   255 runs   (   42.75 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time = 14180.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   134.55 ms /   190 runs   (    0.71 ms per token,  1412.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2939.03 ms /   600 tokens (    4.90 ms per token,   204.15 tokens per second)\n",
      "llama_print_timings:        eval time =  8128.55 ms /   189 runs   (   43.01 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:       total time = 11422.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.14 ms /   256 runs   (    0.71 ms per token,  1413.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2734.62 ms /   564 tokens (    4.85 ms per token,   206.24 tokens per second)\n",
      "llama_print_timings:        eval time = 11097.39 ms /   255 runs   (   43.52 ms per token,    22.98 tokens per second)\n",
      "llama_print_timings:       total time = 14320.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.21 ms /   256 runs   (    0.69 ms per token,  1444.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2878.15 ms /   583 tokens (    4.94 ms per token,   202.56 tokens per second)\n",
      "llama_print_timings:        eval time = 10934.48 ms /   255 runs   (   42.88 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time = 14294.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.27 ms /   178 runs   (    0.74 ms per token,  1355.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2895.61 ms /   583 tokens (    4.97 ms per token,   201.34 tokens per second)\n",
      "llama_print_timings:        eval time =  7422.78 ms /   177 runs   (   41.94 ms per token,    23.85 tokens per second)\n",
      "llama_print_timings:       total time = 10653.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.51 ms /   239 runs   (    0.70 ms per token,  1426.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2994.32 ms /   591 tokens (    5.07 ms per token,   197.37 tokens per second)\n",
      "llama_print_timings:        eval time = 10125.95 ms /   238 runs   (   42.55 ms per token,    23.50 tokens per second)\n",
      "llama_print_timings:       total time = 13556.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.03 ms /   210 runs   (    0.69 ms per token,  1458.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2721.91 ms /   556 tokens (    4.90 ms per token,   204.27 tokens per second)\n",
      "llama_print_timings:        eval time =  8871.22 ms /   209 runs   (   42.45 ms per token,    23.56 tokens per second)\n",
      "llama_print_timings:       total time = 11982.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.16 ms /   256 runs   (    0.71 ms per token,  1413.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2910.78 ms /   601 tokens (    4.84 ms per token,   206.47 tokens per second)\n",
      "llama_print_timings:        eval time = 10919.07 ms /   255 runs   (   42.82 ms per token,    23.35 tokens per second)\n",
      "llama_print_timings:       total time = 14312.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.00 ms /   215 runs   (    0.71 ms per token,  1405.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2922.93 ms /   605 tokens (    4.83 ms per token,   206.98 tokens per second)\n",
      "llama_print_timings:        eval time =  9089.53 ms /   214 runs   (   42.47 ms per token,    23.54 tokens per second)\n",
      "llama_print_timings:       total time = 12414.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.69 ms /   204 runs   (    0.72 ms per token,  1381.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2893.37 ms /   581 tokens (    4.98 ms per token,   200.80 tokens per second)\n",
      "llama_print_timings:        eval time =  8619.60 ms /   203 runs   (   42.46 ms per token,    23.55 tokens per second)\n",
      "llama_print_timings:       total time = 11905.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.33 ms /   222 runs   (    0.72 ms per token,  1393.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2755.29 ms /   568 tokens (    4.85 ms per token,   206.15 tokens per second)\n",
      "llama_print_timings:        eval time =  9363.87 ms /   221 runs   (   42.37 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time = 12535.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   163.15 ms /   227 runs   (    0.72 ms per token,  1391.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2879.84 ms /   584 tokens (    4.93 ms per token,   202.79 tokens per second)\n",
      "llama_print_timings:        eval time =  9695.17 ms /   226 runs   (   42.90 ms per token,    23.31 tokens per second)\n",
      "llama_print_timings:       total time = 13020.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.51 ms /   144 runs   (    0.72 ms per token,  1391.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2930.61 ms /   591 tokens (    4.96 ms per token,   201.66 tokens per second)\n",
      "llama_print_timings:        eval time =  5940.83 ms /   143 runs   (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_print_timings:       total time =  9135.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.41 ms /   178 runs   (    0.72 ms per token,  1397.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2905.22 ms /   580 tokens (    5.01 ms per token,   199.64 tokens per second)\n",
      "llama_print_timings:        eval time =  7445.74 ms /   177 runs   (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_print_timings:       total time = 10681.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   154.20 ms /   216 runs   (    0.71 ms per token,  1400.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2986.81 ms /   594 tokens (    5.03 ms per token,   198.87 tokens per second)\n",
      "llama_print_timings:        eval time =  9187.21 ms /   215 runs   (   42.73 ms per token,    23.40 tokens per second)\n",
      "llama_print_timings:       total time = 12585.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.62 ms /   256 runs   (    0.71 ms per token,  1401.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2843.56 ms /   575 tokens (    4.95 ms per token,   202.21 tokens per second)\n",
      "llama_print_timings:        eval time = 11054.51 ms /   255 runs   (   43.35 ms per token,    23.07 tokens per second)\n",
      "llama_print_timings:       total time = 14380.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.14 ms /   242 runs   (    0.72 ms per token,  1397.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2895.62 ms /   592 tokens (    4.89 ms per token,   204.45 tokens per second)\n",
      "llama_print_timings:        eval time = 10284.03 ms /   241 runs   (   42.67 ms per token,    23.43 tokens per second)\n",
      "llama_print_timings:       total time = 13631.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.37 ms /   223 runs   (    0.71 ms per token,  1399.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2930.70 ms /   603 tokens (    4.86 ms per token,   205.75 tokens per second)\n",
      "llama_print_timings:        eval time =  9498.79 ms /   222 runs   (   42.79 ms per token,    23.37 tokens per second)\n",
      "llama_print_timings:       total time = 12859.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.05 ms /   223 runs   (    0.70 ms per token,  1419.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2950.55 ms /   589 tokens (    5.01 ms per token,   199.62 tokens per second)\n",
      "llama_print_timings:        eval time =  9449.84 ms /   222 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 12816.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.50 ms /   197 runs   (    0.72 ms per token,  1392.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2884.14 ms /   579 tokens (    4.98 ms per token,   200.75 tokens per second)\n",
      "llama_print_timings:        eval time =  8280.10 ms /   196 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time = 11538.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.67 ms /   168 runs   (    0.70 ms per token,  1427.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2945.38 ms /   598 tokens (    4.93 ms per token,   203.03 tokens per second)\n",
      "llama_print_timings:        eval time =  7005.94 ms /   167 runs   (   41.95 ms per token,    23.84 tokens per second)\n",
      "llama_print_timings:       total time = 10263.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.09 ms /   256 runs   (    0.72 ms per token,  1398.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2816.15 ms /   554 tokens (    5.08 ms per token,   196.72 tokens per second)\n",
      "llama_print_timings:        eval time = 10844.96 ms /   255 runs   (   42.53 ms per token,    23.51 tokens per second)\n",
      "llama_print_timings:       total time = 14146.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.50 ms /   199 runs   (    0.71 ms per token,  1406.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2898.68 ms /   603 tokens (    4.81 ms per token,   208.03 tokens per second)\n",
      "llama_print_timings:        eval time =  8331.84 ms /   198 runs   (   42.08 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:       total time = 11594.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   126.51 ms /   178 runs   (    0.71 ms per token,  1407.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2907.11 ms /   595 tokens (    4.89 ms per token,   204.67 tokens per second)\n",
      "llama_print_timings:        eval time =  7424.22 ms /   177 runs   (   41.94 ms per token,    23.84 tokens per second)\n",
      "llama_print_timings:       total time = 10655.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   169.20 ms /   237 runs   (    0.71 ms per token,  1400.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2910.46 ms /   583 tokens (    4.99 ms per token,   200.31 tokens per second)\n",
      "llama_print_timings:        eval time = 10073.39 ms /   236 runs   (   42.68 ms per token,    23.43 tokens per second)\n",
      "llama_print_timings:       total time = 13432.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.16 ms /   256 runs   (    0.72 ms per token,  1390.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3110.66 ms /   613 tokens (    5.07 ms per token,   197.06 tokens per second)\n",
      "llama_print_timings:        eval time = 10994.05 ms /   255 runs   (   43.11 ms per token,    23.19 tokens per second)\n",
      "llama_print_timings:       total time = 14604.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.88 ms /   167 runs   (    0.72 ms per token,  1393.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2975.01 ms /   608 tokens (    4.89 ms per token,   204.37 tokens per second)\n",
      "llama_print_timings:        eval time =  6924.93 ms /   166 runs   (   41.72 ms per token,    23.97 tokens per second)\n",
      "llama_print_timings:       total time = 10209.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.88 ms /   220 runs   (    0.71 ms per token,  1402.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3009.33 ms /   612 tokens (    4.92 ms per token,   203.37 tokens per second)\n",
      "llama_print_timings:        eval time =  9253.35 ms /   219 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time = 12670.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.37 ms /   251 runs   (    0.70 ms per token,  1423.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2895.53 ms /   597 tokens (    4.85 ms per token,   206.18 tokens per second)\n",
      "llama_print_timings:        eval time = 10643.20 ms /   250 runs   (   42.57 ms per token,    23.49 tokens per second)\n",
      "llama_print_timings:       total time = 14008.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.37 ms /   157 runs   (    0.71 ms per token,  1409.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2752.55 ms /   556 tokens (    4.95 ms per token,   201.99 tokens per second)\n",
      "llama_print_timings:        eval time =  6493.57 ms /   156 runs   (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:       total time =  9539.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.20 ms /   248 runs   (    0.71 ms per token,  1399.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2748.34 ms /   571 tokens (    4.81 ms per token,   207.76 tokens per second)\n",
      "llama_print_timings:        eval time = 10484.00 ms /   247 runs   (   42.45 ms per token,    23.56 tokens per second)\n",
      "llama_print_timings:       total time = 13695.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.58 ms /   256 runs   (    0.72 ms per token,  1386.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2712.99 ms /   576 tokens (    4.71 ms per token,   212.31 tokens per second)\n",
      "llama_print_timings:        eval time = 10804.61 ms /   255 runs   (   42.37 ms per token,    23.60 tokens per second)\n",
      "llama_print_timings:       total time = 13999.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   130.95 ms /   183 runs   (    0.72 ms per token,  1397.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2861.45 ms /   582 tokens (    4.92 ms per token,   203.39 tokens per second)\n",
      "llama_print_timings:        eval time =  7595.26 ms /   182 runs   (   41.73 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time = 10791.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   124.40 ms /   174 runs   (    0.71 ms per token,  1398.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2726.23 ms /   568 tokens (    4.80 ms per token,   208.35 tokens per second)\n",
      "llama_print_timings:        eval time =  7244.42 ms /   173 runs   (   41.88 ms per token,    23.88 tokens per second)\n",
      "llama_print_timings:       total time = 10296.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.59 ms /   146 runs   (    0.72 ms per token,  1395.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2982.64 ms /   598 tokens (    4.99 ms per token,   200.49 tokens per second)\n",
      "llama_print_timings:        eval time =  6076.71 ms /   145 runs   (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_print_timings:       total time =  9334.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   179.88 ms /   256 runs   (    0.70 ms per token,  1423.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2628.92 ms /   521 tokens (    5.05 ms per token,   198.18 tokens per second)\n",
      "llama_print_timings:        eval time = 10973.56 ms /   255 runs   (   43.03 ms per token,    23.24 tokens per second)\n",
      "llama_print_timings:       total time = 14099.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.91 ms /   256 runs   (    0.71 ms per token,  1407.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3254.08 ms /   648 tokens (    5.02 ms per token,   199.13 tokens per second)\n",
      "llama_print_timings:        eval time = 11031.77 ms /   255 runs   (   43.26 ms per token,    23.12 tokens per second)\n",
      "llama_print_timings:       total time = 14775.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   169.64 ms /   239 runs   (    0.71 ms per token,  1408.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2899.09 ms /   589 tokens (    4.92 ms per token,   203.17 tokens per second)\n",
      "llama_print_timings:        eval time = 10142.96 ms /   238 runs   (   42.62 ms per token,    23.46 tokens per second)\n",
      "llama_print_timings:       total time = 13505.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   178.28 ms /   256 runs   (    0.70 ms per token,  1435.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3032.22 ms /   595 tokens (    5.10 ms per token,   196.23 tokens per second)\n",
      "llama_print_timings:        eval time = 10923.45 ms /   255 runs   (   42.84 ms per token,    23.34 tokens per second)\n",
      "llama_print_timings:       total time = 14437.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   148.01 ms /   207 runs   (    0.72 ms per token,  1398.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2762.05 ms /   575 tokens (    4.80 ms per token,   208.18 tokens per second)\n",
      "llama_print_timings:        eval time =  8678.00 ms /   206 runs   (   42.13 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time = 11834.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.25 ms /   256 runs   (    0.72 ms per token,  1389.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2653.84 ms /   536 tokens (    4.95 ms per token,   201.97 tokens per second)\n",
      "llama_print_timings:        eval time = 10795.35 ms /   255 runs   (   42.33 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:       total time = 13937.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.50 ms /   222 runs   (    0.71 ms per token,  1409.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2876.65 ms /   604 tokens (    4.76 ms per token,   209.97 tokens per second)\n",
      "llama_print_timings:        eval time =  9308.87 ms /   221 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time = 12599.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.79 ms /   234 runs   (    0.72 ms per token,  1394.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3003.62 ms /   612 tokens (    4.91 ms per token,   203.75 tokens per second)\n",
      "llama_print_timings:        eval time =  9838.02 ms /   233 runs   (   42.22 ms per token,    23.68 tokens per second)\n",
      "llama_print_timings:       total time = 13278.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.38 ms /   256 runs   (    0.72 ms per token,  1395.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2879.83 ms /   590 tokens (    4.88 ms per token,   204.87 tokens per second)\n",
      "llama_print_timings:        eval time = 10837.12 ms /   255 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time = 14200.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.34 ms /   198 runs   (    0.72 ms per token,  1381.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3045.19 ms /   611 tokens (    4.98 ms per token,   200.64 tokens per second)\n",
      "llama_print_timings:        eval time =  8391.93 ms /   197 runs   (   42.60 ms per token,    23.47 tokens per second)\n",
      "llama_print_timings:       total time = 11819.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   176.44 ms /   244 runs   (    0.72 ms per token,  1382.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2914.30 ms /   599 tokens (    4.87 ms per token,   205.54 tokens per second)\n",
      "llama_print_timings:        eval time = 10316.09 ms /   243 runs   (   42.45 ms per token,    23.56 tokens per second)\n",
      "llama_print_timings:       total time = 13707.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.98 ms /   163 runs   (    0.73 ms per token,  1369.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3017.80 ms /   626 tokens (    4.82 ms per token,   207.44 tokens per second)\n",
      "llama_print_timings:        eval time =  6753.01 ms /   162 runs   (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_print_timings:       total time = 10076.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.12 ms /   242 runs   (    0.73 ms per token,  1366.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2917.55 ms /   603 tokens (    4.84 ms per token,   206.68 tokens per second)\n",
      "llama_print_timings:        eval time = 10196.11 ms /   241 runs   (   42.31 ms per token,    23.64 tokens per second)\n",
      "llama_print_timings:       total time = 13584.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.79 ms /   256 runs   (    0.73 ms per token,  1370.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2889.14 ms /   592 tokens (    4.88 ms per token,   204.90 tokens per second)\n",
      "llama_print_timings:        eval time = 10959.36 ms /   255 runs   (   42.98 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time = 14354.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   154.13 ms /   213 runs   (    0.72 ms per token,  1381.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3162.65 ms /   616 tokens (    5.13 ms per token,   194.77 tokens per second)\n",
      "llama_print_timings:        eval time =  9096.81 ms /   212 runs   (   42.91 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time = 12680.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.13 ms /   202 runs   (    0.73 ms per token,  1372.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2940.99 ms /   597 tokens (    4.93 ms per token,   202.99 tokens per second)\n",
      "llama_print_timings:        eval time =  8436.97 ms /   201 runs   (   41.97 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time = 11771.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   147.49 ms /   211 runs   (    0.70 ms per token,  1430.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2984.60 ms /   587 tokens (    5.08 ms per token,   196.68 tokens per second)\n",
      "llama_print_timings:        eval time =  9012.73 ms /   210 runs   (   42.92 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time = 12401.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.08 ms /   252 runs   (    0.73 ms per token,  1376.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2888.50 ms /   608 tokens (    4.75 ms per token,   210.49 tokens per second)\n",
      "llama_print_timings:        eval time = 10620.89 ms /   251 runs   (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_print_timings:       total time = 13989.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   165.76 ms /   233 runs   (    0.71 ms per token,  1405.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2873.21 ms /   594 tokens (    4.84 ms per token,   206.74 tokens per second)\n",
      "llama_print_timings:        eval time = 10004.88 ms /   232 runs   (   43.12 ms per token,    23.19 tokens per second)\n",
      "llama_print_timings:       total time = 13327.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.18 ms /   178 runs   (    0.72 ms per token,  1388.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2929.49 ms /   584 tokens (    5.02 ms per token,   199.35 tokens per second)\n",
      "llama_print_timings:        eval time =  7444.19 ms /   177 runs   (   42.06 ms per token,    23.78 tokens per second)\n",
      "llama_print_timings:       total time = 10710.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.26 ms /   181 runs   (    0.71 ms per token,  1411.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2988.04 ms /   588 tokens (    5.08 ms per token,   196.78 tokens per second)\n",
      "llama_print_timings:        eval time =  7579.97 ms /   180 runs   (   42.11 ms per token,    23.75 tokens per second)\n",
      "llama_print_timings:       total time = 10903.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   172.74 ms /   244 runs   (    0.71 ms per token,  1412.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2717.42 ms /   552 tokens (    4.92 ms per token,   203.13 tokens per second)\n",
      "llama_print_timings:        eval time = 10255.99 ms /   243 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time = 13430.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.34 ms /   256 runs   (    0.71 ms per token,  1403.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2848.05 ms /   578 tokens (    4.93 ms per token,   202.95 tokens per second)\n",
      "llama_print_timings:        eval time = 10813.93 ms /   255 runs   (   42.41 ms per token,    23.58 tokens per second)\n",
      "llama_print_timings:       total time = 14143.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   140.07 ms /   194 runs   (    0.72 ms per token,  1385.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1532.88 ms /   327 tokens (    4.69 ms per token,   213.32 tokens per second)\n",
      "llama_print_timings:        eval time =  7976.03 ms /   193 runs   (   41.33 ms per token,    24.20 tokens per second)\n",
      "llama_print_timings:       total time =  9862.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.42 ms /   162 runs   (    0.71 ms per token,  1403.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2591.92 ms /   530 tokens (    4.89 ms per token,   204.48 tokens per second)\n",
      "llama_print_timings:        eval time =  6663.35 ms /   161 runs   (   41.39 ms per token,    24.16 tokens per second)\n",
      "llama_print_timings:       total time =  9548.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    97.56 ms /   137 runs   (    0.71 ms per token,  1404.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2223.34 ms /   475 tokens (    4.68 ms per token,   213.64 tokens per second)\n",
      "llama_print_timings:        eval time =  5640.28 ms /   136 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =  8112.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   149.84 ms /   208 runs   (    0.72 ms per token,  1388.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   850.92 ms /   175 tokens (    4.86 ms per token,   205.66 tokens per second)\n",
      "llama_print_timings:        eval time =  8514.88 ms /   207 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
      "llama_print_timings:       total time =  9748.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.87 ms /   166 runs   (    0.73 ms per token,  1373.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   449.72 ms /    69 tokens (    6.52 ms per token,   153.43 tokens per second)\n",
      "llama_print_timings:        eval time =  6711.86 ms /   165 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =  7464.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.03 ms /   198 runs   (    0.72 ms per token,  1384.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   564.59 ms /   112 tokens (    5.04 ms per token,   198.37 tokens per second)\n",
      "llama_print_timings:        eval time =  8053.24 ms /   197 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  8984.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    90.97 ms /   128 runs   (    0.71 ms per token,  1407.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   295.57 ms /    34 tokens (    8.69 ms per token,   115.03 tokens per second)\n",
      "llama_print_timings:        eval time =  5134.53 ms /   127 runs   (   40.43 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:       total time =  5665.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.22 ms /   196 runs   (    0.73 ms per token,  1368.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   465.68 ms /    96 tokens (    4.85 ms per token,   206.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7957.48 ms /   195 runs   (   40.81 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:       total time =  8788.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.98 ms /   218 runs   (    0.72 ms per token,  1388.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1271.08 ms /   280 tokens (    4.54 ms per token,   220.29 tokens per second)\n",
      "llama_print_timings:        eval time =  8989.03 ms /   217 runs   (   41.42 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:       total time = 10661.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.89 ms /   256 runs   (    0.73 ms per token,  1369.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1137.03 ms /   242 tokens (    4.70 ms per token,   212.84 tokens per second)\n",
      "llama_print_timings:        eval time = 10540.51 ms /   255 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time = 12157.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.55 ms /   201 runs   (    0.70 ms per token,  1419.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1396.86 ms /   293 tokens (    4.77 ms per token,   209.76 tokens per second)\n",
      "llama_print_timings:        eval time =  8263.47 ms /   200 runs   (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_print_timings:       total time = 10025.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.61 ms /   256 runs   (    0.71 ms per token,  1409.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2330.82 ms /   485 tokens (    4.81 ms per token,   208.08 tokens per second)\n",
      "llama_print_timings:        eval time = 10799.03 ms /   255 runs   (   42.35 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time = 13607.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.82 ms /   164 runs   (    0.71 ms per token,  1403.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1286.69 ms /   274 tokens (    4.70 ms per token,   212.95 tokens per second)\n",
      "llama_print_timings:        eval time =  6722.38 ms /   163 runs   (   41.24 ms per token,    24.25 tokens per second)\n",
      "llama_print_timings:       total time =  8305.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.02 ms /   165 runs   (    0.71 ms per token,  1409.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1142.62 ms /   247 tokens (    4.63 ms per token,   216.17 tokens per second)\n",
      "llama_print_timings:        eval time =  6771.97 ms /   164 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =  8214.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   173.53 ms /   247 runs   (    0.70 ms per token,  1423.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1471.55 ms /   313 tokens (    4.70 ms per token,   212.70 tokens per second)\n",
      "llama_print_timings:        eval time = 10361.02 ms /   246 runs   (   42.12 ms per token,    23.74 tokens per second)\n",
      "llama_print_timings:       total time = 12295.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.20 ms /   159 runs   (    0.71 ms per token,  1404.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   716.10 ms /   136 tokens (    5.27 ms per token,   189.92 tokens per second)\n",
      "llama_print_timings:        eval time =  6545.73 ms /   158 runs   (   41.43 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:       total time =  7551.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.89 ms /   198 runs   (    0.72 ms per token,  1395.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2881.36 ms /   581 tokens (    4.96 ms per token,   201.64 tokens per second)\n",
      "llama_print_timings:        eval time =  8271.29 ms /   197 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time = 11520.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.34 ms /   147 runs   (    0.72 ms per token,  1395.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3029.34 ms /   617 tokens (    4.91 ms per token,   203.67 tokens per second)\n",
      "llama_print_timings:        eval time =  6094.04 ms /   146 runs   (   41.74 ms per token,    23.96 tokens per second)\n",
      "llama_print_timings:       total time =  9392.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   130.67 ms /   182 runs   (    0.72 ms per token,  1392.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2620.35 ms /   520 tokens (    5.04 ms per token,   198.45 tokens per second)\n",
      "llama_print_timings:        eval time =  7581.82 ms /   181 runs   (   41.89 ms per token,    23.87 tokens per second)\n",
      "llama_print_timings:       total time = 10535.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   138.01 ms /   193 runs   (    0.72 ms per token,  1398.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2417.94 ms /   509 tokens (    4.75 ms per token,   210.51 tokens per second)\n",
      "llama_print_timings:        eval time =  8058.38 ms /   192 runs   (   41.97 ms per token,    23.83 tokens per second)\n",
      "llama_print_timings:       total time = 10827.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.46 ms /   256 runs   (    0.71 ms per token,  1403.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2380.09 ms /   502 tokens (    4.74 ms per token,   210.92 tokens per second)\n",
      "llama_print_timings:        eval time = 10927.99 ms /   255 runs   (   42.85 ms per token,    23.33 tokens per second)\n",
      "llama_print_timings:       total time = 13788.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   187.06 ms /   256 runs   (    0.73 ms per token,  1368.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2212.50 ms /   480 tokens (    4.61 ms per token,   216.95 tokens per second)\n",
      "llama_print_timings:        eval time = 10711.58 ms /   255 runs   (   42.01 ms per token,    23.81 tokens per second)\n",
      "llama_print_timings:       total time = 13404.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.17 ms /   141 runs   (    0.72 ms per token,  1380.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   296.46 ms /    52 tokens (    5.70 ms per token,   175.41 tokens per second)\n",
      "llama_print_timings:        eval time =  5671.00 ms /   140 runs   (   40.51 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:       total time =  6224.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.24 ms /   179 runs   (    0.72 ms per token,  1385.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2141.89 ms /   452 tokens (    4.74 ms per token,   211.03 tokens per second)\n",
      "llama_print_timings:        eval time =  7363.72 ms /   178 runs   (   41.37 ms per token,    24.17 tokens per second)\n",
      "llama_print_timings:       total time =  9835.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.53 ms /   145 runs   (    0.71 ms per token,  1400.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2402.08 ms /   510 tokens (    4.71 ms per token,   212.32 tokens per second)\n",
      "llama_print_timings:        eval time =  5935.22 ms /   144 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time =  8604.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.81 ms /   162 runs   (    0.71 ms per token,  1398.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1253.40 ms /   266 tokens (    4.71 ms per token,   212.22 tokens per second)\n",
      "llama_print_timings:        eval time =  6608.31 ms /   161 runs   (   41.05 ms per token,    24.36 tokens per second)\n",
      "llama_print_timings:       total time =  8153.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.87 ms /   129 runs   (    0.72 ms per token,  1389.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1268.98 ms /   258 tokens (    4.92 ms per token,   203.31 tokens per second)\n",
      "llama_print_timings:        eval time =  5230.58 ms /   128 runs   (   40.86 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:       total time =  6730.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.70 ms /   157 runs   (    0.72 ms per token,  1380.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1261.30 ms /   274 tokens (    4.60 ms per token,   217.24 tokens per second)\n",
      "llama_print_timings:        eval time =  6415.32 ms /   156 runs   (   41.12 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:       total time =  7965.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.88 ms /   156 runs   (    0.71 ms per token,  1406.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2911.05 ms /   605 tokens (    4.81 ms per token,   207.83 tokens per second)\n",
      "llama_print_timings:        eval time =  6481.29 ms /   155 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time =  9674.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.89 ms /   151 runs   (    0.71 ms per token,  1399.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2724.69 ms /   562 tokens (    4.85 ms per token,   206.26 tokens per second)\n",
      "llama_print_timings:        eval time =  6247.21 ms /   150 runs   (   41.65 ms per token,    24.01 tokens per second)\n",
      "llama_print_timings:       total time =  9245.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   130.18 ms /   184 runs   (    0.71 ms per token,  1413.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1912.25 ms /   411 tokens (    4.65 ms per token,   214.93 tokens per second)\n",
      "llama_print_timings:        eval time =  7647.31 ms /   183 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time =  9894.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.34 ms /   181 runs   (    0.70 ms per token,  1421.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1624.26 ms /   323 tokens (    5.03 ms per token,   198.86 tokens per second)\n",
      "llama_print_timings:        eval time =  7484.68 ms /   180 runs   (   41.58 ms per token,    24.05 tokens per second)\n",
      "llama_print_timings:       total time =  9440.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.63 ms /   122 runs   (    0.72 ms per token,  1392.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   701.51 ms /   130 tokens (    5.40 ms per token,   185.31 tokens per second)\n",
      "llama_print_timings:        eval time =  4937.82 ms /   121 runs   (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_print_timings:       total time =  5857.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    85.72 ms /   122 runs   (    0.70 ms per token,  1423.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   458.37 ms /    82 tokens (    5.59 ms per token,   178.89 tokens per second)\n",
      "llama_print_timings:        eval time =  4931.59 ms /   121 runs   (   40.76 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:       total time =  5607.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.45 ms /   166 runs   (    0.71 ms per token,  1401.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1442.29 ms /   306 tokens (    4.71 ms per token,   212.16 tokens per second)\n",
      "llama_print_timings:        eval time =  6813.20 ms /   165 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =  8558.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   164.13 ms /   230 runs   (    0.71 ms per token,  1401.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1766.53 ms /   380 tokens (    4.65 ms per token,   215.11 tokens per second)\n",
      "llama_print_timings:        eval time =  9578.51 ms /   229 runs   (   41.83 ms per token,    23.91 tokens per second)\n",
      "llama_print_timings:       total time = 11767.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.08 ms /   157 runs   (    0.70 ms per token,  1426.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1269.74 ms /   270 tokens (    4.70 ms per token,   212.64 tokens per second)\n",
      "llama_print_timings:        eval time =  6450.95 ms /   156 runs   (   41.35 ms per token,    24.18 tokens per second)\n",
      "llama_print_timings:       total time =  8011.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.87 ms /   149 runs   (    0.70 ms per token,  1420.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1783.87 ms /   362 tokens (    4.93 ms per token,   202.93 tokens per second)\n",
      "llama_print_timings:        eval time =  6137.81 ms /   148 runs   (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =  8192.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   145.18 ms /   204 runs   (    0.71 ms per token,  1405.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2230.37 ms /   463 tokens (    4.82 ms per token,   207.59 tokens per second)\n",
      "llama_print_timings:        eval time =  8544.01 ms /   203 runs   (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:       total time = 11151.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   148.29 ms /   210 runs   (    0.71 ms per token,  1416.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2048.05 ms /   441 tokens (    4.64 ms per token,   215.33 tokens per second)\n",
      "llama_print_timings:        eval time =  8733.82 ms /   209 runs   (   41.79 ms per token,    23.93 tokens per second)\n",
      "llama_print_timings:       total time = 11166.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.29 ms /   164 runs   (    0.72 ms per token,  1398.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1590.76 ms /   350 tokens (    4.55 ms per token,   220.02 tokens per second)\n",
      "llama_print_timings:        eval time =  6724.01 ms /   163 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
      "llama_print_timings:       total time =  8612.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    86.82 ms /   122 runs   (    0.71 ms per token,  1405.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   703.37 ms /   130 tokens (    5.41 ms per token,   184.83 tokens per second)\n",
      "llama_print_timings:        eval time =  4978.86 ms /   121 runs   (   41.15 ms per token,    24.30 tokens per second)\n",
      "llama_print_timings:       total time =  5905.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    85.36 ms /   121 runs   (    0.71 ms per token,  1417.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =   466.68 ms /    82 tokens (    5.69 ms per token,   175.71 tokens per second)\n",
      "llama_print_timings:        eval time =  4945.20 ms /   120 runs   (   41.21 ms per token,    24.27 tokens per second)\n",
      "llama_print_timings:       total time =  5633.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.73 ms /   129 runs   (    0.72 ms per token,  1391.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1316.99 ms /   273 tokens (    4.82 ms per token,   207.29 tokens per second)\n",
      "llama_print_timings:        eval time =  5291.45 ms /   128 runs   (   41.34 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =  6852.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.01 ms /   161 runs   (    0.72 ms per token,  1387.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1164.70 ms /   251 tokens (    4.64 ms per token,   215.51 tokens per second)\n",
      "llama_print_timings:        eval time =  6656.75 ms /   160 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time =  8127.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    92.98 ms /   129 runs   (    0.72 ms per token,  1387.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1294.07 ms /   257 tokens (    5.04 ms per token,   198.60 tokens per second)\n",
      "llama_print_timings:        eval time =  5257.56 ms /   128 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
      "llama_print_timings:       total time =  6792.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   135.85 ms /   192 runs   (    0.71 ms per token,  1413.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1406.18 ms /   289 tokens (    4.87 ms per token,   205.52 tokens per second)\n",
      "llama_print_timings:        eval time =  7974.26 ms /   191 runs   (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_print_timings:       total time =  9744.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    91.76 ms /   128 runs   (    0.72 ms per token,  1395.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1671.64 ms /   344 tokens (    4.86 ms per token,   205.79 tokens per second)\n",
      "llama_print_timings:        eval time =  5223.23 ms /   127 runs   (   41.13 ms per token,    24.31 tokens per second)\n",
      "llama_print_timings:       total time =  7129.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.96 ms /   256 runs   (    0.72 ms per token,  1391.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2999.62 ms /   621 tokens (    4.83 ms per token,   207.03 tokens per second)\n",
      "llama_print_timings:        eval time = 10832.32 ms /   255 runs   (   42.48 ms per token,    23.54 tokens per second)\n",
      "llama_print_timings:       total time = 14306.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   162.76 ms /   229 runs   (    0.71 ms per token,  1406.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2979.61 ms /   629 tokens (    4.74 ms per token,   211.10 tokens per second)\n",
      "llama_print_timings:        eval time =  9688.17 ms /   228 runs   (   42.49 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time = 13099.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.91 ms /   154 runs   (    0.70 ms per token,  1427.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2280.49 ms /   469 tokens (    4.86 ms per token,   205.66 tokens per second)\n",
      "llama_print_timings:        eval time =  6423.81 ms /   153 runs   (   41.99 ms per token,    23.82 tokens per second)\n",
      "llama_print_timings:       total time =  8991.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    82.24 ms /   118 runs   (    0.70 ms per token,  1434.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1596.70 ms /   322 tokens (    4.96 ms per token,   201.67 tokens per second)\n",
      "llama_print_timings:        eval time =  4806.51 ms /   117 runs   (   41.08 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =  6621.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.25 ms /   152 runs   (    0.71 ms per token,  1417.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1758.43 ms /   365 tokens (    4.82 ms per token,   207.57 tokens per second)\n",
      "llama_print_timings:        eval time =  6255.80 ms /   151 runs   (   41.43 ms per token,    24.14 tokens per second)\n",
      "llama_print_timings:       total time =  8298.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.63 ms /   159 runs   (    0.71 ms per token,  1399.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1655.80 ms /   349 tokens (    4.74 ms per token,   210.77 tokens per second)\n",
      "llama_print_timings:        eval time =  6525.85 ms /   158 runs   (   41.30 ms per token,    24.21 tokens per second)\n",
      "llama_print_timings:       total time =  8469.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   156.44 ms /   216 runs   (    0.72 ms per token,  1380.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   990.33 ms /   222 tokens (    4.46 ms per token,   224.17 tokens per second)\n",
      "llama_print_timings:        eval time =  8861.74 ms /   215 runs   (   41.22 ms per token,    24.26 tokens per second)\n",
      "llama_print_timings:       total time = 10249.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.54 ms /   152 runs   (    0.73 ms per token,  1375.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   850.89 ms /   182 tokens (    4.68 ms per token,   213.89 tokens per second)\n",
      "llama_print_timings:        eval time =  6154.14 ms /   151 runs   (   40.76 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:       total time =  7282.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    93.44 ms /   129 runs   (    0.72 ms per token,  1380.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   700.98 ms /   153 tokens (    4.58 ms per token,   218.27 tokens per second)\n",
      "llama_print_timings:        eval time =  5211.32 ms /   128 runs   (   40.71 ms per token,    24.56 tokens per second)\n",
      "llama_print_timings:       total time =  6147.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   109.45 ms /   152 runs   (    0.72 ms per token,  1388.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   680.27 ms /   132 tokens (    5.15 ms per token,   194.04 tokens per second)\n",
      "llama_print_timings:        eval time =  6183.46 ms /   151 runs   (   40.95 ms per token,    24.42 tokens per second)\n",
      "llama_print_timings:       total time =  7141.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   107.90 ms /   151 runs   (    0.71 ms per token,  1399.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =   713.55 ms /   139 tokens (    5.13 ms per token,   194.80 tokens per second)\n",
      "llama_print_timings:        eval time =  6216.50 ms /   150 runs   (   41.44 ms per token,    24.13 tokens per second)\n",
      "llama_print_timings:       total time =  7209.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.15 ms /   153 runs   (    0.72 ms per token,  1389.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =   570.72 ms /   121 tokens (    4.72 ms per token,   212.01 tokens per second)\n",
      "llama_print_timings:        eval time =  6182.76 ms /   152 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =  7029.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    86.94 ms /   121 runs   (    0.72 ms per token,  1391.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   564.67 ms /   121 tokens (    4.67 ms per token,   214.28 tokens per second)\n",
      "llama_print_timings:        eval time =  4884.09 ms /   120 runs   (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_print_timings:       total time =  5665.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.31 ms /   121 runs   (    0.72 ms per token,  1385.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =   557.12 ms /   119 tokens (    4.68 ms per token,   213.60 tokens per second)\n",
      "llama_print_timings:        eval time =  4878.44 ms /   120 runs   (   40.65 ms per token,    24.60 tokens per second)\n",
      "llama_print_timings:       total time =  5653.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    91.66 ms /   128 runs   (    0.72 ms per token,  1396.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   855.32 ms /   178 tokens (    4.81 ms per token,   208.11 tokens per second)\n",
      "llama_print_timings:        eval time =  5172.90 ms /   127 runs   (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:       total time =  6258.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    89.25 ms /   127 runs   (    0.70 ms per token,  1422.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   700.41 ms /   151 tokens (    4.64 ms per token,   215.59 tokens per second)\n",
      "llama_print_timings:        eval time =  5150.71 ms /   126 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  6080.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.05 ms /   143 runs   (    0.71 ms per token,  1401.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   546.95 ms /    97 tokens (    5.64 ms per token,   177.35 tokens per second)\n",
      "llama_print_timings:        eval time =  5760.59 ms /   142 runs   (   40.57 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:       total time =  6564.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    86.35 ms /   121 runs   (    0.71 ms per token,  1401.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   572.68 ms /   120 tokens (    4.77 ms per token,   209.54 tokens per second)\n",
      "llama_print_timings:        eval time =  4881.94 ms /   120 runs   (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:       total time =  5672.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.05 ms /   256 runs   (    0.72 ms per token,  1398.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1143.55 ms /   255 tokens (    4.48 ms per token,   222.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10569.54 ms /   255 runs   (   41.45 ms per token,    24.13 tokens per second)\n",
      "llama_print_timings:       total time = 12191.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.40 ms /   155 runs   (    0.72 ms per token,  1391.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1155.86 ms /   250 tokens (    4.62 ms per token,   216.29 tokens per second)\n",
      "llama_print_timings:        eval time =  6318.93 ms /   154 runs   (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_print_timings:       total time =  7754.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   172.23 ms /   239 runs   (    0.72 ms per token,  1387.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2178.76 ms /   457 tokens (    4.77 ms per token,   209.75 tokens per second)\n",
      "llama_print_timings:        eval time = 10018.47 ms /   238 runs   (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:       total time = 12632.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.48 ms /   256 runs   (    0.72 ms per token,  1395.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2211.93 ms /   466 tokens (    4.75 ms per token,   210.68 tokens per second)\n",
      "llama_print_timings:        eval time = 10773.94 ms /   255 runs   (   42.25 ms per token,    23.67 tokens per second)\n",
      "llama_print_timings:       total time = 13457.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.60 ms /   256 runs   (    0.72 ms per token,  1394.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2053.37 ms /   436 tokens (    4.71 ms per token,   212.33 tokens per second)\n",
      "llama_print_timings:        eval time = 10865.90 ms /   255 runs   (   42.61 ms per token,    23.47 tokens per second)\n",
      "llama_print_timings:       total time = 13405.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.72 ms /   188 runs   (    0.70 ms per token,  1427.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2354.30 ms /   450 tokens (    5.23 ms per token,   191.14 tokens per second)\n",
      "llama_print_timings:        eval time =  7879.29 ms /   187 runs   (   42.14 ms per token,    23.73 tokens per second)\n",
      "llama_print_timings:       total time = 10587.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.03 ms /   148 runs   (    0.70 ms per token,  1436.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1680.58 ms /   325 tokens (    5.17 ms per token,   193.39 tokens per second)\n",
      "llama_print_timings:        eval time =  6064.43 ms /   147 runs   (   41.25 ms per token,    24.24 tokens per second)\n",
      "llama_print_timings:       total time =  8015.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    76.85 ms /   110 runs   (    0.70 ms per token,  1431.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1932.01 ms /   404 tokens (    4.78 ms per token,   209.11 tokens per second)\n",
      "llama_print_timings:        eval time =  4404.12 ms /   109 runs   (   40.40 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:       total time =  6533.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   121.42 ms /   175 runs   (    0.69 ms per token,  1441.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1492.06 ms /   319 tokens (    4.68 ms per token,   213.80 tokens per second)\n",
      "llama_print_timings:        eval time =  7441.53 ms /   174 runs   (   42.77 ms per token,    23.38 tokens per second)\n",
      "llama_print_timings:       total time =  9265.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.61 ms /   149 runs   (    0.71 ms per token,  1410.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1550.35 ms /   304 tokens (    5.10 ms per token,   196.09 tokens per second)\n",
      "llama_print_timings:        eval time =  6377.26 ms /   148 runs   (   43.09 ms per token,    23.21 tokens per second)\n",
      "llama_print_timings:       total time =  8220.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   101.16 ms /   142 runs   (    0.71 ms per token,  1403.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   911.93 ms /   167 tokens (    5.46 ms per token,   183.13 tokens per second)\n",
      "llama_print_timings:        eval time =  5848.44 ms /   141 runs   (   41.48 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:       total time =  7031.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.00 ms /   256 runs   (    0.71 ms per token,  1406.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2823.93 ms /   547 tokens (    5.16 ms per token,   193.70 tokens per second)\n",
      "llama_print_timings:        eval time = 11953.40 ms /   255 runs   (   46.88 ms per token,    21.33 tokens per second)\n",
      "llama_print_timings:       total time = 15308.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   122.29 ms /   170 runs   (    0.72 ms per token,  1390.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =   930.88 ms /   174 tokens (    5.35 ms per token,   186.92 tokens per second)\n",
      "llama_print_timings:        eval time =  7224.30 ms /   169 runs   (   42.75 ms per token,    23.39 tokens per second)\n",
      "llama_print_timings:       total time =  8504.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.52 ms /   167 runs   (    0.72 ms per token,  1397.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3169.48 ms /   599 tokens (    5.29 ms per token,   188.99 tokens per second)\n",
      "llama_print_timings:        eval time =  7145.33 ms /   166 runs   (   43.04 ms per token,    23.23 tokens per second)\n",
      "llama_print_timings:       total time = 10656.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   171.46 ms /   240 runs   (    0.71 ms per token,  1399.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2039.33 ms /   397 tokens (    5.14 ms per token,   194.67 tokens per second)\n",
      "llama_print_timings:        eval time = 10447.39 ms /   239 runs   (   43.71 ms per token,    22.88 tokens per second)\n",
      "llama_print_timings:       total time = 12984.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   134.08 ms /   186 runs   (    0.72 ms per token,  1387.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =   631.79 ms /   121 tokens (    5.22 ms per token,   191.52 tokens per second)\n",
      "llama_print_timings:        eval time =  7980.96 ms /   185 runs   (   43.14 ms per token,    23.18 tokens per second)\n",
      "llama_print_timings:       total time =  8998.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.23 ms /   256 runs   (    0.72 ms per token,  1389.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2511.89 ms /   483 tokens (    5.20 ms per token,   192.29 tokens per second)\n",
      "llama_print_timings:        eval time = 11142.30 ms /   255 runs   (   43.70 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time = 14189.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.73 ms /   221 runs   (    0.71 ms per token,  1401.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1817.62 ms /   357 tokens (    5.09 ms per token,   196.41 tokens per second)\n",
      "llama_print_timings:        eval time =  9627.22 ms /   220 runs   (   43.76 ms per token,    22.85 tokens per second)\n",
      "llama_print_timings:       total time = 11901.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   119.56 ms /   167 runs   (    0.72 ms per token,  1396.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3118.20 ms /   603 tokens (    5.17 ms per token,   193.38 tokens per second)\n",
      "llama_print_timings:        eval time =  7290.43 ms /   166 runs   (   43.92 ms per token,    22.77 tokens per second)\n",
      "llama_print_timings:       total time = 10751.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   126.50 ms /   174 runs   (    0.73 ms per token,  1375.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3442.42 ms /   657 tokens (    5.24 ms per token,   190.85 tokens per second)\n",
      "llama_print_timings:        eval time =  7702.00 ms /   173 runs   (   44.52 ms per token,    22.46 tokens per second)\n",
      "llama_print_timings:       total time = 11508.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    96.94 ms /   134 runs   (    0.72 ms per token,  1382.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3430.33 ms /   664 tokens (    5.17 ms per token,   193.57 tokens per second)\n",
      "llama_print_timings:        eval time =  5836.21 ms /   133 runs   (   43.88 ms per token,    22.79 tokens per second)\n",
      "llama_print_timings:       total time =  9543.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   108.79 ms /   152 runs   (    0.72 ms per token,  1397.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3599.28 ms /   675 tokens (    5.33 ms per token,   187.54 tokens per second)\n",
      "llama_print_timings:        eval time =  6638.79 ms /   151 runs   (   43.97 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time = 10552.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   152.18 ms /   212 runs   (    0.72 ms per token,  1393.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3254.99 ms /   622 tokens (    5.23 ms per token,   191.09 tokens per second)\n",
      "llama_print_timings:        eval time =  9380.84 ms /   211 runs   (   44.46 ms per token,    22.49 tokens per second)\n",
      "llama_print_timings:       total time = 13076.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   108.57 ms /   152 runs   (    0.71 ms per token,  1400.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3375.52 ms /   672 tokens (    5.02 ms per token,   199.08 tokens per second)\n",
      "llama_print_timings:        eval time =  6578.78 ms /   151 runs   (   43.57 ms per token,    22.95 tokens per second)\n",
      "llama_print_timings:       total time = 10266.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.42 ms /   162 runs   (    0.72 ms per token,  1391.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3531.36 ms /   690 tokens (    5.12 ms per token,   195.39 tokens per second)\n",
      "llama_print_timings:        eval time =  7075.04 ms /   161 runs   (   43.94 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time = 10943.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.65 ms /   197 runs   (    0.72 ms per token,  1390.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3513.91 ms /   675 tokens (    5.21 ms per token,   192.09 tokens per second)\n",
      "llama_print_timings:        eval time =  8638.15 ms /   196 runs   (   44.07 ms per token,    22.69 tokens per second)\n",
      "llama_print_timings:       total time = 12563.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.08 ms /   202 runs   (    0.71 ms per token,  1402.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3248.87 ms /   638 tokens (    5.09 ms per token,   196.38 tokens per second)\n",
      "llama_print_timings:        eval time =  8919.36 ms /   201 runs   (   44.37 ms per token,    22.54 tokens per second)\n",
      "llama_print_timings:       total time = 12588.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   103.28 ms /   144 runs   (    0.72 ms per token,  1394.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3539.41 ms /   696 tokens (    5.09 ms per token,   196.64 tokens per second)\n",
      "llama_print_timings:        eval time =  6240.52 ms /   143 runs   (   43.64 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:       total time = 10079.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.54 ms /   168 runs   (    0.72 ms per token,  1393.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3162.98 ms /   605 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
      "llama_print_timings:        eval time =  7313.65 ms /   167 runs   (   43.79 ms per token,    22.83 tokens per second)\n",
      "llama_print_timings:       total time = 10825.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.80 ms /   168 runs   (    0.72 ms per token,  1390.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3545.11 ms /   696 tokens (    5.09 ms per token,   196.33 tokens per second)\n",
      "llama_print_timings:        eval time =  7310.89 ms /   167 runs   (   43.78 ms per token,    22.84 tokens per second)\n",
      "llama_print_timings:       total time = 11206.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.84 ms /   156 runs   (    0.72 ms per token,  1394.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3527.66 ms /   679 tokens (    5.20 ms per token,   192.48 tokens per second)\n",
      "llama_print_timings:        eval time =  6755.64 ms /   155 runs   (   43.58 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time = 10608.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.53 ms /   256 runs   (    0.72 ms per token,  1394.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3379.88 ms /   658 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
      "llama_print_timings:        eval time = 11368.44 ms /   255 runs   (   44.58 ms per token,    22.43 tokens per second)\n",
      "llama_print_timings:       total time = 15287.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.08 ms /   256 runs   (    0.72 ms per token,  1390.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3450.28 ms /   697 tokens (    4.95 ms per token,   202.01 tokens per second)\n",
      "llama_print_timings:        eval time = 11248.80 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time = 15239.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.57 ms /   146 runs   (    0.72 ms per token,  1396.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3292.85 ms /   641 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
      "llama_print_timings:        eval time =  6257.72 ms /   145 runs   (   43.16 ms per token,    23.17 tokens per second)\n",
      "llama_print_timings:       total time =  9854.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    83.98 ms /   117 runs   (    0.72 ms per token,  1393.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3676.52 ms /   712 tokens (    5.16 ms per token,   193.66 tokens per second)\n",
      "llama_print_timings:        eval time =  4954.75 ms /   116 runs   (   42.71 ms per token,    23.41 tokens per second)\n",
      "llama_print_timings:       total time =  8872.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.41 ms /   179 runs   (    0.72 ms per token,  1393.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3378.10 ms /   658 tokens (    5.13 ms per token,   194.78 tokens per second)\n",
      "llama_print_timings:        eval time =  7794.21 ms /   178 runs   (   43.79 ms per token,    22.84 tokens per second)\n",
      "llama_print_timings:       total time = 11544.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   114.10 ms /   158 runs   (    0.72 ms per token,  1384.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3520.29 ms /   693 tokens (    5.08 ms per token,   196.86 tokens per second)\n",
      "llama_print_timings:        eval time =  6841.33 ms /   157 runs   (   43.58 ms per token,    22.95 tokens per second)\n",
      "llama_print_timings:       total time = 10690.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   117.34 ms /   164 runs   (    0.72 ms per token,  1397.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3515.69 ms /   678 tokens (    5.19 ms per token,   192.85 tokens per second)\n",
      "llama_print_timings:        eval time =  7108.79 ms /   163 runs   (   43.61 ms per token,    22.93 tokens per second)\n",
      "llama_print_timings:       total time = 10962.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   114.98 ms /   159 runs   (    0.72 ms per token,  1382.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3665.34 ms /   714 tokens (    5.13 ms per token,   194.80 tokens per second)\n",
      "llama_print_timings:        eval time =  6885.12 ms /   158 runs   (   43.58 ms per token,    22.95 tokens per second)\n",
      "llama_print_timings:       total time = 10880.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   150.92 ms /   211 runs   (    0.72 ms per token,  1398.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1402.08 ms /   285 tokens (    4.92 ms per token,   203.27 tokens per second)\n",
      "llama_print_timings:        eval time =  9000.42 ms /   210 runs   (   42.86 ms per token,    23.33 tokens per second)\n",
      "llama_print_timings:       total time = 10840.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.92 ms /   256 runs   (    0.71 ms per token,  1399.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2756.71 ms /   524 tokens (    5.26 ms per token,   190.08 tokens per second)\n",
      "llama_print_timings:        eval time = 11217.77 ms /   255 runs   (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_print_timings:       total time = 14514.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.84 ms /   256 runs   (    0.72 ms per token,  1384.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2861.59 ms /   546 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
      "llama_print_timings:        eval time = 11047.51 ms /   255 runs   (   43.32 ms per token,    23.08 tokens per second)\n",
      "llama_print_timings:       total time = 14452.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.50 ms /   256 runs   (    0.72 ms per token,  1395.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2842.64 ms /   549 tokens (    5.18 ms per token,   193.13 tokens per second)\n",
      "llama_print_timings:        eval time = 11227.96 ms /   255 runs   (   44.03 ms per token,    22.71 tokens per second)\n",
      "llama_print_timings:       total time = 14612.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.26 ms /   256 runs   (    0.72 ms per token,  1396.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1971.23 ms /   391 tokens (    5.04 ms per token,   198.35 tokens per second)\n",
      "llama_print_timings:        eval time = 11108.41 ms /   255 runs   (   43.56 ms per token,    22.96 tokens per second)\n",
      "llama_print_timings:       total time = 13619.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   146.26 ms /   204 runs   (    0.72 ms per token,  1394.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =   755.99 ms /   160 tokens (    4.72 ms per token,   211.64 tokens per second)\n",
      "llama_print_timings:        eval time =  8690.47 ms /   203 runs   (   42.81 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time =  9872.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.14 ms /   256 runs   (    0.72 ms per token,  1397.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2784.97 ms /   534 tokens (    5.22 ms per token,   191.74 tokens per second)\n",
      "llama_print_timings:        eval time = 11285.01 ms /   255 runs   (   44.25 ms per token,    22.60 tokens per second)\n",
      "llama_print_timings:       total time = 14611.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   152.18 ms /   213 runs   (    0.71 ms per token,  1399.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3044.61 ms /   565 tokens (    5.39 ms per token,   185.57 tokens per second)\n",
      "llama_print_timings:        eval time =  9561.70 ms /   212 runs   (   45.10 ms per token,    22.17 tokens per second)\n",
      "llama_print_timings:       total time = 13057.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   186.79 ms /   256 runs   (    0.73 ms per token,  1370.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3013.60 ms /   575 tokens (    5.24 ms per token,   190.80 tokens per second)\n",
      "llama_print_timings:        eval time = 12103.55 ms /   255 runs   (   47.46 ms per token,    21.07 tokens per second)\n",
      "llama_print_timings:       total time = 15685.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   175.56 ms /   245 runs   (    0.72 ms per token,  1395.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =   968.19 ms /   185 tokens (    5.23 ms per token,   191.08 tokens per second)\n",
      "llama_print_timings:        eval time = 10597.12 ms /   244 runs   (   43.43 ms per token,    23.03 tokens per second)\n",
      "llama_print_timings:       total time = 12081.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.78 ms /   256 runs   (    0.71 ms per token,  1400.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2928.34 ms /   572 tokens (    5.12 ms per token,   195.33 tokens per second)\n",
      "llama_print_timings:        eval time = 11379.51 ms /   255 runs   (   44.63 ms per token,    22.41 tokens per second)\n",
      "llama_print_timings:       total time = 14847.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.84 ms /   256 runs   (    0.71 ms per token,  1400.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2949.30 ms /   559 tokens (    5.28 ms per token,   189.54 tokens per second)\n",
      "llama_print_timings:        eval time = 11263.54 ms /   255 runs   (   44.17 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time = 14755.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.19 ms /   256 runs   (    0.72 ms per token,  1397.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1070.85 ms /   215 tokens (    4.98 ms per token,   200.78 tokens per second)\n",
      "llama_print_timings:        eval time = 11188.39 ms /   255 runs   (   43.88 ms per token,    22.79 tokens per second)\n",
      "llama_print_timings:       total time = 12799.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   174.80 ms /   245 runs   (    0.71 ms per token,  1401.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2939.17 ms /   572 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
      "llama_print_timings:        eval time = 10948.04 ms /   244 runs   (   44.87 ms per token,    22.29 tokens per second)\n",
      "llama_print_timings:       total time = 14403.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.71 ms /   256 runs   (    0.72 ms per token,  1393.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2570.32 ms /   482 tokens (    5.33 ms per token,   187.52 tokens per second)\n",
      "llama_print_timings:        eval time = 11421.42 ms /   255 runs   (   44.79 ms per token,    22.33 tokens per second)\n",
      "llama_print_timings:       total time = 14532.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.55 ms /   185 runs   (    0.71 ms per token,  1406.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2436.15 ms /   477 tokens (    5.11 ms per token,   195.80 tokens per second)\n",
      "llama_print_timings:        eval time =  8207.72 ms /   184 runs   (   44.61 ms per token,    22.42 tokens per second)\n",
      "llama_print_timings:       total time = 11027.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   115.42 ms /   162 runs   (    0.71 ms per token,  1403.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2873.72 ms /   542 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
      "llama_print_timings:        eval time =  7106.84 ms /   161 runs   (   44.14 ms per token,    22.65 tokens per second)\n",
      "llama_print_timings:       total time = 10314.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.73 ms /   256 runs   (    0.72 ms per token,  1393.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2909.31 ms /   537 tokens (    5.42 ms per token,   184.58 tokens per second)\n",
      "llama_print_timings:        eval time = 11360.32 ms /   255 runs   (   44.55 ms per token,    22.45 tokens per second)\n",
      "llama_print_timings:       total time = 14809.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.14 ms /   203 runs   (    0.71 ms per token,  1408.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2625.48 ms /   510 tokens (    5.15 ms per token,   194.25 tokens per second)\n",
      "llama_print_timings:        eval time =  9112.81 ms /   202 runs   (   45.11 ms per token,    22.17 tokens per second)\n",
      "llama_print_timings:       total time = 12160.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.99 ms /   256 runs   (    0.72 ms per token,  1383.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1592.49 ms /   308 tokens (    5.17 ms per token,   193.41 tokens per second)\n",
      "llama_print_timings:        eval time = 11822.54 ms /   255 runs   (   46.36 ms per token,    21.57 tokens per second)\n",
      "llama_print_timings:       total time = 13971.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    99.35 ms /   137 runs   (    0.73 ms per token,  1378.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   354.01 ms /    64 tokens (    5.53 ms per token,   180.79 tokens per second)\n",
      "llama_print_timings:        eval time =  6359.00 ms /   136 runs   (   46.76 ms per token,    21.39 tokens per second)\n",
      "llama_print_timings:       total time =  7008.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.85 ms /   256 runs   (    0.71 ms per token,  1407.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1330.93 ms /   238 tokens (    5.59 ms per token,   178.82 tokens per second)\n",
      "llama_print_timings:        eval time = 11510.28 ms /   255 runs   (   45.14 ms per token,    22.15 tokens per second)\n",
      "llama_print_timings:       total time = 13383.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   135.20 ms /   188 runs   (    0.72 ms per token,  1390.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   515.03 ms /    78 tokens (    6.60 ms per token,   151.45 tokens per second)\n",
      "llama_print_timings:        eval time =  8196.69 ms /   187 runs   (   43.83 ms per token,    22.81 tokens per second)\n",
      "llama_print_timings:       total time =  9109.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.14 ms /   256 runs   (    0.72 ms per token,  1390.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1145.83 ms /   219 tokens (    5.23 ms per token,   191.13 tokens per second)\n",
      "llama_print_timings:        eval time = 11409.69 ms /   255 runs   (   44.74 ms per token,    22.35 tokens per second)\n",
      "llama_print_timings:       total time = 13100.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.00 ms /   233 runs   (    0.72 ms per token,  1395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   785.51 ms /   130 tokens (    6.04 ms per token,   165.50 tokens per second)\n",
      "llama_print_timings:        eval time = 10408.60 ms /   232 runs   (   44.86 ms per token,    22.29 tokens per second)\n",
      "llama_print_timings:       total time = 11690.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   133.09 ms /   184 runs   (    0.72 ms per token,  1382.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   647.08 ms /    99 tokens (    6.54 ms per token,   153.00 tokens per second)\n",
      "llama_print_timings:        eval time =  7879.66 ms /   183 runs   (   43.06 ms per token,    23.22 tokens per second)\n",
      "llama_print_timings:       total time =  8911.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.28 ms /   180 runs   (    0.72 ms per token,  1392.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3358.63 ms /   611 tokens (    5.50 ms per token,   181.92 tokens per second)\n",
      "llama_print_timings:        eval time =  8068.03 ms /   179 runs   (   45.07 ms per token,    22.19 tokens per second)\n",
      "llama_print_timings:       total time = 11804.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.17 ms /   256 runs   (    0.72 ms per token,  1397.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3227.41 ms /   584 tokens (    5.53 ms per token,   180.95 tokens per second)\n",
      "llama_print_timings:        eval time = 12110.95 ms /   255 runs   (   47.49 ms per token,    21.06 tokens per second)\n",
      "llama_print_timings:       total time = 15894.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    95.11 ms /   133 runs   (    0.72 ms per token,  1398.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3702.22 ms /   688 tokens (    5.38 ms per token,   185.83 tokens per second)\n",
      "llama_print_timings:        eval time =  5850.45 ms /   132 runs   (   44.32 ms per token,    22.56 tokens per second)\n",
      "llama_print_timings:       total time =  9830.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   106.28 ms /   149 runs   (    0.71 ms per token,  1402.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3795.02 ms /   713 tokens (    5.32 ms per token,   187.88 tokens per second)\n",
      "llama_print_timings:        eval time =  6564.66 ms /   148 runs   (   44.36 ms per token,    22.54 tokens per second)\n",
      "llama_print_timings:       total time = 10667.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.16 ms /   175 runs   (    0.72 ms per token,  1398.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3802.67 ms /   710 tokens (    5.36 ms per token,   186.71 tokens per second)\n",
      "llama_print_timings:        eval time =  7761.12 ms /   174 runs   (   44.60 ms per token,    22.42 tokens per second)\n",
      "llama_print_timings:       total time = 11930.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.68 ms /   145 runs   (    0.73 ms per token,  1372.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3420.21 ms /   654 tokens (    5.23 ms per token,   191.22 tokens per second)\n",
      "llama_print_timings:        eval time =  6454.58 ms /   144 runs   (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_print_timings:       total time = 10187.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   130.46 ms /   182 runs   (    0.72 ms per token,  1395.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1564.40 ms /   264 tokens (    5.93 ms per token,   168.75 tokens per second)\n",
      "llama_print_timings:        eval time =  8085.68 ms /   181 runs   (   44.67 ms per token,    22.39 tokens per second)\n",
      "llama_print_timings:       total time = 10034.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   108.28 ms /   151 runs   (    0.72 ms per token,  1394.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   958.62 ms /   188 tokens (    5.10 ms per token,   196.12 tokens per second)\n",
      "llama_print_timings:        eval time =  6504.32 ms /   150 runs   (   43.36 ms per token,    23.06 tokens per second)\n",
      "llama_print_timings:       total time =  7778.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.95 ms /   180 runs   (    0.72 ms per token,  1395.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1769.73 ms /   350 tokens (    5.06 ms per token,   197.77 tokens per second)\n",
      "llama_print_timings:        eval time =  7906.72 ms /   179 runs   (   44.17 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time = 10054.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.92 ms /   256 runs   (    0.72 ms per token,  1391.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2098.66 ms /   427 tokens (    4.91 ms per token,   203.46 tokens per second)\n",
      "llama_print_timings:        eval time = 11366.94 ms /   255 runs   (   44.58 ms per token,    22.43 tokens per second)\n",
      "llama_print_timings:       total time = 14011.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   122.04 ms /   171 runs   (    0.71 ms per token,  1401.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1892.07 ms /   371 tokens (    5.10 ms per token,   196.08 tokens per second)\n",
      "llama_print_timings:        eval time =  7415.98 ms /   170 runs   (   43.62 ms per token,    22.92 tokens per second)\n",
      "llama_print_timings:       total time =  9667.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   105.83 ms /   148 runs   (    0.72 ms per token,  1398.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2249.84 ms /   438 tokens (    5.14 ms per token,   194.68 tokens per second)\n",
      "llama_print_timings:        eval time =  6456.85 ms /   147 runs   (   43.92 ms per token,    22.77 tokens per second)\n",
      "llama_print_timings:       total time =  9014.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.56 ms /   182 runs   (    0.71 ms per token,  1404.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2929.45 ms /   535 tokens (    5.48 ms per token,   182.63 tokens per second)\n",
      "llama_print_timings:        eval time =  8007.42 ms /   181 runs   (   44.24 ms per token,    22.60 tokens per second)\n",
      "llama_print_timings:       total time = 11319.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.80 ms /   196 runs   (    0.71 ms per token,  1402.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2036.18 ms /   390 tokens (    5.22 ms per token,   191.53 tokens per second)\n",
      "llama_print_timings:        eval time =  8566.07 ms /   195 runs   (   43.93 ms per token,    22.76 tokens per second)\n",
      "llama_print_timings:       total time = 11013.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.28 ms /   256 runs   (    0.71 ms per token,  1404.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1898.88 ms /   376 tokens (    5.05 ms per token,   198.01 tokens per second)\n",
      "llama_print_timings:        eval time = 11255.40 ms /   255 runs   (   44.14 ms per token,    22.66 tokens per second)\n",
      "llama_print_timings:       total time = 13695.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   110.51 ms /   155 runs   (    0.71 ms per token,  1402.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2358.48 ms /   468 tokens (    5.04 ms per token,   198.43 tokens per second)\n",
      "llama_print_timings:        eval time =  6736.13 ms /   154 runs   (   43.74 ms per token,    22.86 tokens per second)\n",
      "llama_print_timings:       total time =  9418.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.31 ms /   256 runs   (    0.72 ms per token,  1396.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2423.24 ms /   470 tokens (    5.16 ms per token,   193.95 tokens per second)\n",
      "llama_print_timings:        eval time = 11416.05 ms /   255 runs   (   44.77 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time = 14385.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   121.57 ms /   168 runs   (    0.72 ms per token,  1381.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1849.41 ms /   372 tokens (    4.97 ms per token,   201.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7371.38 ms /   167 runs   (   44.14 ms per token,    22.66 tokens per second)\n",
      "llama_print_timings:       total time =  9577.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    87.03 ms /   122 runs   (    0.71 ms per token,  1401.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2228.68 ms /   418 tokens (    5.33 ms per token,   187.55 tokens per second)\n",
      "llama_print_timings:        eval time =  5216.44 ms /   121 runs   (   43.11 ms per token,    23.20 tokens per second)\n",
      "llama_print_timings:       total time =  7700.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.03 ms /   221 runs   (    0.71 ms per token,  1407.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2857.64 ms /   535 tokens (    5.34 ms per token,   187.22 tokens per second)\n",
      "llama_print_timings:        eval time =  9759.46 ms /   220 runs   (   44.36 ms per token,    22.54 tokens per second)\n",
      "llama_print_timings:       total time = 13084.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.86 ms /   223 runs   (    0.72 ms per token,  1394.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3200.51 ms /   623 tokens (    5.14 ms per token,   194.66 tokens per second)\n",
      "llama_print_timings:        eval time =  9875.17 ms /   222 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time = 13550.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   132.84 ms /   184 runs   (    0.72 ms per token,  1385.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3069.69 ms /   584 tokens (    5.26 ms per token,   190.25 tokens per second)\n",
      "llama_print_timings:        eval time =  8047.67 ms /   183 runs   (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time = 11507.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   116.54 ms /   163 runs   (    0.71 ms per token,  1398.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3179.51 ms /   599 tokens (    5.31 ms per token,   188.39 tokens per second)\n",
      "llama_print_timings:        eval time =  7172.53 ms /   162 runs   (   44.27 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time = 10692.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   158.57 ms /   223 runs   (    0.71 ms per token,  1406.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2363.40 ms /   491 tokens (    4.81 ms per token,   207.75 tokens per second)\n",
      "llama_print_timings:        eval time =  9992.32 ms /   222 runs   (   45.01 ms per token,    22.22 tokens per second)\n",
      "llama_print_timings:       total time = 12830.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.76 ms /   256 runs   (    0.72 ms per token,  1385.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2240.15 ms /   437 tokens (    5.13 ms per token,   195.08 tokens per second)\n",
      "llama_print_timings:        eval time = 11374.18 ms /   255 runs   (   44.60 ms per token,    22.42 tokens per second)\n",
      "llama_print_timings:       total time = 14163.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   162.20 ms /   225 runs   (    0.72 ms per token,  1387.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1922.50 ms /   370 tokens (    5.20 ms per token,   192.46 tokens per second)\n",
      "llama_print_timings:        eval time =  9917.17 ms /   224 runs   (   44.27 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time = 12321.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   165.03 ms /   231 runs   (    0.71 ms per token,  1399.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2278.10 ms /   432 tokens (    5.27 ms per token,   189.63 tokens per second)\n",
      "llama_print_timings:        eval time = 10687.56 ms /   230 runs   (   46.47 ms per token,    21.52 tokens per second)\n",
      "llama_print_timings:       total time = 13460.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.92 ms /   256 runs   (    0.71 ms per token,  1399.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2859.87 ms /   544 tokens (    5.26 ms per token,   190.22 tokens per second)\n",
      "llama_print_timings:        eval time = 11415.38 ms /   255 runs   (   44.77 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time = 14821.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   142.74 ms /   198 runs   (    0.72 ms per token,  1387.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.31 ms /   404 tokens (    5.10 ms per token,   195.90 tokens per second)\n",
      "llama_print_timings:        eval time =  9052.09 ms /   197 runs   (   45.95 ms per token,    21.76 tokens per second)\n",
      "llama_print_timings:       total time = 11538.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   174.20 ms /   243 runs   (    0.72 ms per token,  1394.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1986.71 ms /   377 tokens (    5.27 ms per token,   189.76 tokens per second)\n",
      "llama_print_timings:        eval time = 11194.47 ms /   242 runs   (   46.26 ms per token,    21.62 tokens per second)\n",
      "llama_print_timings:       total time = 13698.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.54 ms /   173 runs   (    0.71 ms per token,  1400.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2518.79 ms /   469 tokens (    5.37 ms per token,   186.20 tokens per second)\n",
      "llama_print_timings:        eval time =  7956.22 ms /   172 runs   (   46.26 ms per token,    21.62 tokens per second)\n",
      "llama_print_timings:       total time = 10841.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.35 ms /   159 runs   (    0.71 ms per token,  1402.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2665.36 ms /   474 tokens (    5.62 ms per token,   177.84 tokens per second)\n",
      "llama_print_timings:        eval time =  7420.94 ms /   158 runs   (   46.97 ms per token,    21.29 tokens per second)\n",
      "llama_print_timings:       total time = 10424.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   164.07 ms /   230 runs   (    0.71 ms per token,  1401.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1920.42 ms /   372 tokens (    5.16 ms per token,   193.71 tokens per second)\n",
      "llama_print_timings:        eval time = 10144.19 ms /   229 runs   (   44.30 ms per token,    22.57 tokens per second)\n",
      "llama_print_timings:       total time = 12546.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   113.29 ms /   158 runs   (    0.72 ms per token,  1394.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2044.50 ms /   410 tokens (    4.99 ms per token,   200.54 tokens per second)\n",
      "llama_print_timings:        eval time =  6865.40 ms /   157 runs   (   43.73 ms per token,    22.87 tokens per second)\n",
      "llama_print_timings:       total time =  9239.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   109.08 ms /   154 runs   (    0.71 ms per token,  1411.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2822.01 ms /   520 tokens (    5.43 ms per token,   184.27 tokens per second)\n",
      "llama_print_timings:        eval time =  6562.84 ms /   153 runs   (   42.89 ms per token,    23.31 tokens per second)\n",
      "llama_print_timings:       total time =  9702.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.01 ms /   181 runs   (    0.71 ms per token,  1403.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3303.44 ms /   609 tokens (    5.42 ms per token,   184.35 tokens per second)\n",
      "llama_print_timings:        eval time =  7983.91 ms /   180 runs   (   44.36 ms per token,    22.55 tokens per second)\n",
      "llama_print_timings:       total time = 11662.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.38 ms /   180 runs   (    0.72 ms per token,  1391.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3134.50 ms /   592 tokens (    5.29 ms per token,   188.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7909.17 ms /   179 runs   (   44.19 ms per token,    22.63 tokens per second)\n",
      "llama_print_timings:       total time = 11422.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   122.87 ms /   173 runs   (    0.71 ms per token,  1408.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3234.39 ms /   612 tokens (    5.28 ms per token,   189.22 tokens per second)\n",
      "llama_print_timings:        eval time =  7606.30 ms /   172 runs   (   44.22 ms per token,    22.61 tokens per second)\n",
      "llama_print_timings:       total time = 11199.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.83 ms /   197 runs   (    0.71 ms per token,  1408.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2946.01 ms /   547 tokens (    5.39 ms per token,   185.68 tokens per second)\n",
      "llama_print_timings:        eval time =  8677.24 ms /   196 runs   (   44.27 ms per token,    22.59 tokens per second)\n",
      "llama_print_timings:       total time = 12034.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.60 ms /   256 runs   (    0.72 ms per token,  1394.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3574.69 ms /   682 tokens (    5.24 ms per token,   190.79 tokens per second)\n",
      "llama_print_timings:        eval time = 11507.24 ms /   255 runs   (   45.13 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time = 15623.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   127.49 ms /   179 runs   (    0.71 ms per token,  1404.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3544.34 ms /   685 tokens (    5.17 ms per token,   193.27 tokens per second)\n",
      "llama_print_timings:        eval time =  7826.81 ms /   178 runs   (   43.97 ms per token,    22.74 tokens per second)\n",
      "llama_print_timings:       total time = 11742.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   155.32 ms /   217 runs   (    0.72 ms per token,  1397.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2950.99 ms /   561 tokens (    5.26 ms per token,   190.11 tokens per second)\n",
      "llama_print_timings:        eval time =  9592.08 ms /   216 runs   (   44.41 ms per token,    22.52 tokens per second)\n",
      "llama_print_timings:       total time = 13000.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.56 ms /   256 runs   (    0.72 ms per token,  1394.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2523.25 ms /   487 tokens (    5.18 ms per token,   193.01 tokens per second)\n",
      "llama_print_timings:        eval time = 11341.76 ms /   255 runs   (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_print_timings:       total time = 14412.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   101.59 ms /   141 runs   (    0.72 ms per token,  1387.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   323.05 ms /    45 tokens (    7.18 ms per token,   139.30 tokens per second)\n",
      "llama_print_timings:        eval time =  6009.73 ms /   140 runs   (   42.93 ms per token,    23.30 tokens per second)\n",
      "llama_print_timings:       total time =  6627.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   143.92 ms /   196 runs   (    0.73 ms per token,  1361.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =   934.80 ms /   183 tokens (    5.11 ms per token,   195.76 tokens per second)\n",
      "llama_print_timings:        eval time =  8428.57 ms /   195 runs   (   43.22 ms per token,    23.14 tokens per second)\n",
      "llama_print_timings:       total time =  9787.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.08 ms /   256 runs   (    0.72 ms per token,  1390.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2820.83 ms /   542 tokens (    5.20 ms per token,   192.14 tokens per second)\n",
      "llama_print_timings:        eval time = 11373.98 ms /   255 runs   (   44.60 ms per token,    22.42 tokens per second)\n",
      "llama_print_timings:       total time = 14743.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.86 ms /   256 runs   (    0.71 ms per token,  1400.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2770.83 ms /   530 tokens (    5.23 ms per token,   191.28 tokens per second)\n",
      "llama_print_timings:        eval time = 11301.70 ms /   255 runs   (   44.32 ms per token,    22.56 tokens per second)\n",
      "llama_print_timings:       total time = 14616.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.21 ms /   256 runs   (    0.72 ms per token,  1397.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2355.41 ms /   460 tokens (    5.12 ms per token,   195.29 tokens per second)\n",
      "llama_print_timings:        eval time = 11245.38 ms /   255 runs   (   44.10 ms per token,    22.68 tokens per second)\n",
      "llama_print_timings:       total time = 14144.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.71 ms /   222 runs   (    0.71 ms per token,  1407.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2043.95 ms /   416 tokens (    4.91 ms per token,   203.53 tokens per second)\n",
      "llama_print_timings:        eval time =  9715.37 ms /   221 runs   (   43.96 ms per token,    22.75 tokens per second)\n",
      "llama_print_timings:       total time = 12223.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.30 ms /   195 runs   (    0.71 ms per token,  1399.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2200.73 ms /   439 tokens (    5.01 ms per token,   199.48 tokens per second)\n",
      "llama_print_timings:        eval time =  8504.51 ms /   194 runs   (   43.84 ms per token,    22.81 tokens per second)\n",
      "llama_print_timings:       total time = 11114.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   111.48 ms /   156 runs   (    0.71 ms per token,  1399.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2179.00 ms /   417 tokens (    5.23 ms per token,   191.37 tokens per second)\n",
      "llama_print_timings:        eval time =  6724.57 ms /   155 runs   (   43.38 ms per token,    23.05 tokens per second)\n",
      "llama_print_timings:       total time =  9229.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.21 ms /   143 runs   (    0.71 ms per token,  1399.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1537.54 ms /   295 tokens (    5.21 ms per token,   191.87 tokens per second)\n",
      "llama_print_timings:        eval time =  6128.60 ms /   142 runs   (   43.16 ms per token,    23.17 tokens per second)\n",
      "llama_print_timings:       total time =  7964.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   102.21 ms /   144 runs   (    0.71 ms per token,  1408.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1528.87 ms /   292 tokens (    5.24 ms per token,   190.99 tokens per second)\n",
      "llama_print_timings:        eval time =  6221.61 ms /   143 runs   (   43.51 ms per token,    22.98 tokens per second)\n",
      "llama_print_timings:       total time =  8046.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   131.11 ms /   183 runs   (    0.72 ms per token,  1395.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2420.20 ms /   461 tokens (    5.25 ms per token,   190.48 tokens per second)\n",
      "llama_print_timings:        eval time =  8011.85 ms /   182 runs   (   44.02 ms per token,    22.72 tokens per second)\n",
      "llama_print_timings:       total time = 10815.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.91 ms /   256 runs   (    0.71 ms per token,  1407.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2425.58 ms /   477 tokens (    5.09 ms per token,   196.65 tokens per second)\n",
      "llama_print_timings:        eval time = 11418.18 ms /   255 runs   (   44.78 ms per token,    22.33 tokens per second)\n",
      "llama_print_timings:       total time = 14383.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   162.38 ms /   229 runs   (    0.71 ms per token,  1410.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1453.64 ms /   299 tokens (    4.86 ms per token,   205.69 tokens per second)\n",
      "llama_print_timings:        eval time = 10105.98 ms /   228 runs   (   44.32 ms per token,    22.56 tokens per second)\n",
      "llama_print_timings:       total time = 12037.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   134.46 ms /   189 runs   (    0.71 ms per token,  1405.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1258.93 ms /   245 tokens (    5.14 ms per token,   194.61 tokens per second)\n",
      "llama_print_timings:        eval time =  8291.34 ms /   188 runs   (   44.10 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time =  9943.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   184.36 ms /   256 runs   (    0.72 ms per token,  1388.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  3000.61 ms /   570 tokens (    5.26 ms per token,   189.96 tokens per second)\n",
      "llama_print_timings:        eval time = 11555.62 ms /   255 runs   (   45.32 ms per token,    22.07 tokens per second)\n",
      "llama_print_timings:       total time = 15100.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   178.56 ms /   250 runs   (    0.71 ms per token,  1400.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2842.73 ms /   541 tokens (    5.25 ms per token,   190.31 tokens per second)\n",
      "llama_print_timings:        eval time = 11190.86 ms /   249 runs   (   44.94 ms per token,    22.25 tokens per second)\n",
      "llama_print_timings:       total time = 14562.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.48 ms /   254 runs   (    0.71 ms per token,  1399.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2844.29 ms /   539 tokens (    5.28 ms per token,   189.50 tokens per second)\n",
      "llama_print_timings:        eval time = 11405.81 ms /   253 runs   (   45.08 ms per token,    22.18 tokens per second)\n",
      "llama_print_timings:       total time = 14787.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   155.79 ms /   218 runs   (    0.71 ms per token,  1399.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2375.52 ms /   451 tokens (    5.27 ms per token,   189.85 tokens per second)\n",
      "llama_print_timings:        eval time =  9711.70 ms /   217 runs   (   44.75 ms per token,    22.34 tokens per second)\n",
      "llama_print_timings:       total time = 12546.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.43 ms /   214 runs   (    0.72 ms per token,  1394.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2974.43 ms /   561 tokens (    5.30 ms per token,   188.61 tokens per second)\n",
      "llama_print_timings:        eval time =  9579.03 ms /   213 runs   (   44.97 ms per token,    22.24 tokens per second)\n",
      "llama_print_timings:       total time = 13005.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.63 ms /   216 runs   (    0.71 ms per token,  1405.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2969.58 ms /   572 tokens (    5.19 ms per token,   192.62 tokens per second)\n",
      "llama_print_timings:        eval time =  9648.92 ms /   215 runs   (   44.88 ms per token,    22.28 tokens per second)\n",
      "llama_print_timings:       total time = 13071.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.53 ms /   256 runs   (    0.71 ms per token,  1402.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2943.66 ms /   546 tokens (    5.39 ms per token,   185.48 tokens per second)\n",
      "llama_print_timings:        eval time = 11451.63 ms /   255 runs   (   44.91 ms per token,    22.27 tokens per second)\n",
      "llama_print_timings:       total time = 14936.14 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   133.85 ms /   189 runs   (    0.71 ms per token,  1412.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1062.95 ms /   196 tokens (    5.42 ms per token,   184.39 tokens per second)\n",
      "llama_print_timings:        eval time =  8214.18 ms /   188 runs   (   43.69 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time =  9670.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   153.45 ms /   216 runs   (    0.71 ms per token,  1407.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   895.50 ms /   171 tokens (    5.24 ms per token,   190.95 tokens per second)\n",
      "llama_print_timings:        eval time =  9394.75 ms /   215 runs   (   43.70 ms per token,    22.89 tokens per second)\n",
      "llama_print_timings:       total time = 10737.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.28 ms /   256 runs   (    0.71 ms per token,  1404.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2619.13 ms /   509 tokens (    5.15 ms per token,   194.34 tokens per second)\n",
      "llama_print_timings:        eval time = 11526.36 ms /   255 runs   (   45.20 ms per token,    22.12 tokens per second)\n",
      "llama_print_timings:       total time = 14692.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   159.62 ms /   223 runs   (    0.72 ms per token,  1397.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2863.69 ms /   535 tokens (    5.35 ms per token,   186.82 tokens per second)\n",
      "llama_print_timings:        eval time = 10020.21 ms /   222 runs   (   45.14 ms per token,    22.16 tokens per second)\n",
      "llama_print_timings:       total time = 13353.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.85 ms /   256 runs   (    0.71 ms per token,  1400.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2749.52 ms /   515 tokens (    5.34 ms per token,   187.31 tokens per second)\n",
      "llama_print_timings:        eval time = 11247.46 ms /   255 runs   (   44.11 ms per token,    22.67 tokens per second)\n",
      "llama_print_timings:       total time = 14536.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   149.21 ms /   207 runs   (    0.72 ms per token,  1387.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2316.49 ms /   491 tokens (    4.72 ms per token,   211.96 tokens per second)\n",
      "llama_print_timings:        eval time =  9170.85 ms /   206 runs   (   44.52 ms per token,    22.46 tokens per second)\n",
      "llama_print_timings:       total time = 11922.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   123.17 ms /   175 runs   (    0.70 ms per token,  1420.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2145.77 ms /   433 tokens (    4.96 ms per token,   201.79 tokens per second)\n",
      "llama_print_timings:        eval time =  7226.05 ms /   174 runs   (   41.53 ms per token,    24.08 tokens per second)\n",
      "llama_print_timings:       total time =  9694.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.53 ms /   256 runs   (    0.71 ms per token,  1418.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1793.73 ms /   381 tokens (    4.71 ms per token,   212.41 tokens per second)\n",
      "llama_print_timings:        eval time = 10838.04 ms /   255 runs   (   42.50 ms per token,    23.53 tokens per second)\n",
      "llama_print_timings:       total time = 13121.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.23 ms /   256 runs   (    0.72 ms per token,  1397.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2154.81 ms /   433 tokens (    4.98 ms per token,   200.95 tokens per second)\n",
      "llama_print_timings:        eval time = 10993.36 ms /   255 runs   (   43.11 ms per token,    23.20 tokens per second)\n",
      "llama_print_timings:       total time = 13650.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   139.32 ms /   199 runs   (    0.70 ms per token,  1428.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2483.70 ms /   510 tokens (    4.87 ms per token,   205.34 tokens per second)\n",
      "llama_print_timings:        eval time =  8719.07 ms /   198 runs   (   44.04 ms per token,    22.71 tokens per second)\n",
      "llama_print_timings:       total time = 11583.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   120.36 ms /   167 runs   (    0.72 ms per token,  1387.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1433.90 ms /   292 tokens (    4.91 ms per token,   203.64 tokens per second)\n",
      "llama_print_timings:        eval time =  6861.31 ms /   166 runs   (   41.33 ms per token,    24.19 tokens per second)\n",
      "llama_print_timings:       total time =  8602.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    65.50 ms /    89 runs   (    0.74 ms per token,  1358.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =   571.30 ms /   113 tokens (    5.06 ms per token,   197.79 tokens per second)\n",
      "llama_print_timings:        eval time =  3609.29 ms /    88 runs   (   41.01 ms per token,    24.38 tokens per second)\n",
      "llama_print_timings:       total time =  4349.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.40 ms /   256 runs   (    0.70 ms per token,  1419.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2716.00 ms /   553 tokens (    4.91 ms per token,   203.61 tokens per second)\n",
      "llama_print_timings:        eval time = 11131.35 ms /   255 runs   (   43.65 ms per token,    22.91 tokens per second)\n",
      "llama_print_timings:       total time = 14333.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   168.23 ms /   233 runs   (    0.72 ms per token,  1384.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1040.19 ms /   222 tokens (    4.69 ms per token,   213.42 tokens per second)\n",
      "llama_print_timings:        eval time =  9650.57 ms /   232 runs   (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_print_timings:       total time = 11119.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    90.73 ms /   126 runs   (    0.72 ms per token,  1388.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1428.71 ms /   307 tokens (    4.65 ms per token,   214.88 tokens per second)\n",
      "llama_print_timings:        eval time =  5133.93 ms /   125 runs   (   41.07 ms per token,    24.35 tokens per second)\n",
      "llama_print_timings:       total time =  6791.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =    88.49 ms /   125 runs   (    0.71 ms per token,  1412.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   303.36 ms /    56 tokens (    5.42 ms per token,   184.60 tokens per second)\n",
      "llama_print_timings:        eval time =  5095.34 ms /   124 runs   (   41.09 ms per token,    24.34 tokens per second)\n",
      "llama_print_timings:       total time =  5626.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.20 ms /   165 runs   (    0.72 ms per token,  1395.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   724.15 ms /   157 tokens (    4.61 ms per token,   216.80 tokens per second)\n",
      "llama_print_timings:        eval time =  6741.96 ms /   164 runs   (   41.11 ms per token,    24.33 tokens per second)\n",
      "llama_print_timings:       total time =  7774.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.22 ms /   256 runs   (    0.71 ms per token,  1412.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2220.85 ms /   432 tokens (    5.14 ms per token,   194.52 tokens per second)\n",
      "llama_print_timings:        eval time = 11114.84 ms /   255 runs   (   43.59 ms per token,    22.94 tokens per second)\n",
      "llama_print_timings:       total time = 13835.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.70 ms /   199 runs   (    0.71 ms per token,  1404.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2645.71 ms /   531 tokens (    4.98 ms per token,   200.70 tokens per second)\n",
      "llama_print_timings:        eval time =  8357.86 ms /   198 runs   (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_print_timings:       total time = 11379.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.78 ms /   255 runs   (    0.72 ms per token,  1395.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2637.57 ms /   528 tokens (    5.00 ms per token,   200.18 tokens per second)\n",
      "llama_print_timings:        eval time = 10919.36 ms /   254 runs   (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time = 14051.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.12 ms /   256 runs   (    0.71 ms per token,  1405.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2635.62 ms /   527 tokens (    5.00 ms per token,   199.95 tokens per second)\n",
      "llama_print_timings:        eval time = 11072.50 ms /   255 runs   (   43.42 ms per token,    23.03 tokens per second)\n",
      "llama_print_timings:       total time = 14210.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   125.49 ms /   176 runs   (    0.71 ms per token,  1402.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2165.45 ms /   437 tokens (    4.96 ms per token,   201.81 tokens per second)\n",
      "llama_print_timings:        eval time =  7664.04 ms /   175 runs   (   43.79 ms per token,    22.83 tokens per second)\n",
      "llama_print_timings:       total time = 10176.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   151.05 ms /   213 runs   (    0.71 ms per token,  1410.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2932.57 ms /   566 tokens (    5.18 ms per token,   193.00 tokens per second)\n",
      "llama_print_timings:        eval time =  9229.26 ms /   212 runs   (   43.53 ms per token,    22.97 tokens per second)\n",
      "llama_print_timings:       total time = 12569.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.60 ms /   256 runs   (    0.71 ms per token,  1409.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2785.42 ms /   546 tokens (    5.10 ms per token,   196.02 tokens per second)\n",
      "llama_print_timings:        eval time = 11101.27 ms /   255 runs   (   43.53 ms per token,    22.97 tokens per second)\n",
      "llama_print_timings:       total time = 14382.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   129.61 ms /   181 runs   (    0.72 ms per token,  1396.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2642.00 ms /   536 tokens (    4.93 ms per token,   202.88 tokens per second)\n",
      "llama_print_timings:        eval time =  7718.62 ms /   180 runs   (   42.88 ms per token,    23.32 tokens per second)\n",
      "llama_print_timings:       total time = 10712.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.75 ms /   256 runs   (    0.69 ms per token,  1440.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2202.37 ms /   491 tokens (    4.49 ms per token,   222.94 tokens per second)\n",
      "llama_print_timings:        eval time = 11094.48 ms /   255 runs   (   43.51 ms per token,    22.98 tokens per second)\n",
      "llama_print_timings:       total time = 13784.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   141.15 ms /   197 runs   (    0.72 ms per token,  1395.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2723.07 ms /   518 tokens (    5.26 ms per token,   190.23 tokens per second)\n",
      "llama_print_timings:        eval time =  8460.91 ms /   196 runs   (   43.17 ms per token,    23.17 tokens per second)\n",
      "llama_print_timings:       total time = 11576.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.69 ms /   256 runs   (    0.72 ms per token,  1393.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2822.21 ms /   552 tokens (    5.11 ms per token,   195.59 tokens per second)\n",
      "llama_print_timings:        eval time = 11177.73 ms /   255 runs   (   43.83 ms per token,    22.81 tokens per second)\n",
      "llama_print_timings:       total time = 14519.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   151.25 ms /   208 runs   (    0.73 ms per token,  1375.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2396.47 ms /   486 tokens (    4.93 ms per token,   202.80 tokens per second)\n",
      "llama_print_timings:        eval time =  8918.24 ms /   207 runs   (   43.08 ms per token,    23.21 tokens per second)\n",
      "llama_print_timings:       total time = 11715.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   167.16 ms /   236 runs   (    0.71 ms per token,  1411.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1931.38 ms /   415 tokens (    4.65 ms per token,   214.87 tokens per second)\n",
      "llama_print_timings:        eval time = 10274.69 ms /   235 runs   (   43.72 ms per token,    22.87 tokens per second)\n",
      "llama_print_timings:       total time = 12665.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   177.57 ms /   249 runs   (    0.71 ms per token,  1402.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2419.44 ms /   481 tokens (    5.03 ms per token,   198.81 tokens per second)\n",
      "llama_print_timings:        eval time = 10664.24 ms /   248 runs   (   43.00 ms per token,    23.26 tokens per second)\n",
      "llama_print_timings:       total time = 13548.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   183.73 ms /   256 runs   (    0.72 ms per token,  1393.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2354.00 ms /   490 tokens (    4.80 ms per token,   208.16 tokens per second)\n",
      "llama_print_timings:        eval time = 10873.14 ms /   255 runs   (   42.64 ms per token,    23.45 tokens per second)\n",
      "llama_print_timings:       total time = 13710.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   137.79 ms /   193 runs   (    0.71 ms per token,  1400.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   714.43 ms /   155 tokens (    4.61 ms per token,   216.96 tokens per second)\n",
      "llama_print_timings:        eval time =  7927.76 ms /   192 runs   (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =  8996.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   140.65 ms /   197 runs   (    0.71 ms per token,  1400.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1921.67 ms /   409 tokens (    4.70 ms per token,   212.84 tokens per second)\n",
      "llama_print_timings:        eval time =  8194.67 ms /   196 runs   (   41.81 ms per token,    23.92 tokens per second)\n",
      "llama_print_timings:       total time = 10484.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   104.69 ms /   147 runs   (    0.71 ms per token,  1404.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   868.33 ms /   180 tokens (    4.82 ms per token,   207.29 tokens per second)\n",
      "llama_print_timings:        eval time =  5968.79 ms /   146 runs   (   40.88 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:       total time =  7107.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   118.18 ms /   165 runs   (    0.72 ms per token,  1396.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1418.66 ms /   293 tokens (    4.84 ms per token,   206.53 tokens per second)\n",
      "llama_print_timings:        eval time =  6770.51 ms /   164 runs   (   41.28 ms per token,    24.22 tokens per second)\n",
      "llama_print_timings:       total time =  8505.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   181.50 ms /   256 runs   (    0.71 ms per token,  1410.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2431.22 ms /   521 tokens (    4.67 ms per token,   214.30 tokens per second)\n",
      "llama_print_timings:        eval time = 10801.16 ms /   255 runs   (   42.36 ms per token,    23.61 tokens per second)\n",
      "llama_print_timings:       total time = 13708.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   144.59 ms /   206 runs   (    0.70 ms per token,  1424.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2605.22 ms /   527 tokens (    4.94 ms per token,   202.29 tokens per second)\n",
      "llama_print_timings:        eval time =  8774.79 ms /   205 runs   (   42.80 ms per token,    23.36 tokens per second)\n",
      "llama_print_timings:       total time = 11774.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   187.36 ms /   256 runs   (    0.73 ms per token,  1366.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2831.72 ms /   555 tokens (    5.10 ms per token,   195.99 tokens per second)\n",
      "llama_print_timings:        eval time = 10834.80 ms /   255 runs   (   42.49 ms per token,    23.54 tokens per second)\n",
      "llama_print_timings:       total time = 14153.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   161.72 ms /   226 runs   (    0.72 ms per token,  1397.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2614.89 ms /   535 tokens (    4.89 ms per token,   204.60 tokens per second)\n",
      "llama_print_timings:        eval time =  9938.70 ms /   225 runs   (   44.17 ms per token,    22.64 tokens per second)\n",
      "llama_print_timings:       total time = 12991.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   180.63 ms /   256 runs   (    0.71 ms per token,  1417.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   722.46 ms /   150 tokens (    4.82 ms per token,   207.63 tokens per second)\n",
      "llama_print_timings:        eval time = 10958.20 ms /   255 runs   (   42.97 ms per token,    23.27 tokens per second)\n",
      "llama_print_timings:       total time = 12177.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   157.28 ms /   223 runs   (    0.71 ms per token,  1417.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2941.51 ms /   565 tokens (    5.21 ms per token,   192.08 tokens per second)\n",
      "llama_print_timings:        eval time = 10026.23 ms /   222 runs   (   45.16 ms per token,    22.14 tokens per second)\n",
      "llama_print_timings:       total time = 13403.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   161.74 ms /   226 runs   (    0.72 ms per token,  1397.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1637.44 ms /   332 tokens (    4.93 ms per token,   202.76 tokens per second)\n",
      "llama_print_timings:        eval time =  9454.70 ms /   225 runs   (   42.02 ms per token,    23.80 tokens per second)\n",
      "llama_print_timings:       total time = 11520.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   128.22 ms /   181 runs   (    0.71 ms per token,  1411.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   306.74 ms /    49 tokens (    6.26 ms per token,   159.75 tokens per second)\n",
      "llama_print_timings:        eval time =  7426.68 ms /   180 runs   (   41.26 ms per token,    24.24 tokens per second)\n",
      "llama_print_timings:       total time =  8070.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.13 ms /   256 runs   (    0.71 ms per token,  1405.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2379.49 ms /   506 tokens (    4.70 ms per token,   212.65 tokens per second)\n",
      "llama_print_timings:        eval time = 11144.94 ms /   255 runs   (   43.71 ms per token,    22.88 tokens per second)\n",
      "llama_print_timings:       total time = 14023.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  2261.89 ms\n",
      "llama_print_timings:      sample time =   182.03 ms /   256 runs   (    0.71 ms per token,  1406.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2064.55 ms /   442 tokens (    4.67 ms per token,   214.09 tokens per second)\n",
      "llama_print_timings:        eval time = 10969.54 ms /   255 runs   (   43.02 ms per token,    23.25 tokens per second)\n",
      "llama_print_timings:       total time = 13524.12 ms\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.39 ms /    43 runs   (    0.71 ms per token,  1415.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2492.70 ms /   650 tokens (    3.83 ms per token,   260.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1252.69 ms /    42 runs   (   29.83 ms per token,    33.53 tokens per second)\n",
      "llama_print_timings:       total time =  3827.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.85 ms /    38 runs   (    0.68 ms per token,  1469.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1854.32 ms /   536 tokens (    3.46 ms per token,   289.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1105.76 ms /    37 runs   (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_print_timings:       total time =  3031.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.71 ms /    46 runs   (    0.71 ms per token,  1406.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1929.47 ms /   545 tokens (    3.54 ms per token,   282.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1326.13 ms /    45 runs   (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_print_timings:       total time =  3342.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   163.55 ms /   227 runs   (    0.72 ms per token,  1387.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1944.66 ms /   556 tokens (    3.50 ms per token,   285.91 tokens per second)\n",
      "llama_print_timings:        eval time =  6809.61 ms /   226 runs   (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_print_timings:       total time =  9180.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.37 ms /    32 runs   (    0.73 ms per token,  1369.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1683.27 ms /   514 tokens (    3.27 ms per token,   305.36 tokens per second)\n",
      "llama_print_timings:        eval time =   916.62 ms /    31 runs   (   29.57 ms per token,    33.82 tokens per second)\n",
      "llama_print_timings:       total time =  2662.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.02 ms /    42 runs   (    0.71 ms per token,  1399.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   792.98 ms /   251 tokens (    3.16 ms per token,   316.53 tokens per second)\n",
      "llama_print_timings:        eval time =  1169.99 ms /    41 runs   (   28.54 ms per token,    35.04 tokens per second)\n",
      "llama_print_timings:       total time =  2040.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.27 ms /    44 runs   (    0.71 ms per token,  1407.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   319.63 ms /    68 tokens (    4.70 ms per token,   212.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1194.85 ms /    43 runs   (   27.79 ms per token,    35.99 tokens per second)\n",
      "llama_print_timings:       total time =  1597.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.06 ms /   256 runs   (    0.71 ms per token,  1406.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2048.94 ms /   586 tokens (    3.50 ms per token,   286.00 tokens per second)\n",
      "llama_print_timings:        eval time =  7815.69 ms /   255 runs   (   30.65 ms per token,    32.63 tokens per second)\n",
      "llama_print_timings:       total time = 10341.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.42 ms /    46 runs   (    0.70 ms per token,  1419.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1852.91 ms /   548 tokens (    3.38 ms per token,   295.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1329.26 ms /    45 runs   (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_print_timings:       total time =  3266.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.97 ms /   256 runs   (    0.71 ms per token,  1399.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1787.12 ms /   531 tokens (    3.37 ms per token,   297.13 tokens per second)\n",
      "llama_print_timings:        eval time =  7725.40 ms /   255 runs   (   30.30 ms per token,    33.01 tokens per second)\n",
      "llama_print_timings:       total time =  9991.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   147.44 ms /   207 runs   (    0.71 ms per token,  1404.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1792.21 ms /   538 tokens (    3.33 ms per token,   300.19 tokens per second)\n",
      "llama_print_timings:        eval time =  6232.76 ms /   206 runs   (   30.26 ms per token,    33.05 tokens per second)\n",
      "llama_print_timings:       total time =  8412.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   181.62 ms /   256 runs   (    0.71 ms per token,  1409.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1789.77 ms /   538 tokens (    3.33 ms per token,   300.60 tokens per second)\n",
      "llama_print_timings:        eval time =  7734.39 ms /   255 runs   (   30.33 ms per token,    32.97 tokens per second)\n",
      "llama_print_timings:       total time = 10002.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   181.10 ms /   256 runs   (    0.71 ms per token,  1413.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1796.87 ms /   540 tokens (    3.33 ms per token,   300.52 tokens per second)\n",
      "llama_print_timings:        eval time =  7794.84 ms /   255 runs   (   30.57 ms per token,    32.71 tokens per second)\n",
      "llama_print_timings:       total time = 10066.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.35 ms /    44 runs   (    0.71 ms per token,  1403.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1490.32 ms /   458 tokens (    3.25 ms per token,   307.32 tokens per second)\n",
      "llama_print_timings:        eval time =  1266.40 ms /    43 runs   (   29.45 ms per token,    33.95 tokens per second)\n",
      "llama_print_timings:       total time =  2837.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    48.37 ms /    69 runs   (    0.70 ms per token,  1426.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1894.86 ms /   552 tokens (    3.43 ms per token,   291.31 tokens per second)\n",
      "llama_print_timings:        eval time =  2090.45 ms /    68 runs   (   30.74 ms per token,    32.53 tokens per second)\n",
      "llama_print_timings:       total time =  4106.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.23 ms /    58 runs   (    0.71 ms per token,  1406.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1790.65 ms /   529 tokens (    3.38 ms per token,   295.42 tokens per second)\n",
      "llama_print_timings:        eval time =  1696.85 ms /    57 runs   (   29.77 ms per token,    33.59 tokens per second)\n",
      "llama_print_timings:       total time =  3591.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    59.40 ms /    83 runs   (    0.72 ms per token,  1397.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1797.06 ms /   543 tokens (    3.31 ms per token,   302.16 tokens per second)\n",
      "llama_print_timings:        eval time =  2455.60 ms /    82 runs   (   29.95 ms per token,    33.39 tokens per second)\n",
      "llama_print_timings:       total time =  4404.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.98 ms /    53 runs   (    0.72 ms per token,  1395.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1793.50 ms /   542 tokens (    3.31 ms per token,   302.20 tokens per second)\n",
      "llama_print_timings:        eval time =  1555.39 ms /    52 runs   (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_print_timings:       total time =  3444.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.59 ms /    59 runs   (    0.70 ms per token,  1418.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1786.60 ms /   532 tokens (    3.36 ms per token,   297.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1751.66 ms /    58 runs   (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:       total time =  3647.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.00 ms /    53 runs   (    0.72 ms per token,  1394.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1628.33 ms /   510 tokens (    3.19 ms per token,   313.20 tokens per second)\n",
      "llama_print_timings:        eval time =  1546.49 ms /    52 runs   (   29.74 ms per token,    33.62 tokens per second)\n",
      "llama_print_timings:       total time =  3269.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    46.52 ms /    64 runs   (    0.73 ms per token,  1375.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1782.76 ms /   521 tokens (    3.42 ms per token,   292.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1877.42 ms /    63 runs   (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_print_timings:       total time =  3778.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.04 ms /    49 runs   (    0.72 ms per token,  1398.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1866.02 ms /   557 tokens (    3.35 ms per token,   298.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1439.55 ms /    48 runs   (   29.99 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:       total time =  3392.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   180.98 ms /   256 runs   (    0.71 ms per token,  1414.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1767.86 ms /   515 tokens (    3.43 ms per token,   291.31 tokens per second)\n",
      "llama_print_timings:        eval time =  7769.92 ms /   255 runs   (   30.47 ms per token,    32.82 tokens per second)\n",
      "llama_print_timings:       total time = 10013.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.60 ms /    54 runs   (    0.70 ms per token,  1436.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   787.66 ms /   235 tokens (    3.35 ms per token,   298.35 tokens per second)\n",
      "llama_print_timings:        eval time =  1526.70 ms /    53 runs   (   28.81 ms per token,    34.72 tokens per second)\n",
      "llama_print_timings:       total time =  2409.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.82 ms /    33 runs   (    0.72 ms per token,  1385.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1872.25 ms /   567 tokens (    3.30 ms per token,   302.84 tokens per second)\n",
      "llama_print_timings:        eval time =   951.56 ms /    32 runs   (   29.74 ms per token,    33.63 tokens per second)\n",
      "llama_print_timings:       total time =  2886.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.60 ms /    41 runs   (    0.70 ms per token,  1433.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1770.52 ms /   516 tokens (    3.43 ms per token,   291.44 tokens per second)\n",
      "llama_print_timings:        eval time =  1186.50 ms /    40 runs   (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:       total time =  3031.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.37 ms /    43 runs   (    0.71 ms per token,  1416.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1858.88 ms /   546 tokens (    3.40 ms per token,   293.73 tokens per second)\n",
      "llama_print_timings:        eval time =  1249.94 ms /    42 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  3186.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.11 ms /    44 runs   (    0.71 ms per token,  1414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   978.23 ms /   316 tokens (    3.10 ms per token,   323.03 tokens per second)\n",
      "llama_print_timings:        eval time =  1241.31 ms /    43 runs   (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_print_timings:       total time =  2298.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.31 ms /    41 runs   (    0.71 ms per token,  1398.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   866.14 ms /   269 tokens (    3.22 ms per token,   310.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1147.92 ms /    40 runs   (   28.70 ms per token,    34.85 tokens per second)\n",
      "llama_print_timings:       total time =  2085.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.74 ms /    39 runs   (    0.71 ms per token,  1405.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   879.52 ms /   276 tokens (    3.19 ms per token,   313.81 tokens per second)\n",
      "llama_print_timings:        eval time =  1079.25 ms /    38 runs   (   28.40 ms per token,    35.21 tokens per second)\n",
      "llama_print_timings:       total time =  2031.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   179.31 ms /   256 runs   (    0.70 ms per token,  1427.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1895.37 ms /   553 tokens (    3.43 ms per token,   291.76 tokens per second)\n",
      "llama_print_timings:        eval time =  7797.75 ms /   255 runs   (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_print_timings:       total time = 10174.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.83 ms /    39 runs   (    0.71 ms per token,  1401.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1988.50 ms /   592 tokens (    3.36 ms per token,   297.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1145.00 ms /    38 runs   (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_print_timings:       total time =  3203.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.20 ms /    53 runs   (    0.70 ms per token,  1424.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2072.74 ms /   590 tokens (    3.51 ms per token,   284.65 tokens per second)\n",
      "llama_print_timings:        eval time =  1593.24 ms /    52 runs   (   30.64 ms per token,    32.64 tokens per second)\n",
      "llama_print_timings:       total time =  3764.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.71 ms /    51 runs   (    0.70 ms per token,  1428.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1975.62 ms /   566 tokens (    3.49 ms per token,   286.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1502.08 ms /    50 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3574.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.05 ms /    57 runs   (    0.72 ms per token,  1388.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1950.41 ms /   567 tokens (    3.44 ms per token,   290.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1689.52 ms /    56 runs   (   30.17 ms per token,    33.15 tokens per second)\n",
      "llama_print_timings:       total time =  3744.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   184.06 ms /   256 runs   (    0.72 ms per token,  1390.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2016.79 ms /   577 tokens (    3.50 ms per token,   286.10 tokens per second)\n",
      "llama_print_timings:        eval time =  7759.08 ms /   255 runs   (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_print_timings:       total time = 10269.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.25 ms /   256 runs   (    0.71 ms per token,  1404.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1873.43 ms /   572 tokens (    3.28 ms per token,   305.32 tokens per second)\n",
      "llama_print_timings:        eval time =  7800.19 ms /   255 runs   (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_print_timings:       total time = 10169.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.14 ms /    37 runs   (    0.71 ms per token,  1415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1991.13 ms /   579 tokens (    3.44 ms per token,   290.79 tokens per second)\n",
      "llama_print_timings:        eval time =  1092.99 ms /    36 runs   (   30.36 ms per token,    32.94 tokens per second)\n",
      "llama_print_timings:       total time =  3153.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.40 ms /    45 runs   (    0.70 ms per token,  1433.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1983.72 ms /   585 tokens (    3.39 ms per token,   294.90 tokens per second)\n",
      "llama_print_timings:        eval time =  1324.43 ms /    44 runs   (   30.10 ms per token,    33.22 tokens per second)\n",
      "llama_print_timings:       total time =  3386.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.31 ms /   256 runs   (    0.71 ms per token,  1404.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1980.60 ms /   583 tokens (    3.40 ms per token,   294.36 tokens per second)\n",
      "llama_print_timings:        eval time =  7779.16 ms /   255 runs   (   30.51 ms per token,    32.78 tokens per second)\n",
      "llama_print_timings:       total time = 10230.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.13 ms /    47 runs   (    0.75 ms per token,  1337.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1868.91 ms /   568 tokens (    3.29 ms per token,   303.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1375.46 ms /    46 runs   (   29.90 ms per token,    33.44 tokens per second)\n",
      "llama_print_timings:       total time =  3334.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.85 ms /    40 runs   (    0.70 ms per token,  1436.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1985.10 ms /   586 tokens (    3.39 ms per token,   295.20 tokens per second)\n",
      "llama_print_timings:        eval time =  1195.56 ms /    39 runs   (   30.66 ms per token,    32.62 tokens per second)\n",
      "llama_print_timings:       total time =  3254.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.03 ms /    47 runs   (    0.70 ms per token,  1422.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =   672.54 ms /   194 tokens (    3.47 ms per token,   288.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1299.86 ms /    46 runs   (   28.26 ms per token,    35.39 tokens per second)\n",
      "llama_print_timings:       total time =  2058.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.17 ms /    47 runs   (    0.71 ms per token,  1416.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1791.79 ms /   540 tokens (    3.32 ms per token,   301.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1370.87 ms /    46 runs   (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_print_timings:       total time =  3250.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   180.37 ms /   256 runs   (    0.70 ms per token,  1419.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   979.70 ms /   308 tokens (    3.18 ms per token,   314.38 tokens per second)\n",
      "llama_print_timings:        eval time =  7449.21 ms /   255 runs   (   29.21 ms per token,    34.23 tokens per second)\n",
      "llama_print_timings:       total time =  8916.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.66 ms /    39 runs   (    0.71 ms per token,  1410.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2110.02 ms /   617 tokens (    3.42 ms per token,   292.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1143.25 ms /    38 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3323.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.64 ms /    35 runs   (    0.70 ms per token,  1420.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2251.44 ms /   643 tokens (    3.50 ms per token,   285.59 tokens per second)\n",
      "llama_print_timings:        eval time =  1026.35 ms /    34 runs   (   30.19 ms per token,    33.13 tokens per second)\n",
      "llama_print_timings:       total time =  3340.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.89 ms /    42 runs   (    0.71 ms per token,  1405.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2062.51 ms /   595 tokens (    3.47 ms per token,   288.48 tokens per second)\n",
      "llama_print_timings:        eval time =  1231.66 ms /    41 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3370.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.45 ms /    50 runs   (    0.71 ms per token,  1410.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2264.49 ms /   649 tokens (    3.49 ms per token,   286.60 tokens per second)\n",
      "llama_print_timings:        eval time =  1484.83 ms /    49 runs   (   30.30 ms per token,    33.00 tokens per second)\n",
      "llama_print_timings:       total time =  3840.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.89 ms /    39 runs   (    0.72 ms per token,  1398.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1846.95 ms /   532 tokens (    3.47 ms per token,   288.04 tokens per second)\n",
      "llama_print_timings:        eval time =  1127.33 ms /    38 runs   (   29.67 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:       total time =  3046.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.27 ms /    44 runs   (    0.71 ms per token,  1407.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2064.34 ms /   593 tokens (    3.48 ms per token,   287.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1298.09 ms /    43 runs   (   30.19 ms per token,    33.13 tokens per second)\n",
      "llama_print_timings:       total time =  3440.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.80 ms /    36 runs   (    0.72 ms per token,  1395.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2031.51 ms /   579 tokens (    3.51 ms per token,   285.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1045.29 ms /    35 runs   (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_print_timings:       total time =  3144.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.28 ms /    47 runs   (    0.71 ms per token,  1412.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1929.44 ms /   569 tokens (    3.39 ms per token,   294.90 tokens per second)\n",
      "llama_print_timings:        eval time =  1370.54 ms /    46 runs   (   29.79 ms per token,    33.56 tokens per second)\n",
      "llama_print_timings:       total time =  3386.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.81 ms /    44 runs   (    0.72 ms per token,  1383.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2148.87 ms /   613 tokens (    3.51 ms per token,   285.27 tokens per second)\n",
      "llama_print_timings:        eval time =  1293.68 ms /    43 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3523.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    19.80 ms /    28 runs   (    0.71 ms per token,  1414.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2064.08 ms /   596 tokens (    3.46 ms per token,   288.75 tokens per second)\n",
      "llama_print_timings:        eval time =   810.59 ms /    27 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  2926.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.28 ms /    52 runs   (    0.72 ms per token,  1394.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1933.00 ms /   564 tokens (    3.43 ms per token,   291.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1524.72 ms /    51 runs   (   29.90 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  3550.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.06 ms /    43 runs   (    0.72 ms per token,  1384.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2041.44 ms /   580 tokens (    3.52 ms per token,   284.11 tokens per second)\n",
      "llama_print_timings:        eval time =  1261.65 ms /    42 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3382.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.49 ms /    52 runs   (    0.70 ms per token,  1424.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2056.31 ms /   600 tokens (    3.43 ms per token,   291.78 tokens per second)\n",
      "llama_print_timings:        eval time =  1532.29 ms /    51 runs   (   30.04 ms per token,    33.28 tokens per second)\n",
      "llama_print_timings:       total time =  3680.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.48 ms /    46 runs   (    0.71 ms per token,  1416.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1921.55 ms /   561 tokens (    3.43 ms per token,   291.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1347.72 ms /    45 runs   (   29.95 ms per token,    33.39 tokens per second)\n",
      "llama_print_timings:       total time =  3351.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.87 ms /    46 runs   (    0.71 ms per token,  1399.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2042.45 ms /   590 tokens (    3.46 ms per token,   288.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1397.32 ms /    45 runs   (   31.05 ms per token,    32.20 tokens per second)\n",
      "llama_print_timings:       total time =  3530.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.85 ms /    52 runs   (    0.73 ms per token,  1373.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2089.17 ms /   579 tokens (    3.61 ms per token,   277.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1542.68 ms /    51 runs   (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_print_timings:       total time =  3734.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.08 ms /    33 runs   (    0.73 ms per token,  1370.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1873.18 ms /   542 tokens (    3.46 ms per token,   289.35 tokens per second)\n",
      "llama_print_timings:        eval time =   943.61 ms /    32 runs   (   29.49 ms per token,    33.91 tokens per second)\n",
      "llama_print_timings:       total time =  2881.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.94 ms /    46 runs   (    0.72 ms per token,  1396.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1952.07 ms /   556 tokens (    3.51 ms per token,   284.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1336.88 ms /    45 runs   (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_print_timings:       total time =  3374.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.08 ms /    50 runs   (    0.74 ms per token,  1348.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2065.28 ms /   585 tokens (    3.53 ms per token,   283.25 tokens per second)\n",
      "llama_print_timings:        eval time =  1466.58 ms /    49 runs   (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_print_timings:       total time =  3624.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.57 ms /    41 runs   (    0.72 ms per token,  1386.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1932.65 ms /   576 tokens (    3.36 ms per token,   298.04 tokens per second)\n",
      "llama_print_timings:        eval time =  1197.22 ms /    40 runs   (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_print_timings:       total time =  3205.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.74 ms /    40 runs   (    0.72 ms per token,  1391.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1846.67 ms /   543 tokens (    3.40 ms per token,   294.04 tokens per second)\n",
      "llama_print_timings:        eval time =  1157.20 ms /    39 runs   (   29.67 ms per token,    33.70 tokens per second)\n",
      "llama_print_timings:       total time =  3079.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.73 ms /    41 runs   (    0.70 ms per token,  1427.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1842.92 ms /   523 tokens (    3.52 ms per token,   283.79 tokens per second)\n",
      "llama_print_timings:        eval time =  1192.71 ms /    40 runs   (   29.82 ms per token,    33.54 tokens per second)\n",
      "llama_print_timings:       total time =  3108.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.68 ms /    45 runs   (    0.70 ms per token,  1420.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1939.71 ms /   560 tokens (    3.46 ms per token,   288.70 tokens per second)\n",
      "llama_print_timings:        eval time =  1314.88 ms /    44 runs   (   29.88 ms per token,    33.46 tokens per second)\n",
      "llama_print_timings:       total time =  3335.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.49 ms /    40 runs   (    0.71 ms per token,  1404.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1966.36 ms /   568 tokens (    3.46 ms per token,   288.86 tokens per second)\n",
      "llama_print_timings:        eval time =  1169.61 ms /    39 runs   (   29.99 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:       total time =  3209.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.50 ms /    53 runs   (    0.71 ms per token,  1413.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1667.51 ms /   483 tokens (    3.45 ms per token,   289.65 tokens per second)\n",
      "llama_print_timings:        eval time =  1537.00 ms /    52 runs   (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_print_timings:       total time =  3299.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.04 ms /    49 runs   (    0.72 ms per token,  1398.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1528.21 ms /   473 tokens (    3.23 ms per token,   309.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1412.94 ms /    48 runs   (   29.44 ms per token,    33.97 tokens per second)\n",
      "llama_print_timings:       total time =  3036.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.37 ms /    38 runs   (    0.69 ms per token,  1440.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1969.95 ms /   575 tokens (    3.43 ms per token,   291.89 tokens per second)\n",
      "llama_print_timings:        eval time =  1108.44 ms /    37 runs   (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_print_timings:       total time =  3145.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.18 ms /    43 runs   (    0.73 ms per token,  1379.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1994.76 ms /   560 tokens (    3.56 ms per token,   280.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1250.01 ms /    42 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  3328.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.53 ms /    44 runs   (    0.72 ms per token,  1395.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2001.03 ms /   567 tokens (    3.53 ms per token,   283.35 tokens per second)\n",
      "llama_print_timings:        eval time =  1287.48 ms /    43 runs   (   29.94 ms per token,    33.40 tokens per second)\n",
      "llama_print_timings:       total time =  3368.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.82 ms /    40 runs   (    0.70 ms per token,  1437.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2090.52 ms /   597 tokens (    3.50 ms per token,   285.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1172.05 ms /    39 runs   (   30.05 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3335.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.59 ms /    47 runs   (    0.71 ms per token,  1399.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2053.74 ms /   580 tokens (    3.54 ms per token,   282.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1372.77 ms /    46 runs   (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_print_timings:       total time =  3513.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.45 ms /    51 runs   (    0.73 ms per token,  1362.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1916.46 ms /   556 tokens (    3.45 ms per token,   290.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1481.22 ms /    50 runs   (   29.62 ms per token,    33.76 tokens per second)\n",
      "llama_print_timings:       total time =  3492.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.12 ms /    46 runs   (    0.70 ms per token,  1432.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2045.74 ms /   587 tokens (    3.49 ms per token,   286.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1339.35 ms /    45 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  3470.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.00 ms /    44 runs   (    0.70 ms per token,  1419.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2055.51 ms /   589 tokens (    3.49 ms per token,   286.55 tokens per second)\n",
      "llama_print_timings:        eval time =  1277.02 ms /    43 runs   (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_print_timings:       total time =  3414.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.73 ms /    40 runs   (    0.72 ms per token,  1392.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2077.88 ms /   597 tokens (    3.48 ms per token,   287.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1171.79 ms /    39 runs   (   30.05 ms per token,    33.28 tokens per second)\n",
      "llama_print_timings:       total time =  3325.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.11 ms /    46 runs   (    0.72 ms per token,  1389.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2164.12 ms /   613 tokens (    3.53 ms per token,   283.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1367.29 ms /    45 runs   (   30.38 ms per token,    32.91 tokens per second)\n",
      "llama_print_timings:       total time =  3620.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.36 ms /    56 runs   (    0.70 ms per token,  1422.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2056.80 ms /   578 tokens (    3.56 ms per token,   281.02 tokens per second)\n",
      "llama_print_timings:        eval time =  1640.77 ms /    55 runs   (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_print_timings:       total time =  3799.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.07 ms /    45 runs   (    0.67 ms per token,  1496.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1941.86 ms /   574 tokens (    3.38 ms per token,   295.59 tokens per second)\n",
      "llama_print_timings:        eval time =  1315.27 ms /    44 runs   (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  3337.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.21 ms /    53 runs   (    0.70 ms per token,  1424.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2086.99 ms /   606 tokens (    3.44 ms per token,   290.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1564.41 ms /    52 runs   (   30.08 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3748.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.00 ms /    50 runs   (    0.70 ms per token,  1428.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2058.84 ms /   588 tokens (    3.50 ms per token,   285.60 tokens per second)\n",
      "llama_print_timings:        eval time =  1474.60 ms /    49 runs   (   30.09 ms per token,    33.23 tokens per second)\n",
      "llama_print_timings:       total time =  3622.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.80 ms /    38 runs   (    0.71 ms per token,  1417.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2046.58 ms /   596 tokens (    3.43 ms per token,   291.22 tokens per second)\n",
      "llama_print_timings:        eval time =  1112.14 ms /    37 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3225.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.91 ms /    37 runs   (    0.70 ms per token,  1428.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2035.56 ms /   588 tokens (    3.46 ms per token,   288.86 tokens per second)\n",
      "llama_print_timings:        eval time =  1082.21 ms /    36 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3186.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.35 ms /    45 runs   (    0.70 ms per token,  1435.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2053.32 ms /   602 tokens (    3.41 ms per token,   293.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1326.29 ms /    44 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  3460.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.40 ms /    51 runs   (    0.77 ms per token,  1294.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   783.95 ms /   247 tokens (    3.17 ms per token,   315.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1406.90 ms /    50 runs   (   28.14 ms per token,    35.54 tokens per second)\n",
      "llama_print_timings:       total time =  2292.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.82 ms /   256 runs   (    0.72 ms per token,  1392.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =   481.44 ms /   141 tokens (    3.41 ms per token,   292.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7242.02 ms /   255 runs   (   28.40 ms per token,    35.21 tokens per second)\n",
      "llama_print_timings:       total time =  8205.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.07 ms /    50 runs   (    0.72 ms per token,  1386.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2002.12 ms /   608 tokens (    3.29 ms per token,   303.68 tokens per second)\n",
      "llama_print_timings:        eval time =  1470.28 ms /    49 runs   (   30.01 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  3563.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.16 ms /    46 runs   (    0.70 ms per token,  1430.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1988.28 ms /   578 tokens (    3.44 ms per token,   290.70 tokens per second)\n",
      "llama_print_timings:        eval time =  1355.73 ms /    45 runs   (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_print_timings:       total time =  3425.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.13 ms /    42 runs   (    0.69 ms per token,  1441.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2229.54 ms /   662 tokens (    3.37 ms per token,   296.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1246.16 ms /    41 runs   (   30.39 ms per token,    32.90 tokens per second)\n",
      "llama_print_timings:       total time =  3551.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.87 ms /    38 runs   (    0.73 ms per token,  1363.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2364.57 ms /   701 tokens (    3.37 ms per token,   296.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1114.99 ms /    37 runs   (   30.13 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  3553.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.70 ms /    52 runs   (    0.71 ms per token,  1416.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2377.71 ms /   694 tokens (    3.43 ms per token,   291.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1553.26 ms /    51 runs   (   30.46 ms per token,    32.83 tokens per second)\n",
      "llama_print_timings:       total time =  4026.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.95 ms /    46 runs   (    0.74 ms per token,  1354.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2349.75 ms /   684 tokens (    3.44 ms per token,   291.09 tokens per second)\n",
      "llama_print_timings:        eval time =  1357.81 ms /    45 runs   (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3796.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.68 ms /    38 runs   (    0.73 ms per token,  1372.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1930.73 ms /   566 tokens (    3.41 ms per token,   293.15 tokens per second)\n",
      "llama_print_timings:        eval time =  1103.60 ms /    37 runs   (   29.83 ms per token,    33.53 tokens per second)\n",
      "llama_print_timings:       total time =  3104.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.36 ms /    52 runs   (    0.72 ms per token,  1391.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =   393.72 ms /   107 tokens (    3.68 ms per token,   271.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1426.20 ms /    51 runs   (   27.96 ms per token,    35.76 tokens per second)\n",
      "llama_print_timings:       total time =  1913.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.20 ms /    33 runs   (    0.70 ms per token,  1422.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =   217.29 ms /    56 tokens (    3.88 ms per token,   257.72 tokens per second)\n",
      "llama_print_timings:        eval time =   885.72 ms /    32 runs   (   27.68 ms per token,    36.13 tokens per second)\n",
      "llama_print_timings:       total time =  1163.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.05 ms /    41 runs   (    0.71 ms per token,  1411.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1808.67 ms /   532 tokens (    3.40 ms per token,   294.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1186.11 ms /    40 runs   (   29.65 ms per token,    33.72 tokens per second)\n",
      "llama_print_timings:       total time =  3069.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.80 ms /    43 runs   (    0.76 ms per token,  1311.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1633.76 ms /   498 tokens (    3.28 ms per token,   304.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1225.37 ms /    42 runs   (   29.18 ms per token,    34.28 tokens per second)\n",
      "llama_print_timings:       total time =  2942.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.06 ms /    49 runs   (    0.70 ms per token,  1438.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1415.46 ms /   428 tokens (    3.31 ms per token,   302.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1401.69 ms /    48 runs   (   29.20 ms per token,    34.24 tokens per second)\n",
      "llama_print_timings:       total time =  2904.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.67 ms /   256 runs   (    0.72 ms per token,  1393.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1396.31 ms /   418 tokens (    3.34 ms per token,   299.36 tokens per second)\n",
      "llama_print_timings:        eval time =  7529.45 ms /   255 runs   (   29.53 ms per token,    33.87 tokens per second)\n",
      "llama_print_timings:       total time =  9408.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    52.69 ms /    73 runs   (    0.72 ms per token,  1385.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1607.90 ms /   488 tokens (    3.29 ms per token,   303.50 tokens per second)\n",
      "llama_print_timings:        eval time =  2122.84 ms /    72 runs   (   29.48 ms per token,    33.92 tokens per second)\n",
      "llama_print_timings:       total time =  3864.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.43 ms /    45 runs   (    0.72 ms per token,  1387.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1784.47 ms /   517 tokens (    3.45 ms per token,   289.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1301.36 ms /    44 runs   (   29.58 ms per token,    33.81 tokens per second)\n",
      "llama_print_timings:       total time =  3167.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.14 ms /   256 runs   (    0.71 ms per token,  1405.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1633.68 ms /   501 tokens (    3.26 ms per token,   306.67 tokens per second)\n",
      "llama_print_timings:        eval time =  7654.59 ms /   255 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  9765.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.83 ms /    50 runs   (    0.72 ms per token,  1395.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1287.04 ms /   408 tokens (    3.15 ms per token,   317.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1418.17 ms /    49 runs   (   28.94 ms per token,    34.55 tokens per second)\n",
      "llama_print_timings:       total time =  2796.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.49 ms /    43 runs   (    0.71 ms per token,  1410.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   324.59 ms /    89 tokens (    3.65 ms per token,   274.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1170.76 ms /    42 runs   (   27.88 ms per token,    35.87 tokens per second)\n",
      "llama_print_timings:       total time =  1570.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.30 ms /    48 runs   (    0.71 ms per token,  1399.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1187.57 ms /   381 tokens (    3.12 ms per token,   320.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1369.75 ms /    47 runs   (   29.14 ms per token,    34.31 tokens per second)\n",
      "llama_print_timings:       total time =  2642.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.57 ms /    43 runs   (    0.71 ms per token,  1406.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1625.36 ms /   493 tokens (    3.30 ms per token,   303.32 tokens per second)\n",
      "llama_print_timings:        eval time =  1247.45 ms /    42 runs   (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_print_timings:       total time =  2946.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.95 ms /    45 runs   (    0.82 ms per token,  1217.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1783.14 ms /   527 tokens (    3.38 ms per token,   295.55 tokens per second)\n",
      "llama_print_timings:        eval time =  1285.19 ms /    44 runs   (   29.21 ms per token,    34.24 tokens per second)\n",
      "llama_print_timings:       total time =  3165.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.11 ms /    44 runs   (    0.71 ms per token,  1414.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1769.43 ms /   515 tokens (    3.44 ms per token,   291.05 tokens per second)\n",
      "llama_print_timings:        eval time =  1266.77 ms /    43 runs   (   29.46 ms per token,    33.94 tokens per second)\n",
      "llama_print_timings:       total time =  3124.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    65.93 ms /    90 runs   (    0.73 ms per token,  1365.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1521.46 ms /   466 tokens (    3.26 ms per token,   306.28 tokens per second)\n",
      "llama_print_timings:        eval time =  2602.17 ms /    89 runs   (   29.24 ms per token,    34.20 tokens per second)\n",
      "llama_print_timings:       total time =  4311.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.49 ms /    35 runs   (    0.70 ms per token,  1429.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1767.02 ms /   501 tokens (    3.53 ms per token,   283.53 tokens per second)\n",
      "llama_print_timings:        eval time =  1008.10 ms /    34 runs   (   29.65 ms per token,    33.73 tokens per second)\n",
      "llama_print_timings:       total time =  2837.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.24 ms /    30 runs   (    0.71 ms per token,  1412.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1266.51 ms /   377 tokens (    3.36 ms per token,   297.67 tokens per second)\n",
      "llama_print_timings:        eval time =   847.84 ms /    29 runs   (   29.24 ms per token,    34.20 tokens per second)\n",
      "llama_print_timings:       total time =  2167.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    47.69 ms /    69 runs   (    0.69 ms per token,  1446.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =   894.10 ms /   259 tokens (    3.45 ms per token,   289.68 tokens per second)\n",
      "llama_print_timings:        eval time =  2009.55 ms /    68 runs   (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_print_timings:       total time =  3031.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    63.89 ms /    91 runs   (    0.70 ms per token,  1424.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   337.01 ms /    88 tokens (    3.83 ms per token,   261.12 tokens per second)\n",
      "llama_print_timings:        eval time =  2505.08 ms /    90 runs   (   27.83 ms per token,    35.93 tokens per second)\n",
      "llama_print_timings:       total time =  3011.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   168.18 ms /   236 runs   (    0.71 ms per token,  1403.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   689.24 ms /   197 tokens (    3.50 ms per token,   285.82 tokens per second)\n",
      "llama_print_timings:        eval time =  6708.69 ms /   235 runs   (   28.55 ms per token,    35.03 tokens per second)\n",
      "llama_print_timings:       total time =  7843.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.37 ms /    50 runs   (    0.71 ms per token,  1413.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   322.22 ms /    77 tokens (    4.18 ms per token,   238.97 tokens per second)\n",
      "llama_print_timings:        eval time =  1360.24 ms /    49 runs   (   27.76 ms per token,    36.02 tokens per second)\n",
      "llama_print_timings:       total time =  1771.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    62.45 ms /    86 runs   (    0.73 ms per token,  1377.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1821.16 ms /   531 tokens (    3.43 ms per token,   291.57 tokens per second)\n",
      "llama_print_timings:        eval time =  2517.60 ms /    85 runs   (   29.62 ms per token,    33.76 tokens per second)\n",
      "llama_print_timings:       total time =  4498.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.93 ms /   256 runs   (    0.72 ms per token,  1391.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1194.31 ms /   372 tokens (    3.21 ms per token,   311.48 tokens per second)\n",
      "llama_print_timings:        eval time =  7484.79 ms /   255 runs   (   29.35 ms per token,    34.07 tokens per second)\n",
      "llama_print_timings:       total time =  9166.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.70 ms /    51 runs   (    0.70 ms per token,  1428.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   587.30 ms /   181 tokens (    3.24 ms per token,   308.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1394.95 ms /    50 runs   (   27.90 ms per token,    35.84 tokens per second)\n",
      "llama_print_timings:       total time =  2074.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.43 ms /   256 runs   (    0.72 ms per token,  1395.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1501.61 ms /   469 tokens (    3.20 ms per token,   312.33 tokens per second)\n",
      "llama_print_timings:        eval time =  7617.24 ms /   255 runs   (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_print_timings:       total time =  9598.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   179.57 ms /   256 runs   (    0.70 ms per token,  1425.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1624.52 ms /   503 tokens (    3.23 ms per token,   309.63 tokens per second)\n",
      "llama_print_timings:        eval time =  7661.11 ms /   255 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  9752.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.90 ms /    48 runs   (    0.73 ms per token,  1375.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   688.39 ms /   208 tokens (    3.31 ms per token,   302.16 tokens per second)\n",
      "llama_print_timings:        eval time =  1329.22 ms /    47 runs   (   28.28 ms per token,    35.36 tokens per second)\n",
      "llama_print_timings:       total time =  2103.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.02 ms /    30 runs   (    0.73 ms per token,  1362.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1287.61 ms /   404 tokens (    3.19 ms per token,   313.76 tokens per second)\n",
      "llama_print_timings:        eval time =   846.58 ms /    29 runs   (   29.19 ms per token,    34.26 tokens per second)\n",
      "llama_print_timings:       total time =  2187.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.30 ms /    53 runs   (    0.72 ms per token,  1383.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   767.16 ms /   232 tokens (    3.31 ms per token,   302.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1465.44 ms /    52 runs   (   28.18 ms per token,    35.48 tokens per second)\n",
      "llama_print_timings:       total time =  2329.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.81 ms /    49 runs   (    0.71 ms per token,  1407.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =   395.81 ms /   118 tokens (    3.35 ms per token,   298.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1337.07 ms /    48 runs   (   27.86 ms per token,    35.90 tokens per second)\n",
      "llama_print_timings:       total time =  1824.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.93 ms /    52 runs   (    0.71 ms per token,  1407.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =   217.82 ms /    64 tokens (    3.40 ms per token,   293.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1409.60 ms /    51 runs   (   27.64 ms per token,    36.18 tokens per second)\n",
      "llama_print_timings:       total time =  1720.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   180.22 ms /   256 runs   (    0.70 ms per token,  1420.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1871.29 ms /   561 tokens (    3.34 ms per token,   299.79 tokens per second)\n",
      "llama_print_timings:        eval time =  7812.07 ms /   255 runs   (   30.64 ms per token,    32.64 tokens per second)\n",
      "llama_print_timings:       total time = 10172.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   179.85 ms /   256 runs   (    0.70 ms per token,  1423.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1897.91 ms /   557 tokens (    3.41 ms per token,   293.48 tokens per second)\n",
      "llama_print_timings:        eval time =  7729.42 ms /   255 runs   (   30.31 ms per token,    32.99 tokens per second)\n",
      "llama_print_timings:       total time = 10108.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.05 ms /    43 runs   (    0.72 ms per token,  1385.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1789.38 ms /   540 tokens (    3.31 ms per token,   301.78 tokens per second)\n",
      "llama_print_timings:        eval time =  1249.18 ms /    42 runs   (   29.74 ms per token,    33.62 tokens per second)\n",
      "llama_print_timings:       total time =  3118.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.20 ms /    49 runs   (    0.70 ms per token,  1432.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2191.91 ms /   644 tokens (    3.40 ms per token,   293.81 tokens per second)\n",
      "llama_print_timings:        eval time =  1448.25 ms /    48 runs   (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3730.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.87 ms /    40 runs   (    0.70 ms per token,  1435.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1421.12 ms /   426 tokens (    3.34 ms per token,   299.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1133.41 ms /    39 runs   (   29.06 ms per token,    34.41 tokens per second)\n",
      "llama_print_timings:       total time =  2626.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.38 ms /   256 runs   (    0.72 ms per token,  1396.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1665.69 ms /   499 tokens (    3.34 ms per token,   299.58 tokens per second)\n",
      "llama_print_timings:        eval time =  7679.58 ms /   255 runs   (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_print_timings:       total time =  9840.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.36 ms /    42 runs   (    0.72 ms per token,  1383.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1853.30 ms /   540 tokens (    3.43 ms per token,   291.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1218.88 ms /    41 runs   (   29.73 ms per token,    33.64 tokens per second)\n",
      "llama_print_timings:       total time =  3150.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.02 ms /    43 runs   (    0.70 ms per token,  1432.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1848.61 ms /   544 tokens (    3.40 ms per token,   294.28 tokens per second)\n",
      "llama_print_timings:        eval time =  1252.29 ms /    42 runs   (   29.82 ms per token,    33.54 tokens per second)\n",
      "llama_print_timings:       total time =  3177.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.26 ms /    44 runs   (    0.73 ms per token,  1363.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1936.13 ms /   557 tokens (    3.48 ms per token,   287.69 tokens per second)\n",
      "llama_print_timings:        eval time =  1282.26 ms /    43 runs   (   29.82 ms per token,    33.53 tokens per second)\n",
      "llama_print_timings:       total time =  3299.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.78 ms /    49 runs   (    0.71 ms per token,  1408.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1939.91 ms /   547 tokens (    3.55 ms per token,   281.97 tokens per second)\n",
      "llama_print_timings:        eval time =  1433.34 ms /    48 runs   (   29.86 ms per token,    33.49 tokens per second)\n",
      "llama_print_timings:       total time =  3462.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.22 ms /    51 runs   (    0.73 ms per token,  1370.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1476.69 ms /   438 tokens (    3.37 ms per token,   296.61 tokens per second)\n",
      "llama_print_timings:        eval time =  1466.26 ms /    50 runs   (   29.33 ms per token,    34.10 tokens per second)\n",
      "llama_print_timings:       total time =  3038.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.75 ms /    38 runs   (    0.73 ms per token,  1369.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1259.15 ms /   384 tokens (    3.28 ms per token,   304.97 tokens per second)\n",
      "llama_print_timings:        eval time =  1063.61 ms /    37 runs   (   28.75 ms per token,    34.79 tokens per second)\n",
      "llama_print_timings:       total time =  2397.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.56 ms /    40 runs   (    0.69 ms per token,  1451.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   928.35 ms /   288 tokens (    3.22 ms per token,   310.23 tokens per second)\n",
      "llama_print_timings:        eval time =  1122.08 ms /    39 runs   (   28.77 ms per token,    34.76 tokens per second)\n",
      "llama_print_timings:       total time =  2119.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.78 ms /    41 runs   (    0.73 ms per token,  1376.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1712.55 ms /   482 tokens (    3.55 ms per token,   281.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1181.18 ms /    40 runs   (   29.53 ms per token,    33.86 tokens per second)\n",
      "llama_print_timings:       total time =  2968.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.14 ms /    39 runs   (    0.75 ms per token,  1338.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   396.55 ms /   106 tokens (    3.74 ms per token,   267.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1055.56 ms /    38 runs   (   27.78 ms per token,    36.00 tokens per second)\n",
      "llama_print_timings:       total time =  1528.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.44 ms /    44 runs   (    0.76 ms per token,  1315.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   712.68 ms /   224 tokens (    3.18 ms per token,   314.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1218.47 ms /    43 runs   (   28.34 ms per token,    35.29 tokens per second)\n",
      "llama_print_timings:       total time =  2016.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    56.12 ms /    78 runs   (    0.72 ms per token,  1389.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   324.64 ms /    77 tokens (    4.22 ms per token,   237.18 tokens per second)\n",
      "llama_print_timings:        eval time =  2132.46 ms /    77 runs   (   27.69 ms per token,    36.11 tokens per second)\n",
      "llama_print_timings:       total time =  2601.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.62 ms /    45 runs   (    0.70 ms per token,  1423.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   215.82 ms /    35 tokens (    6.17 ms per token,   162.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1246.13 ms /    44 runs   (   28.32 ms per token,    35.31 tokens per second)\n",
      "llama_print_timings:       total time =  1546.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.95 ms /    33 runs   (    0.70 ms per token,  1438.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1485.95 ms /   421 tokens (    3.53 ms per token,   283.32 tokens per second)\n",
      "llama_print_timings:        eval time =   964.75 ms /    32 runs   (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_print_timings:       total time =  2512.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.16 ms /    40 runs   (    0.68 ms per token,  1472.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1501.34 ms /   446 tokens (    3.37 ms per token,   297.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1151.26 ms /    39 runs   (   29.52 ms per token,    33.88 tokens per second)\n",
      "llama_print_timings:       total time =  2723.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    42.15 ms /    60 runs   (    0.70 ms per token,  1423.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1227.04 ms /   355 tokens (    3.46 ms per token,   289.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1700.02 ms /    59 runs   (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_print_timings:       total time =  3035.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    45.49 ms /    63 runs   (    0.72 ms per token,  1385.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1941.24 ms /   543 tokens (    3.58 ms per token,   279.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1927.77 ms /    62 runs   (   31.09 ms per token,    32.16 tokens per second)\n",
      "llama_print_timings:       total time =  3992.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.48 ms /    51 runs   (    0.72 ms per token,  1397.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1145.06 ms /   327 tokens (    3.50 ms per token,   285.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1443.86 ms /    50 runs   (   28.88 ms per token,    34.63 tokens per second)\n",
      "llama_print_timings:       total time =  2690.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.51 ms /    43 runs   (    0.71 ms per token,  1409.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1285.89 ms /   368 tokens (    3.49 ms per token,   286.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1225.81 ms /    42 runs   (   29.19 ms per token,    34.26 tokens per second)\n",
      "llama_print_timings:       total time =  2588.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    58.32 ms /    84 runs   (    0.69 ms per token,  1440.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2033.54 ms /   545 tokens (    3.73 ms per token,   268.01 tokens per second)\n",
      "llama_print_timings:        eval time =  2481.19 ms /    83 runs   (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  4673.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.26 ms /    44 runs   (    0.73 ms per token,  1364.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2060.19 ms /   556 tokens (    3.71 ms per token,   269.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1282.24 ms /    43 runs   (   29.82 ms per token,    33.54 tokens per second)\n",
      "llama_print_timings:       total time =  3427.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.81 ms /    47 runs   (    0.74 ms per token,  1350.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1919.65 ms /   528 tokens (    3.64 ms per token,   275.05 tokens per second)\n",
      "llama_print_timings:        eval time =  1360.28 ms /    46 runs   (   29.57 ms per token,    33.82 tokens per second)\n",
      "llama_print_timings:       total time =  3370.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    40.50 ms /    56 runs   (    0.72 ms per token,  1382.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2007.63 ms /   571 tokens (    3.52 ms per token,   284.42 tokens per second)\n",
      "llama_print_timings:        eval time =  1644.62 ms /    55 runs   (   29.90 ms per token,    33.44 tokens per second)\n",
      "llama_print_timings:       total time =  3755.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.42 ms /    45 runs   (    0.72 ms per token,  1388.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1687.61 ms /   487 tokens (    3.47 ms per token,   288.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1295.18 ms /    44 runs   (   29.44 ms per token,    33.97 tokens per second)\n",
      "llama_print_timings:       total time =  3065.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.64 ms /    44 runs   (    0.72 ms per token,  1390.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2101.49 ms /   587 tokens (    3.58 ms per token,   279.33 tokens per second)\n",
      "llama_print_timings:        eval time =  1291.85 ms /    43 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3473.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.87 ms /    56 runs   (    0.69 ms per token,  1440.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2162.56 ms /   620 tokens (    3.49 ms per token,   286.70 tokens per second)\n",
      "llama_print_timings:        eval time =  1663.00 ms /    55 runs   (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_print_timings:       total time =  3924.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.49 ms /    40 runs   (    0.74 ms per token,  1356.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2035.94 ms /   577 tokens (    3.53 ms per token,   283.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1158.97 ms /    39 runs   (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_print_timings:       total time =  3270.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   183.99 ms /   256 runs   (    0.72 ms per token,  1391.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1942.80 ms /   560 tokens (    3.47 ms per token,   288.24 tokens per second)\n",
      "llama_print_timings:        eval time =  7699.19 ms /   255 runs   (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time = 10145.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.27 ms /    45 runs   (    0.74 ms per token,  1352.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1663.95 ms /   485 tokens (    3.43 ms per token,   291.48 tokens per second)\n",
      "llama_print_timings:        eval time =  1301.05 ms /    44 runs   (   29.57 ms per token,    33.82 tokens per second)\n",
      "llama_print_timings:       total time =  3049.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.88 ms /    40 runs   (    0.70 ms per token,  1434.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1440.61 ms /   434 tokens (    3.32 ms per token,   301.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1167.55 ms /    39 runs   (   29.94 ms per token,    33.40 tokens per second)\n",
      "llama_print_timings:       total time =  2682.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.86 ms /    47 runs   (    0.72 ms per token,  1387.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   895.61 ms /   281 tokens (    3.19 ms per token,   313.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1320.27 ms /    46 runs   (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_print_timings:       total time =  2299.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    73.58 ms /   101 runs   (    0.73 ms per token,  1372.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1719.43 ms /   497 tokens (    3.46 ms per token,   289.05 tokens per second)\n",
      "llama_print_timings:        eval time =  2956.11 ms /   100 runs   (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_print_timings:       total time =  4864.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    53.94 ms /    74 runs   (    0.73 ms per token,  1371.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1554.82 ms /   460 tokens (    3.38 ms per token,   295.85 tokens per second)\n",
      "llama_print_timings:        eval time =  2150.58 ms /    73 runs   (   29.46 ms per token,    33.94 tokens per second)\n",
      "llama_print_timings:       total time =  3842.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.03 ms /    32 runs   (    0.75 ms per token,  1331.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   985.67 ms /   296 tokens (    3.33 ms per token,   300.30 tokens per second)\n",
      "llama_print_timings:        eval time =   877.14 ms /    31 runs   (   28.29 ms per token,    35.34 tokens per second)\n",
      "llama_print_timings:       total time =  1923.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.12 ms /    51 runs   (    0.73 ms per token,  1373.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1701.98 ms /   540 tokens (    3.15 ms per token,   317.28 tokens per second)\n",
      "llama_print_timings:        eval time =  1487.80 ms /    50 runs   (   29.76 ms per token,    33.61 tokens per second)\n",
      "llama_print_timings:       total time =  3284.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.63 ms /    45 runs   (    0.73 ms per token,  1379.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =   317.37 ms /    67 tokens (    4.74 ms per token,   211.11 tokens per second)\n",
      "llama_print_timings:        eval time =  1215.40 ms /    44 runs   (   27.62 ms per token,    36.20 tokens per second)\n",
      "llama_print_timings:       total time =  1615.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    48.80 ms /    68 runs   (    0.72 ms per token,  1393.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1707.97 ms /   512 tokens (    3.34 ms per token,   299.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1993.19 ms /    67 runs   (   29.75 ms per token,    33.61 tokens per second)\n",
      "llama_print_timings:       total time =  3821.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.62 ms /    34 runs   (    0.72 ms per token,  1380.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1854.45 ms /   530 tokens (    3.50 ms per token,   285.80 tokens per second)\n",
      "llama_print_timings:        eval time =   975.95 ms /    33 runs   (   29.57 ms per token,    33.81 tokens per second)\n",
      "llama_print_timings:       total time =  2892.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.71 ms /    50 runs   (    0.71 ms per token,  1400.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1448.22 ms /   438 tokens (    3.31 ms per token,   302.44 tokens per second)\n",
      "llama_print_timings:        eval time =  1437.68 ms /    49 runs   (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_print_timings:       total time =  2974.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   179.94 ms /   256 runs   (    0.70 ms per token,  1422.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1543.40 ms /   460 tokens (    3.36 ms per token,   298.04 tokens per second)\n",
      "llama_print_timings:        eval time =  7607.08 ms /   255 runs   (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_print_timings:       total time =  9626.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.80 ms /    50 runs   (    0.70 ms per token,  1436.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1917.93 ms /   549 tokens (    3.49 ms per token,   286.25 tokens per second)\n",
      "llama_print_timings:        eval time =  1462.83 ms /    49 runs   (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_print_timings:       total time =  3469.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.86 ms /    37 runs   (    0.70 ms per token,  1431.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =   585.88 ms /   174 tokens (    3.37 ms per token,   296.99 tokens per second)\n",
      "llama_print_timings:        eval time =  1008.00 ms /    36 runs   (   28.00 ms per token,    35.71 tokens per second)\n",
      "llama_print_timings:       total time =  1658.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.34 ms /    53 runs   (    0.70 ms per token,  1419.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =   493.72 ms /   154 tokens (    3.21 ms per token,   311.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1462.17 ms /    52 runs   (   28.12 ms per token,    35.56 tokens per second)\n",
      "llama_print_timings:       total time =  2051.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.05 ms /    48 runs   (    0.75 ms per token,  1331.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   482.53 ms /   134 tokens (    3.60 ms per token,   277.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1297.40 ms /    47 runs   (   27.60 ms per token,    36.23 tokens per second)\n",
      "llama_print_timings:       total time =  1872.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.09 ms /    51 runs   (    0.71 ms per token,  1413.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1303.96 ms /   392 tokens (    3.33 ms per token,   300.62 tokens per second)\n",
      "llama_print_timings:        eval time =  1446.88 ms /    50 runs   (   28.94 ms per token,    34.56 tokens per second)\n",
      "llama_print_timings:       total time =  2844.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.42 ms /    35 runs   (    0.70 ms per token,  1433.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   695.00 ms /   215 tokens (    3.23 ms per token,   309.35 tokens per second)\n",
      "llama_print_timings:        eval time =   966.02 ms /    34 runs   (   28.41 ms per token,    35.20 tokens per second)\n",
      "llama_print_timings:       total time =  1721.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   180.63 ms /   256 runs   (    0.71 ms per token,  1417.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1702.48 ms /   500 tokens (    3.40 ms per token,   293.69 tokens per second)\n",
      "llama_print_timings:        eval time =  7681.26 ms /   255 runs   (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_print_timings:       total time =  9851.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.20 ms /    42 runs   (    0.72 ms per token,  1390.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1511.57 ms /   455 tokens (    3.32 ms per token,   301.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1208.81 ms /    41 runs   (   29.48 ms per token,    33.92 tokens per second)\n",
      "llama_print_timings:       total time =  2795.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    74.08 ms /   104 runs   (    0.71 ms per token,  1403.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   399.39 ms /   126 tokens (    3.17 ms per token,   315.48 tokens per second)\n",
      "llama_print_timings:        eval time =  2896.52 ms /   103 runs   (   28.12 ms per token,    35.56 tokens per second)\n",
      "llama_print_timings:       total time =  3482.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.73 ms /    34 runs   (    0.73 ms per token,  1374.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1513.53 ms /   463 tokens (    3.27 ms per token,   305.91 tokens per second)\n",
      "llama_print_timings:        eval time =   967.09 ms /    33 runs   (   29.31 ms per token,    34.12 tokens per second)\n",
      "llama_print_timings:       total time =  2543.40 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.33 ms /    36 runs   (    0.73 ms per token,  1367.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   395.98 ms /   115 tokens (    3.44 ms per token,   290.42 tokens per second)\n",
      "llama_print_timings:        eval time =   971.40 ms /    35 runs   (   27.75 ms per token,    36.03 tokens per second)\n",
      "llama_print_timings:       total time =  1433.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.20 ms /    46 runs   (    0.70 ms per token,  1428.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   791.23 ms /   250 tokens (    3.16 ms per token,   315.96 tokens per second)\n",
      "llama_print_timings:        eval time =  1285.27 ms /    45 runs   (   28.56 ms per token,    35.01 tokens per second)\n",
      "llama_print_timings:       total time =  2157.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.00 ms /    40 runs   (    0.73 ms per token,  1379.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1858.19 ms /   530 tokens (    3.51 ms per token,   285.22 tokens per second)\n",
      "llama_print_timings:        eval time =  1166.51 ms /    39 runs   (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_print_timings:       total time =  3096.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.18 ms /    52 runs   (    0.71 ms per token,  1398.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   644.41 ms /   193 tokens (    3.34 ms per token,   299.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1450.16 ms /    51 runs   (   28.43 ms per token,    35.17 tokens per second)\n",
      "llama_print_timings:       total time =  2185.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.52 ms /    42 runs   (    0.73 ms per token,  1376.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1843.74 ms /   521 tokens (    3.54 ms per token,   282.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1217.33 ms /    41 runs   (   29.69 ms per token,    33.68 tokens per second)\n",
      "llama_print_timings:       total time =  3137.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   180.93 ms /   256 runs   (    0.71 ms per token,  1414.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1534.69 ms /   460 tokens (    3.34 ms per token,   299.74 tokens per second)\n",
      "llama_print_timings:        eval time =  7643.99 ms /   255 runs   (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:       total time =  9647.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.96 ms /    39 runs   (    0.72 ms per token,  1394.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1376.13 ms /   418 tokens (    3.29 ms per token,   303.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1111.22 ms /    38 runs   (   29.24 ms per token,    34.20 tokens per second)\n",
      "llama_print_timings:       total time =  2556.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.13 ms /    39 runs   (    0.72 ms per token,  1386.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1192.47 ms /   380 tokens (    3.14 ms per token,   318.67 tokens per second)\n",
      "llama_print_timings:        eval time =  1104.52 ms /    38 runs   (   29.07 ms per token,    34.40 tokens per second)\n",
      "llama_print_timings:       total time =  2367.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.91 ms /    41 runs   (    0.71 ms per token,  1418.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1089.02 ms /   327 tokens (    3.33 ms per token,   300.27 tokens per second)\n",
      "llama_print_timings:        eval time =  1159.58 ms /    40 runs   (   28.99 ms per token,    34.50 tokens per second)\n",
      "llama_print_timings:       total time =  2320.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.25 ms /    41 runs   (    0.71 ms per token,  1401.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   892.55 ms /   284 tokens (    3.14 ms per token,   318.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1145.21 ms /    40 runs   (   28.63 ms per token,    34.93 tokens per second)\n",
      "llama_print_timings:       total time =  2110.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.21 ms /    42 runs   (    0.72 ms per token,  1390.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =   979.70 ms /   306 tokens (    3.20 ms per token,   312.34 tokens per second)\n",
      "llama_print_timings:        eval time =  1179.62 ms /    41 runs   (   28.77 ms per token,    34.76 tokens per second)\n",
      "llama_print_timings:       total time =  2234.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.97 ms /    36 runs   (    0.72 ms per token,  1386.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1571.10 ms /   477 tokens (    3.29 ms per token,   303.61 tokens per second)\n",
      "llama_print_timings:        eval time =  1034.89 ms /    35 runs   (   29.57 ms per token,    33.82 tokens per second)\n",
      "llama_print_timings:       total time =  2671.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.91 ms /    44 runs   (    0.70 ms per token,  1423.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1928.43 ms /   526 tokens (    3.67 ms per token,   272.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1320.81 ms /    43 runs   (   30.72 ms per token,    32.56 tokens per second)\n",
      "llama_print_timings:       total time =  3330.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.71 ms /    37 runs   (    0.69 ms per token,  1438.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =   813.12 ms /   245 tokens (    3.32 ms per token,   301.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1012.47 ms /    36 runs   (   28.12 ms per token,    35.56 tokens per second)\n",
      "llama_print_timings:       total time =  1895.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.87 ms /    40 runs   (    0.70 ms per token,  1435.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   704.67 ms /   201 tokens (    3.51 ms per token,   285.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1150.05 ms /    39 runs   (   29.49 ms per token,    33.91 tokens per second)\n",
      "llama_print_timings:       total time =  1929.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    75.37 ms /   108 runs   (    0.70 ms per token,  1432.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   219.98 ms /    60 tokens (    3.67 ms per token,   272.75 tokens per second)\n",
      "llama_print_timings:        eval time =  2995.41 ms /   107 runs   (   27.99 ms per token,    35.72 tokens per second)\n",
      "llama_print_timings:       total time =  3416.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.39 ms /    31 runs   (    0.69 ms per token,  1449.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   313.02 ms /    65 tokens (    4.82 ms per token,   207.66 tokens per second)\n",
      "llama_print_timings:        eval time =   901.22 ms /    30 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  1272.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.83 ms /    38 runs   (    0.71 ms per token,  1416.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   327.22 ms /    67 tokens (    4.88 ms per token,   204.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1024.32 ms /    37 runs   (   27.68 ms per token,    36.12 tokens per second)\n",
      "llama_print_timings:       total time =  1419.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.95 ms /    51 runs   (    0.70 ms per token,  1418.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1973.76 ms /   543 tokens (    3.63 ms per token,   275.11 tokens per second)\n",
      "llama_print_timings:        eval time =  1495.14 ms /    50 runs   (   29.90 ms per token,    33.44 tokens per second)\n",
      "llama_print_timings:       total time =  3561.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.80 ms /   256 runs   (    0.69 ms per token,  1448.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1451.08 ms /   396 tokens (    3.66 ms per token,   272.90 tokens per second)\n",
      "llama_print_timings:        eval time =  7588.99 ms /   255 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  9515.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.86 ms /   256 runs   (    0.69 ms per token,  1455.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =   685.44 ms /   201 tokens (    3.41 ms per token,   293.24 tokens per second)\n",
      "llama_print_timings:        eval time =  7281.98 ms /   255 runs   (   28.56 ms per token,    35.02 tokens per second)\n",
      "llama_print_timings:       total time =  8444.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.28 ms /    43 runs   (    0.68 ms per token,  1468.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   500.07 ms /   159 tokens (    3.15 ms per token,   317.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1178.82 ms /    42 runs   (   28.07 ms per token,    35.63 tokens per second)\n",
      "llama_print_timings:       total time =  1752.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.30 ms /    47 runs   (    0.69 ms per token,  1455.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =   653.61 ms /   193 tokens (    3.39 ms per token,   295.28 tokens per second)\n",
      "llama_print_timings:        eval time =  1300.63 ms /    46 runs   (   28.27 ms per token,    35.37 tokens per second)\n",
      "llama_print_timings:       total time =  2036.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.78 ms /    50 runs   (    0.68 ms per token,  1480.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   145.85 ms /    26 tokens (    5.61 ms per token,   178.27 tokens per second)\n",
      "llama_print_timings:        eval time =  1352.55 ms /    49 runs   (   27.60 ms per token,    36.23 tokens per second)\n",
      "llama_print_timings:       total time =  1585.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.54 ms /    40 runs   (    0.69 ms per token,  1452.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =   394.38 ms /   102 tokens (    3.87 ms per token,   258.64 tokens per second)\n",
      "llama_print_timings:        eval time =  1087.17 ms /    39 runs   (   27.88 ms per token,    35.87 tokens per second)\n",
      "llama_print_timings:       total time =  1551.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.98 ms /    41 runs   (    0.68 ms per token,  1465.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1985.36 ms /   562 tokens (    3.53 ms per token,   283.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1195.74 ms /    40 runs   (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  3253.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.83 ms /    49 runs   (    0.69 ms per token,  1448.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2184.84 ms /   627 tokens (    3.48 ms per token,   286.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1456.54 ms /    48 runs   (   30.34 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:       total time =  3726.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.22 ms /    52 runs   (    0.70 ms per token,  1435.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2171.17 ms /   628 tokens (    3.46 ms per token,   289.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1541.55 ms /    51 runs   (   30.23 ms per token,    33.08 tokens per second)\n",
      "llama_print_timings:       total time =  3810.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.11 ms /    42 runs   (    0.69 ms per token,  1442.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2092.17 ms /   580 tokens (    3.61 ms per token,   277.22 tokens per second)\n",
      "llama_print_timings:        eval time =  1235.41 ms /    41 runs   (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_print_timings:       total time =  3401.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.79 ms /    39 runs   (    0.69 ms per token,  1455.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1466.07 ms /   448 tokens (    3.27 ms per token,   305.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1117.60 ms /    38 runs   (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_print_timings:       total time =  2651.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.11 ms /    57 runs   (    0.69 ms per token,  1457.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =   216.90 ms /    50 tokens (    4.34 ms per token,   230.52 tokens per second)\n",
      "llama_print_timings:        eval time =  1543.83 ms /    56 runs   (   27.57 ms per token,    36.27 tokens per second)\n",
      "llama_print_timings:       total time =  1858.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   174.11 ms /   256 runs   (    0.68 ms per token,  1470.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1966.04 ms /   564 tokens (    3.49 ms per token,   286.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7758.20 ms /   255 runs   (   30.42 ms per token,    32.87 tokens per second)\n",
      "llama_print_timings:       total time = 10182.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.28 ms /    53 runs   (    0.67 ms per token,  1502.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   778.59 ms /   242 tokens (    3.22 ms per token,   310.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1480.38 ms /    52 runs   (   28.47 ms per token,    35.13 tokens per second)\n",
      "llama_print_timings:       total time =  2349.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.57 ms /    45 runs   (    0.68 ms per token,  1472.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   324.36 ms /    84 tokens (    3.86 ms per token,   258.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1222.39 ms /    44 runs   (   27.78 ms per token,    35.99 tokens per second)\n",
      "llama_print_timings:       total time =  1622.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    44.51 ms /    65 runs   (    0.68 ms per token,  1460.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   682.47 ms /   196 tokens (    3.48 ms per token,   287.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1807.68 ms /    64 runs   (   28.25 ms per token,    35.40 tokens per second)\n",
      "llama_print_timings:       total time =  2603.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.10 ms /    37 runs   (    0.68 ms per token,  1474.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =   222.50 ms /    63 tokens (    3.53 ms per token,   283.15 tokens per second)\n",
      "llama_print_timings:        eval time =   999.11 ms /    36 runs   (   27.75 ms per token,    36.03 tokens per second)\n",
      "llama_print_timings:       total time =  1284.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    70.01 ms /   102 runs   (    0.69 ms per token,  1456.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =   483.48 ms /   141 tokens (    3.43 ms per token,   291.64 tokens per second)\n",
      "llama_print_timings:        eval time =  2840.74 ms /   101 runs   (   28.13 ms per token,    35.55 tokens per second)\n",
      "llama_print_timings:       total time =  3502.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.01 ms /    38 runs   (    0.68 ms per token,  1460.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =   991.27 ms /   298 tokens (    3.33 ms per token,   300.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1065.09 ms /    37 runs   (   28.79 ms per token,    34.74 tokens per second)\n",
      "llama_print_timings:       total time =  2121.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.33 ms /    34 runs   (    0.69 ms per token,  1457.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   402.60 ms /   128 tokens (    3.15 ms per token,   317.93 tokens per second)\n",
      "llama_print_timings:        eval time =   924.49 ms /    33 runs   (   28.01 ms per token,    35.70 tokens per second)\n",
      "llama_print_timings:       total time =  1386.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.30 ms /    37 runs   (    0.68 ms per token,  1462.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1769.46 ms /   545 tokens (    3.25 ms per token,   308.00 tokens per second)\n",
      "llama_print_timings:        eval time =  1075.64 ms /    36 runs   (   29.88 ms per token,    33.47 tokens per second)\n",
      "llama_print_timings:       total time =  2908.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    44.08 ms /    64 runs   (    0.69 ms per token,  1451.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1868.06 ms /   522 tokens (    3.58 ms per token,   279.43 tokens per second)\n",
      "llama_print_timings:        eval time =  1877.32 ms /    63 runs   (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_print_timings:       total time =  3856.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.46 ms /    40 runs   (    0.69 ms per token,  1456.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1945.79 ms /   547 tokens (    3.56 ms per token,   281.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1164.37 ms /    39 runs   (   29.86 ms per token,    33.49 tokens per second)\n",
      "llama_print_timings:       total time =  3179.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    40.55 ms /    59 runs   (    0.69 ms per token,  1454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1873.54 ms /   543 tokens (    3.45 ms per token,   289.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1738.69 ms /    58 runs   (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:       total time =  3715.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.47 ms /    53 runs   (    0.69 ms per token,  1453.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1964.66 ms /   566 tokens (    3.47 ms per token,   288.09 tokens per second)\n",
      "llama_print_timings:        eval time =  1545.25 ms /    52 runs   (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_print_timings:       total time =  3609.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.33 ms /    31 runs   (    0.69 ms per token,  1453.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2196.50 ms /   588 tokens (    3.74 ms per token,   267.70 tokens per second)\n",
      "llama_print_timings:        eval time =   906.08 ms /    30 runs   (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:       total time =  3158.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.26 ms /    44 runs   (    0.69 ms per token,  1453.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1116.25 ms /   325 tokens (    3.43 ms per token,   291.15 tokens per second)\n",
      "llama_print_timings:        eval time =  1240.21 ms /    43 runs   (   28.84 ms per token,    34.67 tokens per second)\n",
      "llama_print_timings:       total time =  2435.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.66 ms /    37 runs   (    0.69 ms per token,  1442.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1621.59 ms /   472 tokens (    3.44 ms per token,   291.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1062.51 ms /    36 runs   (   29.51 ms per token,    33.88 tokens per second)\n",
      "llama_print_timings:       total time =  2750.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.33 ms /    33 runs   (    0.68 ms per token,  1477.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1636.47 ms /   479 tokens (    3.42 ms per token,   292.70 tokens per second)\n",
      "llama_print_timings:        eval time =   952.43 ms /    32 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  2648.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.50 ms /    43 runs   (    0.69 ms per token,  1457.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1970.76 ms /   524 tokens (    3.76 ms per token,   265.89 tokens per second)\n",
      "llama_print_timings:        eval time =  1258.97 ms /    42 runs   (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:       total time =  3305.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    67.85 ms /    98 runs   (    0.69 ms per token,  1444.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1928.95 ms /   524 tokens (    3.68 ms per token,   271.65 tokens per second)\n",
      "llama_print_timings:        eval time =  2914.81 ms /    97 runs   (   30.05 ms per token,    33.28 tokens per second)\n",
      "llama_print_timings:       total time =  5018.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.96 ms /    36 runs   (    0.69 ms per token,  1442.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1624.16 ms /   474 tokens (    3.43 ms per token,   291.84 tokens per second)\n",
      "llama_print_timings:        eval time =  1045.47 ms /    35 runs   (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_print_timings:       total time =  2732.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.02 ms /    45 runs   (    0.69 ms per token,  1450.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   804.55 ms /   241 tokens (    3.34 ms per token,   299.55 tokens per second)\n",
      "llama_print_timings:        eval time =  1262.86 ms /    44 runs   (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_print_timings:       total time =  2146.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.57 ms /    46 runs   (    0.69 ms per token,  1457.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1248.35 ms /   370 tokens (    3.37 ms per token,   296.39 tokens per second)\n",
      "llama_print_timings:        eval time =  1316.65 ms /    45 runs   (   29.26 ms per token,    34.18 tokens per second)\n",
      "llama_print_timings:       total time =  2644.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.24 ms /    48 runs   (    0.69 ms per token,  1444.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   495.36 ms /   153 tokens (    3.24 ms per token,   308.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1325.54 ms /    47 runs   (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_print_timings:       total time =  1905.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    45.54 ms /    66 runs   (    0.69 ms per token,  1449.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   808.72 ms /   245 tokens (    3.30 ms per token,   302.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1867.45 ms /    65 runs   (   28.73 ms per token,    34.81 tokens per second)\n",
      "llama_print_timings:       total time =  2790.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.44 ms /    38 runs   (    0.70 ms per token,  1437.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2078.34 ms /   574 tokens (    3.62 ms per token,   276.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1113.24 ms /    37 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3260.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   182.52 ms /   256 runs   (    0.71 ms per token,  1402.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1120.20 ms /   325 tokens (    3.45 ms per token,   290.13 tokens per second)\n",
      "llama_print_timings:        eval time =  7431.25 ms /   255 runs   (   29.14 ms per token,    34.31 tokens per second)\n",
      "llama_print_timings:       total time =  9075.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   137.13 ms /   195 runs   (    0.70 ms per token,  1422.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   544.09 ms /   147 tokens (    3.70 ms per token,   270.18 tokens per second)\n",
      "llama_print_timings:        eval time =  5575.09 ms /   194 runs   (   28.74 ms per token,    34.80 tokens per second)\n",
      "llama_print_timings:       total time =  6500.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.96 ms /   256 runs   (    0.70 ms per token,  1438.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2030.26 ms /   490 tokens (    4.14 ms per token,   241.35 tokens per second)\n",
      "llama_print_timings:        eval time =  7655.37 ms /   255 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time = 10174.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.75 ms /   256 runs   (    0.69 ms per token,  1440.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   852.39 ms /   244 tokens (    3.49 ms per token,   286.26 tokens per second)\n",
      "llama_print_timings:        eval time =  7366.74 ms /   255 runs   (   28.89 ms per token,    34.62 tokens per second)\n",
      "llama_print_timings:       total time =  8717.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.37 ms /    39 runs   (    0.68 ms per token,  1478.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1448.83 ms /   375 tokens (    3.86 ms per token,   258.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1135.87 ms /    38 runs   (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  2656.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.84 ms /    46 runs   (    0.69 ms per token,  1444.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2232.62 ms /   565 tokens (    3.95 ms per token,   253.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1350.42 ms /    45 runs   (   30.01 ms per token,    33.32 tokens per second)\n",
      "llama_print_timings:       total time =  3672.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.85 ms /    36 runs   (    0.69 ms per token,  1448.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2072.32 ms /   559 tokens (    3.71 ms per token,   269.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1041.27 ms /    35 runs   (   29.75 ms per token,    33.61 tokens per second)\n",
      "llama_print_timings:       total time =  3182.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.56 ms /    47 runs   (    0.69 ms per token,  1443.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =   926.66 ms /   269 tokens (    3.44 ms per token,   290.29 tokens per second)\n",
      "llama_print_timings:        eval time =  1308.70 ms /    46 runs   (   28.45 ms per token,    35.15 tokens per second)\n",
      "llama_print_timings:       total time =  2322.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.35 ms /   256 runs   (    0.70 ms per token,  1435.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   702.64 ms /   194 tokens (    3.62 ms per token,   276.10 tokens per second)\n",
      "llama_print_timings:        eval time =  7282.85 ms /   255 runs   (   28.56 ms per token,    35.01 tokens per second)\n",
      "llama_print_timings:       total time =  8485.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.69 ms /    42 runs   (    0.71 ms per token,  1414.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2318.91 ms /   575 tokens (    4.03 ms per token,   247.96 tokens per second)\n",
      "llama_print_timings:        eval time =  1237.77 ms /    41 runs   (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time =  3636.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.66 ms /   256 runs   (    0.69 ms per token,  1440.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2088.71 ms /   557 tokens (    3.75 ms per token,   266.67 tokens per second)\n",
      "llama_print_timings:        eval time =  7752.03 ms /   255 runs   (   30.40 ms per token,    32.89 tokens per second)\n",
      "llama_print_timings:       total time = 10319.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   139.23 ms /   200 runs   (    0.70 ms per token,  1436.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2709.87 ms /   718 tokens (    3.77 ms per token,   264.96 tokens per second)\n",
      "llama_print_timings:        eval time =  6183.51 ms /   199 runs   (   31.07 ms per token,    32.18 tokens per second)\n",
      "llama_print_timings:       total time =  9264.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.47 ms /    34 runs   (    0.69 ms per token,  1448.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1988.74 ms /   597 tokens (    3.33 ms per token,   300.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1002.41 ms /    33 runs   (   30.38 ms per token,    32.92 tokens per second)\n",
      "llama_print_timings:       total time =  3051.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.57 ms /    43 runs   (    0.69 ms per token,  1454.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1940.98 ms /   519 tokens (    3.74 ms per token,   267.39 tokens per second)\n",
      "llama_print_timings:        eval time =  1258.69 ms /    42 runs   (   29.97 ms per token,    33.37 tokens per second)\n",
      "llama_print_timings:       total time =  3276.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.88 ms /    36 runs   (    0.69 ms per token,  1447.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2178.62 ms /   589 tokens (    3.70 ms per token,   270.36 tokens per second)\n",
      "llama_print_timings:        eval time =  1056.51 ms /    35 runs   (   30.19 ms per token,    33.13 tokens per second)\n",
      "llama_print_timings:       total time =  3299.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.60 ms /    41 runs   (    0.70 ms per token,  1433.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2048.04 ms /   569 tokens (    3.60 ms per token,   277.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1198.71 ms /    40 runs   (   29.97 ms per token,    33.37 tokens per second)\n",
      "llama_print_timings:       total time =  3322.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.41 ms /    38 runs   (    0.69 ms per token,  1439.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2189.17 ms /   582 tokens (    3.76 ms per token,   265.85 tokens per second)\n",
      "llama_print_timings:        eval time =  1113.00 ms /    37 runs   (   30.08 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3372.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.96 ms /    40 runs   (    0.70 ms per token,  1430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2060.19 ms /   576 tokens (    3.58 ms per token,   279.59 tokens per second)\n",
      "llama_print_timings:        eval time =  1176.31 ms /    39 runs   (   30.16 ms per token,    33.15 tokens per second)\n",
      "llama_print_timings:       total time =  3313.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.69 ms /    50 runs   (    0.69 ms per token,  1441.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1830.57 ms /   512 tokens (    3.58 ms per token,   279.69 tokens per second)\n",
      "llama_print_timings:        eval time =  1457.43 ms /    49 runs   (   29.74 ms per token,    33.62 tokens per second)\n",
      "llama_print_timings:       total time =  3380.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.83 ms /    49 runs   (    0.69 ms per token,  1448.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2029.12 ms /   525 tokens (    3.86 ms per token,   258.73 tokens per second)\n",
      "llama_print_timings:        eval time =  1440.63 ms /    48 runs   (   30.01 ms per token,    33.32 tokens per second)\n",
      "llama_print_timings:       total time =  3557.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.07 ms /    49 runs   (    0.74 ms per token,  1358.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1972.46 ms /   525 tokens (    3.76 ms per token,   266.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1439.67 ms /    48 runs   (   29.99 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:       total time =  3504.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    87.92 ms /   128 runs   (    0.69 ms per token,  1455.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1960.29 ms /   515 tokens (    3.81 ms per token,   262.72 tokens per second)\n",
      "llama_print_timings:        eval time =  3813.23 ms /   127 runs   (   30.03 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  6003.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   146.76 ms /   213 runs   (    0.69 ms per token,  1451.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1808.87 ms /   500 tokens (    3.62 ms per token,   276.42 tokens per second)\n",
      "llama_print_timings:        eval time =  6410.51 ms /   212 runs   (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_print_timings:       total time =  8603.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.36 ms /    40 runs   (    0.68 ms per token,  1462.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1300.75 ms /   372 tokens (    3.50 ms per token,   285.99 tokens per second)\n",
      "llama_print_timings:        eval time =  1144.27 ms /    39 runs   (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_print_timings:       total time =  2514.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.33 ms /    44 runs   (    0.69 ms per token,  1450.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1161.93 ms /   326 tokens (    3.56 ms per token,   280.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1252.99 ms /    43 runs   (   29.14 ms per token,    34.32 tokens per second)\n",
      "llama_print_timings:       total time =  2493.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.86 ms /    42 runs   (    0.69 ms per token,  1455.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1063.90 ms /   314 tokens (    3.39 ms per token,   295.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1196.11 ms /    41 runs   (   29.17 ms per token,    34.28 tokens per second)\n",
      "llama_print_timings:       total time =  2333.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.27 ms /    48 runs   (    0.69 ms per token,  1442.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =   941.04 ms /   280 tokens (    3.36 ms per token,   297.54 tokens per second)\n",
      "llama_print_timings:        eval time =  1353.33 ms /    47 runs   (   28.79 ms per token,    34.73 tokens per second)\n",
      "llama_print_timings:       total time =  2379.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.23 ms /    42 runs   (    0.70 ms per token,  1436.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1162.61 ms /   328 tokens (    3.54 ms per token,   282.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1182.80 ms /    41 runs   (   28.85 ms per token,    34.66 tokens per second)\n",
      "llama_print_timings:       total time =  2422.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.04 ms /    29 runs   (    0.69 ms per token,  1447.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2250.55 ms /   590 tokens (    3.81 ms per token,   262.16 tokens per second)\n",
      "llama_print_timings:        eval time =   848.85 ms /    28 runs   (   30.32 ms per token,    32.99 tokens per second)\n",
      "llama_print_timings:       total time =  3150.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.39 ms /    38 runs   (    0.69 ms per token,  1439.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1951.58 ms /   535 tokens (    3.65 ms per token,   274.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1105.18 ms /    37 runs   (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_print_timings:       total time =  3125.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.55 ms /    50 runs   (    0.69 ms per token,  1447.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   211.34 ms /    34 tokens (    6.22 ms per token,   160.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1345.00 ms /    49 runs   (   27.45 ms per token,    36.43 tokens per second)\n",
      "llama_print_timings:       total time =  1645.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.31 ms /    63 runs   (    0.69 ms per token,  1454.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1156.61 ms /   340 tokens (    3.40 ms per token,   293.96 tokens per second)\n",
      "llama_print_timings:        eval time =  1793.07 ms /    62 runs   (   28.92 ms per token,    34.58 tokens per second)\n",
      "llama_print_timings:       total time =  3062.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.35 ms /    60 runs   (    0.69 ms per token,  1451.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1399.50 ms /   388 tokens (    3.61 ms per token,   277.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1722.65 ms /    59 runs   (   29.20 ms per token,    34.25 tokens per second)\n",
      "llama_print_timings:       total time =  3229.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.71 ms /   256 runs   (    0.69 ms per token,  1456.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   712.45 ms /   198 tokens (    3.60 ms per token,   277.92 tokens per second)\n",
      "llama_print_timings:        eval time =  7323.08 ms /   255 runs   (   28.72 ms per token,    34.82 tokens per second)\n",
      "llama_print_timings:       total time =  8509.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   174.82 ms /   256 runs   (    0.68 ms per token,  1464.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1592.75 ms /   426 tokens (    3.74 ms per token,   267.46 tokens per second)\n",
      "llama_print_timings:        eval time =  7587.97 ms /   255 runs   (   29.76 ms per token,    33.61 tokens per second)\n",
      "llama_print_timings:       total time =  9656.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.36 ms /   256 runs   (    0.69 ms per token,  1451.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   735.42 ms /   197 tokens (    3.73 ms per token,   267.87 tokens per second)\n",
      "llama_print_timings:        eval time =  7318.43 ms /   255 runs   (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_print_timings:       total time =  8526.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.51 ms /   256 runs   (    0.69 ms per token,  1450.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1629.03 ms /   426 tokens (    3.82 ms per token,   261.51 tokens per second)\n",
      "llama_print_timings:        eval time =  7617.05 ms /   255 runs   (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_print_timings:       total time =  9719.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.97 ms /    45 runs   (    0.69 ms per token,  1452.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   402.23 ms /   110 tokens (    3.66 ms per token,   273.48 tokens per second)\n",
      "llama_print_timings:        eval time =  1229.19 ms /    44 runs   (   27.94 ms per token,    35.80 tokens per second)\n",
      "llama_print_timings:       total time =  1711.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.74 ms /   256 runs   (    0.69 ms per token,  1456.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2174.72 ms /   555 tokens (    3.92 ms per token,   255.21 tokens per second)\n",
      "llama_print_timings:        eval time =  7763.01 ms /   255 runs   (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_print_timings:       total time = 10410.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.05 ms /   256 runs   (    0.69 ms per token,  1454.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =   399.70 ms /   103 tokens (    3.88 ms per token,   257.70 tokens per second)\n",
      "llama_print_timings:        eval time =  7205.47 ms /   255 runs   (   28.26 ms per token,    35.39 tokens per second)\n",
      "llama_print_timings:       total time =  8078.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.40 ms /    43 runs   (    0.68 ms per token,  1462.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =   641.88 ms /   187 tokens (    3.43 ms per token,   291.33 tokens per second)\n",
      "llama_print_timings:        eval time =  1200.74 ms /    42 runs   (   28.59 ms per token,    34.98 tokens per second)\n",
      "llama_print_timings:       total time =  1918.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.19 ms /    63 runs   (    0.69 ms per token,  1458.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   223.98 ms /    51 tokens (    4.39 ms per token,   227.70 tokens per second)\n",
      "llama_print_timings:        eval time =  1708.92 ms /    62 runs   (   27.56 ms per token,    36.28 tokens per second)\n",
      "llama_print_timings:       total time =  2047.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.16 ms /    55 runs   (    0.71 ms per token,  1404.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1924.32 ms /   500 tokens (    3.85 ms per token,   259.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1615.15 ms /    54 runs   (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_print_timings:       total time =  3642.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.41 ms /    52 runs   (    0.70 ms per token,  1428.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2112.66 ms /   563 tokens (    3.75 ms per token,   266.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1528.28 ms /    51 runs   (   29.97 ms per token,    33.37 tokens per second)\n",
      "llama_print_timings:       total time =  3738.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.96 ms /    61 runs   (    0.69 ms per token,  1453.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2048.08 ms /   545 tokens (    3.76 ms per token,   266.10 tokens per second)\n",
      "llama_print_timings:        eval time =  1798.81 ms /    60 runs   (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:       total time =  3958.13 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    67.43 ms /    96 runs   (    0.70 ms per token,  1423.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1949.21 ms /   523 tokens (    3.73 ms per token,   268.31 tokens per second)\n",
      "llama_print_timings:        eval time =  2846.56 ms /    95 runs   (   29.96 ms per token,    33.37 tokens per second)\n",
      "llama_print_timings:       total time =  4971.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.84 ms /    30 runs   (    0.69 ms per token,  1439.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1932.95 ms /   533 tokens (    3.63 ms per token,   275.74 tokens per second)\n",
      "llama_print_timings:        eval time =   861.19 ms /    29 runs   (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_print_timings:       total time =  2849.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    48.24 ms /    70 runs   (    0.69 ms per token,  1450.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1942.32 ms /   535 tokens (    3.63 ms per token,   275.44 tokens per second)\n",
      "llama_print_timings:        eval time =  2055.77 ms /    69 runs   (   29.79 ms per token,    33.56 tokens per second)\n",
      "llama_print_timings:       total time =  4124.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.36 ms /    50 runs   (    0.69 ms per token,  1455.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1749.04 ms /   484 tokens (    3.61 ms per token,   276.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1459.41 ms /    49 runs   (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_print_timings:       total time =  3296.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.89 ms /    33 runs   (    0.69 ms per token,  1441.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1492.11 ms /   431 tokens (    3.46 ms per token,   288.85 tokens per second)\n",
      "llama_print_timings:        eval time =   938.60 ms /    32 runs   (   29.33 ms per token,    34.09 tokens per second)\n",
      "llama_print_timings:       total time =  2488.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.27 ms /    47 runs   (    0.69 ms per token,  1456.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1408.18 ms /   416 tokens (    3.39 ms per token,   295.42 tokens per second)\n",
      "llama_print_timings:        eval time =  1355.28 ms /    46 runs   (   29.46 ms per token,    33.94 tokens per second)\n",
      "llama_print_timings:       total time =  2846.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.37 ms /    37 runs   (    0.79 ms per token,  1259.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1397.30 ms /   409 tokens (    3.42 ms per token,   292.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1050.86 ms /    36 runs   (   29.19 ms per token,    34.26 tokens per second)\n",
      "llama_print_timings:       total time =  2526.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.98 ms /    45 runs   (    0.69 ms per token,  1452.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1786.28 ms /   502 tokens (    3.56 ms per token,   281.03 tokens per second)\n",
      "llama_print_timings:        eval time =  1315.47 ms /    44 runs   (   29.90 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  3180.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.92 ms /    35 runs   (    0.68 ms per token,  1463.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   824.70 ms /   250 tokens (    3.30 ms per token,   303.14 tokens per second)\n",
      "llama_print_timings:        eval time =   976.08 ms /    34 runs   (   28.71 ms per token,    34.83 tokens per second)\n",
      "llama_print_timings:       total time =  1861.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.05 ms /    44 runs   (    0.68 ms per token,  1464.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =   216.81 ms /    51 tokens (    4.25 ms per token,   235.23 tokens per second)\n",
      "llama_print_timings:        eval time =  1196.93 ms /    43 runs   (   27.84 ms per token,    35.93 tokens per second)\n",
      "llama_print_timings:       total time =  1489.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.77 ms /    33 runs   (    0.69 ms per token,  1449.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2099.68 ms /   555 tokens (    3.78 ms per token,   264.33 tokens per second)\n",
      "llama_print_timings:        eval time =   960.15 ms /    32 runs   (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  3118.93 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    49.61 ms /    71 runs   (    0.70 ms per token,  1431.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1979.59 ms /   540 tokens (    3.67 ms per token,   272.78 tokens per second)\n",
      "llama_print_timings:        eval time =  2092.02 ms /    70 runs   (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_print_timings:       total time =  4201.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.02 ms /    35 runs   (    0.69 ms per token,  1457.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1992.93 ms /   532 tokens (    3.75 ms per token,   266.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1015.04 ms /    34 runs   (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_print_timings:       total time =  3071.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.16 ms /    46 runs   (    0.68 ms per token,  1476.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   824.65 ms /   244 tokens (    3.38 ms per token,   295.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1279.51 ms /    45 runs   (   28.43 ms per token,    35.17 tokens per second)\n",
      "llama_print_timings:       total time =  2186.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    58.00 ms /    84 runs   (    0.69 ms per token,  1448.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2112.23 ms /   553 tokens (    3.82 ms per token,   261.81 tokens per second)\n",
      "llama_print_timings:        eval time =  2485.91 ms /    83 runs   (   29.95 ms per token,    33.39 tokens per second)\n",
      "llama_print_timings:       total time =  4751.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.42 ms /    43 runs   (    0.68 ms per token,  1461.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =   931.99 ms /   284 tokens (    3.28 ms per token,   304.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1206.68 ms /    42 runs   (   28.73 ms per token,    34.81 tokens per second)\n",
      "llama_print_timings:       total time =  2215.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.42 ms /    55 runs   (    0.70 ms per token,  1431.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1809.91 ms /   500 tokens (    3.62 ms per token,   276.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1606.44 ms /    54 runs   (   29.75 ms per token,    33.61 tokens per second)\n",
      "llama_print_timings:       total time =  3519.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.97 ms /   256 runs   (    0.70 ms per token,  1430.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   632.86 ms /   186 tokens (    3.40 ms per token,   293.91 tokens per second)\n",
      "llama_print_timings:        eval time =  7307.82 ms /   255 runs   (   28.66 ms per token,    34.89 tokens per second)\n",
      "llama_print_timings:       total time =  8434.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   152.40 ms /   221 runs   (    0.69 ms per token,  1450.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   239.11 ms /    59 tokens (    4.05 ms per token,   246.75 tokens per second)\n",
      "llama_print_timings:        eval time =  6237.84 ms /   220 runs   (   28.35 ms per token,    35.27 tokens per second)\n",
      "llama_print_timings:       total time =  6877.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.16 ms /    45 runs   (    0.69 ms per token,  1444.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   426.44 ms /   122 tokens (    3.50 ms per token,   286.09 tokens per second)\n",
      "llama_print_timings:        eval time =  1252.23 ms /    44 runs   (   28.46 ms per token,    35.14 tokens per second)\n",
      "llama_print_timings:       total time =  1757.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.88 ms /    43 runs   (    0.69 ms per token,  1439.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2159.34 ms /   540 tokens (    4.00 ms per token,   250.08 tokens per second)\n",
      "llama_print_timings:        eval time =  1265.88 ms /    42 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  3501.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.23 ms /    48 runs   (    0.69 ms per token,  1444.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1508.63 ms /   441 tokens (    3.42 ms per token,   292.32 tokens per second)\n",
      "llama_print_timings:        eval time =  1392.46 ms /    47 runs   (   29.63 ms per token,    33.75 tokens per second)\n",
      "llama_print_timings:       total time =  2985.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    87.00 ms /   125 runs   (    0.70 ms per token,  1436.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2199.95 ms /   595 tokens (    3.70 ms per token,   270.46 tokens per second)\n",
      "llama_print_timings:        eval time =  3776.72 ms /   124 runs   (   30.46 ms per token,    32.83 tokens per second)\n",
      "llama_print_timings:       total time =  6201.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.74 ms /    44 runs   (    0.70 ms per token,  1431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2186.38 ms /   599 tokens (    3.65 ms per token,   273.97 tokens per second)\n",
      "llama_print_timings:        eval time =  1304.89 ms /    43 runs   (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:       total time =  3570.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.36 ms /    35 runs   (    0.70 ms per token,  1437.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2177.94 ms /   595 tokens (    3.66 ms per token,   273.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1029.53 ms /    34 runs   (   30.28 ms per token,    33.02 tokens per second)\n",
      "llama_print_timings:       total time =  3270.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.41 ms /    32 runs   (    0.70 ms per token,  1427.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2168.32 ms /   595 tokens (    3.64 ms per token,   274.41 tokens per second)\n",
      "llama_print_timings:        eval time =   940.50 ms /    31 runs   (   30.34 ms per token,    32.96 tokens per second)\n",
      "llama_print_timings:       total time =  3165.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.88 ms /    30 runs   (    0.70 ms per token,  1436.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2176.04 ms /   606 tokens (    3.59 ms per token,   278.49 tokens per second)\n",
      "llama_print_timings:        eval time =   876.42 ms /    29 runs   (   30.22 ms per token,    33.09 tokens per second)\n",
      "llama_print_timings:       total time =  3111.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.08 ms /    43 runs   (    0.70 ms per token,  1429.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2630.71 ms /   764 tokens (    3.44 ms per token,   290.42 tokens per second)\n",
      "llama_print_timings:        eval time =  1296.25 ms /    42 runs   (   30.86 ms per token,    32.40 tokens per second)\n",
      "llama_print_timings:       total time =  4007.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.38 ms /    36 runs   (    0.70 ms per token,  1418.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2659.20 ms /   711 tokens (    3.74 ms per token,   267.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1071.32 ms /    35 runs   (   30.61 ms per token,    32.67 tokens per second)\n",
      "llama_print_timings:       total time =  3797.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.33 ms /   256 runs   (    0.69 ms per token,  1443.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1940.33 ms /   537 tokens (    3.61 ms per token,   276.76 tokens per second)\n",
      "llama_print_timings:        eval time =  7691.31 ms /   255 runs   (   30.16 ms per token,    33.15 tokens per second)\n",
      "llama_print_timings:       total time = 10116.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.07 ms /    48 runs   (    0.69 ms per token,  1451.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   622.80 ms /   171 tokens (    3.64 ms per token,   274.57 tokens per second)\n",
      "llama_print_timings:        eval time =  1325.49 ms /    47 runs   (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_print_timings:       total time =  2036.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.10 ms /   256 runs   (    0.69 ms per token,  1445.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1461.94 ms /   405 tokens (    3.61 ms per token,   277.03 tokens per second)\n",
      "llama_print_timings:        eval time =  7564.19 ms /   255 runs   (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_print_timings:       total time =  9510.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.28 ms /    54 runs   (    0.69 ms per token,  1448.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1626.37 ms /   438 tokens (    3.71 ms per token,   269.31 tokens per second)\n",
      "llama_print_timings:        eval time =  1575.06 ms /    53 runs   (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_print_timings:       total time =  3297.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.79 ms /    39 runs   (    0.69 ms per token,  1456.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1527.78 ms /   419 tokens (    3.65 ms per token,   274.25 tokens per second)\n",
      "llama_print_timings:        eval time =  1119.30 ms /    38 runs   (   29.46 ms per token,    33.95 tokens per second)\n",
      "llama_print_timings:       total time =  2716.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.64 ms /    34 runs   (    0.70 ms per token,  1438.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1025.89 ms /   302 tokens (    3.40 ms per token,   294.38 tokens per second)\n",
      "llama_print_timings:        eval time =   957.49 ms /    33 runs   (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_print_timings:       total time =  2043.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.20 ms /    48 runs   (    0.69 ms per token,  1445.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   394.37 ms /    98 tokens (    4.02 ms per token,   248.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1321.40 ms /    47 runs   (   28.11 ms per token,    35.57 tokens per second)\n",
      "llama_print_timings:       total time =  1800.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.81 ms /    49 runs   (    0.69 ms per token,  1449.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   824.66 ms /   237 tokens (    3.48 ms per token,   287.39 tokens per second)\n",
      "llama_print_timings:        eval time =  1368.52 ms /    48 runs   (   28.51 ms per token,    35.07 tokens per second)\n",
      "llama_print_timings:       total time =  2281.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.07 ms /    60 runs   (    0.68 ms per token,  1460.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1306.28 ms /   368 tokens (    3.55 ms per token,   281.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1731.33 ms /    59 runs   (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_print_timings:       total time =  3143.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.06 ms /    31 runs   (    0.68 ms per token,  1471.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2093.94 ms /   565 tokens (    3.71 ms per token,   269.83 tokens per second)\n",
      "llama_print_timings:        eval time =   904.58 ms /    30 runs   (   30.15 ms per token,    33.16 tokens per second)\n",
      "llama_print_timings:       total time =  3054.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.83 ms /    46 runs   (    0.69 ms per token,  1445.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1275.40 ms /   375 tokens (    3.40 ms per token,   294.03 tokens per second)\n",
      "llama_print_timings:        eval time =  1318.41 ms /    45 runs   (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_print_timings:       total time =  2675.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    56.85 ms /    83 runs   (    0.68 ms per token,  1460.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   404.45 ms /   126 tokens (    3.21 ms per token,   311.53 tokens per second)\n",
      "llama_print_timings:        eval time =  2304.22 ms /    82 runs   (   28.10 ms per token,    35.59 tokens per second)\n",
      "llama_print_timings:       total time =  2857.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.84 ms /    37 runs   (    0.70 ms per token,  1431.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2230.02 ms /   597 tokens (    3.74 ms per token,   267.71 tokens per second)\n",
      "llama_print_timings:        eval time =  1093.89 ms /    36 runs   (   30.39 ms per token,    32.91 tokens per second)\n",
      "llama_print_timings:       total time =  3389.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.05 ms /   256 runs   (    0.69 ms per token,  1445.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2160.72 ms /   580 tokens (    3.73 ms per token,   268.43 tokens per second)\n",
      "llama_print_timings:        eval time =  7817.88 ms /   255 runs   (   30.66 ms per token,    32.62 tokens per second)\n",
      "llama_print_timings:       total time = 10454.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.13 ms /   256 runs   (    0.69 ms per token,  1445.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   698.97 ms /   217 tokens (    3.22 ms per token,   310.46 tokens per second)\n",
      "llama_print_timings:        eval time =  7334.34 ms /   255 runs   (   28.76 ms per token,    34.77 tokens per second)\n",
      "llama_print_timings:       total time =  8521.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.61 ms /    41 runs   (    0.67 ms per token,  1485.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1853.74 ms /   503 tokens (    3.69 ms per token,   271.34 tokens per second)\n",
      "llama_print_timings:        eval time =  1201.59 ms /    40 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3127.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.85 ms /    35 runs   (    0.68 ms per token,  1467.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1156.14 ms /   333 tokens (    3.47 ms per token,   288.03 tokens per second)\n",
      "llama_print_timings:        eval time =   985.50 ms /    34 runs   (   28.99 ms per token,    34.50 tokens per second)\n",
      "llama_print_timings:       total time =  2204.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.55 ms /    37 runs   (    0.69 ms per token,  1448.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =   936.31 ms /   267 tokens (    3.51 ms per token,   285.16 tokens per second)\n",
      "llama_print_timings:        eval time =  1039.88 ms /    36 runs   (   28.89 ms per token,    34.62 tokens per second)\n",
      "llama_print_timings:       total time =  2040.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.85 ms /    39 runs   (    0.69 ms per token,  1452.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1045.22 ms /   300 tokens (    3.48 ms per token,   287.02 tokens per second)\n",
      "llama_print_timings:        eval time =  1100.40 ms /    38 runs   (   28.96 ms per token,    34.53 tokens per second)\n",
      "llama_print_timings:       total time =  2215.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.65 ms /    46 runs   (    0.69 ms per token,  1453.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1168.18 ms /   346 tokens (    3.38 ms per token,   296.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1310.12 ms /    45 runs   (   29.11 ms per token,    34.35 tokens per second)\n",
      "llama_print_timings:       total time =  2558.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.23 ms /    41 runs   (    0.69 ms per token,  1452.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =   699.68 ms /   195 tokens (    3.59 ms per token,   278.70 tokens per second)\n",
      "llama_print_timings:        eval time =  1138.66 ms /    40 runs   (   28.47 ms per token,    35.13 tokens per second)\n",
      "llama_print_timings:       total time =  1910.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.53 ms /    40 runs   (    0.69 ms per token,  1453.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1794.74 ms /   504 tokens (    3.56 ms per token,   280.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1166.78 ms /    39 runs   (   29.92 ms per token,    33.43 tokens per second)\n",
      "llama_print_timings:       total time =  3031.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.57 ms /    37 runs   (    0.69 ms per token,  1447.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1157.97 ms /   337 tokens (    3.44 ms per token,   291.03 tokens per second)\n",
      "llama_print_timings:        eval time =  1048.82 ms /    36 runs   (   29.13 ms per token,    34.32 tokens per second)\n",
      "llama_print_timings:       total time =  2271.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.01 ms /    51 runs   (    0.69 ms per token,  1456.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2206.72 ms /   578 tokens (    3.82 ms per token,   261.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1511.55 ms /    50 runs   (   30.23 ms per token,    33.08 tokens per second)\n",
      "llama_print_timings:       total time =  3809.71 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    44.55 ms /    63 runs   (    0.71 ms per token,  1414.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1291.88 ms /   379 tokens (    3.41 ms per token,   293.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1798.79 ms /    62 runs   (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_print_timings:       total time =  3211.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.84 ms /    55 runs   (    0.69 ms per token,  1453.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =   218.38 ms /    64 tokens (    3.41 ms per token,   293.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1499.70 ms /    54 runs   (   27.77 ms per token,    36.01 tokens per second)\n",
      "llama_print_timings:       total time =  1816.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.71 ms /    44 runs   (    0.70 ms per token,  1432.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   740.04 ms /   219 tokens (    3.38 ms per token,   295.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1215.19 ms /    43 runs   (   28.26 ms per token,    35.39 tokens per second)\n",
      "llama_print_timings:       total time =  2038.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.91 ms /    48 runs   (    0.71 ms per token,  1415.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2324.16 ms /   591 tokens (    3.93 ms per token,   254.29 tokens per second)\n",
      "llama_print_timings:        eval time =  1412.66 ms /    47 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3828.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.14 ms /    40 runs   (    0.70 ms per token,  1421.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2278.66 ms /   604 tokens (    3.77 ms per token,   265.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1267.23 ms /    39 runs   (   32.49 ms per token,    30.78 tokens per second)\n",
      "llama_print_timings:       total time =  3623.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.51 ms /    51 runs   (    0.70 ms per token,  1436.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2129.17 ms /   567 tokens (    3.76 ms per token,   266.30 tokens per second)\n",
      "llama_print_timings:        eval time =  1541.40 ms /    50 runs   (   30.83 ms per token,    32.44 tokens per second)\n",
      "llama_print_timings:       total time =  3766.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    64.55 ms /    94 runs   (    0.69 ms per token,  1456.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2235.40 ms /   600 tokens (    3.73 ms per token,   268.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2809.56 ms /    93 runs   (   30.21 ms per token,    33.10 tokens per second)\n",
      "llama_print_timings:       total time =  5212.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.14 ms /    51 runs   (    0.69 ms per token,  1451.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2004.07 ms /   564 tokens (    3.55 ms per token,   281.43 tokens per second)\n",
      "llama_print_timings:        eval time =  1501.87 ms /    50 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3595.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.58 ms /    49 runs   (    0.69 ms per token,  1459.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2132.05 ms /   581 tokens (    3.67 ms per token,   272.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1445.50 ms /    48 runs   (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =  3662.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.59 ms /    50 runs   (    0.69 ms per token,  1445.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2102.73 ms /   583 tokens (    3.61 ms per token,   277.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1469.75 ms /    49 runs   (   29.99 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:       total time =  3661.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.23 ms /    50 runs   (    0.68 ms per token,  1460.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2103.18 ms /   591 tokens (    3.56 ms per token,   281.00 tokens per second)\n",
      "llama_print_timings:        eval time =  1479.55 ms /    49 runs   (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time =  3668.59 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.25 ms /    47 runs   (    0.71 ms per token,  1413.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2041.22 ms /   554 tokens (    3.68 ms per token,   271.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1449.84 ms /    46 runs   (   31.52 ms per token,    31.73 tokens per second)\n",
      "llama_print_timings:       total time =  3579.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    51.00 ms /    74 runs   (    0.69 ms per token,  1450.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2211.49 ms /   601 tokens (    3.68 ms per token,   271.76 tokens per second)\n",
      "llama_print_timings:        eval time =  2225.29 ms /    73 runs   (   30.48 ms per token,    32.80 tokens per second)\n",
      "llama_print_timings:       total time =  4567.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.08 ms /    50 runs   (    0.68 ms per token,  1467.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2143.95 ms /   605 tokens (    3.54 ms per token,   282.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1485.56 ms /    49 runs   (   30.32 ms per token,    32.98 tokens per second)\n",
      "llama_print_timings:       total time =  3716.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.72 ms /    56 runs   (    0.69 ms per token,  1446.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2107.49 ms /   581 tokens (    3.63 ms per token,   275.68 tokens per second)\n",
      "llama_print_timings:        eval time =  1653.93 ms /    55 runs   (   30.07 ms per token,    33.25 tokens per second)\n",
      "llama_print_timings:       total time =  3862.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.06 ms /    50 runs   (    0.68 ms per token,  1468.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1999.88 ms /   568 tokens (    3.52 ms per token,   284.02 tokens per second)\n",
      "llama_print_timings:        eval time =  1474.26 ms /    49 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3561.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.27 ms /    53 runs   (    0.68 ms per token,  1461.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2122.14 ms /   584 tokens (    3.63 ms per token,   275.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1566.03 ms /    52 runs   (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_print_timings:       total time =  3782.28 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.37 ms /    49 runs   (    0.68 ms per token,  1468.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2111.60 ms /   591 tokens (    3.57 ms per token,   279.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1444.96 ms /    48 runs   (   30.10 ms per token,    33.22 tokens per second)\n",
      "llama_print_timings:       total time =  3642.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    44.34 ms /    64 runs   (    0.69 ms per token,  1443.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2108.03 ms /   580 tokens (    3.63 ms per token,   275.14 tokens per second)\n",
      "llama_print_timings:        eval time =  1890.37 ms /    63 runs   (   30.01 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  4117.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.53 ms /    63 runs   (    0.69 ms per token,  1447.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2149.12 ms /   594 tokens (    3.62 ms per token,   276.39 tokens per second)\n",
      "llama_print_timings:        eval time =  1865.39 ms /    62 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  4130.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.06 ms /    52 runs   (    0.69 ms per token,  1442.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2016.48 ms /   575 tokens (    3.51 ms per token,   285.15 tokens per second)\n",
      "llama_print_timings:        eval time =  1532.86 ms /    51 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3642.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.55 ms /    54 runs   (    0.70 ms per token,  1437.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2114.53 ms /   591 tokens (    3.58 ms per token,   279.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1587.62 ms /    53 runs   (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_print_timings:       total time =  3801.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.07 ms /    44 runs   (    0.68 ms per token,  1463.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2160.85 ms /   603 tokens (    3.58 ms per token,   279.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1291.05 ms /    43 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  3533.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.98 ms /    47 runs   (    0.68 ms per token,  1469.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2137.61 ms /   587 tokens (    3.64 ms per token,   274.61 tokens per second)\n",
      "llama_print_timings:        eval time =  1386.21 ms /    46 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  3606.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.77 ms /    46 runs   (    0.69 ms per token,  1448.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2098.38 ms /   578 tokens (    3.63 ms per token,   275.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1352.64 ms /    45 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3531.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.28 ms /    60 runs   (    0.69 ms per token,  1453.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2110.33 ms /   598 tokens (    3.53 ms per token,   283.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1782.63 ms /    59 runs   (   30.21 ms per token,    33.10 tokens per second)\n",
      "llama_print_timings:       total time =  4000.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.18 ms /    42 runs   (    0.67 ms per token,  1490.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1965.05 ms /   554 tokens (    3.55 ms per token,   281.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1232.96 ms /    41 runs   (   30.07 ms per token,    33.25 tokens per second)\n",
      "llama_print_timings:       total time =  3270.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    40.55 ms /    59 runs   (    0.69 ms per token,  1454.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2123.50 ms /   603 tokens (    3.52 ms per token,   283.97 tokens per second)\n",
      "llama_print_timings:        eval time =  1750.55 ms /    58 runs   (   30.18 ms per token,    33.13 tokens per second)\n",
      "llama_print_timings:       total time =  3978.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    45.95 ms /    66 runs   (    0.70 ms per token,  1436.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2117.20 ms /   595 tokens (    3.56 ms per token,   281.03 tokens per second)\n",
      "llama_print_timings:        eval time =  1956.86 ms /    65 runs   (   30.11 ms per token,    33.22 tokens per second)\n",
      "llama_print_timings:       total time =  4198.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.43 ms /    47 runs   (    0.69 ms per token,  1449.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2155.13 ms /   583 tokens (    3.70 ms per token,   270.52 tokens per second)\n",
      "llama_print_timings:        eval time =  1382.15 ms /    46 runs   (   30.05 ms per token,    33.28 tokens per second)\n",
      "llama_print_timings:       total time =  3622.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.48 ms /    37 runs   (    0.69 ms per token,  1452.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2233.85 ms /   613 tokens (    3.64 ms per token,   274.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1095.59 ms /    36 runs   (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_print_timings:       total time =  3396.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.87 ms /    52 runs   (    0.69 ms per token,  1449.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2134.32 ms /   608 tokens (    3.51 ms per token,   284.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1535.52 ms /    51 runs   (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =  3766.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.82 ms /    41 runs   (    0.68 ms per token,  1473.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2216.38 ms /   612 tokens (    3.62 ms per token,   276.13 tokens per second)\n",
      "llama_print_timings:        eval time =  1203.01 ms /    40 runs   (   30.08 ms per token,    33.25 tokens per second)\n",
      "llama_print_timings:       total time =  3492.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.43 ms /    46 runs   (    0.68 ms per token,  1463.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2130.30 ms /   596 tokens (    3.57 ms per token,   279.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1355.70 ms /    45 runs   (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_print_timings:       total time =  3568.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.28 ms /    40 runs   (    0.68 ms per token,  1466.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2017.71 ms /   556 tokens (    3.63 ms per token,   275.56 tokens per second)\n",
      "llama_print_timings:        eval time =  1166.88 ms /    39 runs   (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_print_timings:       total time =  3257.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.12 ms /   256 runs   (    0.68 ms per token,  1461.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2041.62 ms /   571 tokens (    3.58 ms per token,   279.68 tokens per second)\n",
      "llama_print_timings:        eval time =  7784.92 ms /   255 runs   (   30.53 ms per token,    32.76 tokens per second)\n",
      "llama_print_timings:       total time = 10292.66 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.74 ms /    51 runs   (    0.68 ms per token,  1467.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2016.72 ms /   575 tokens (    3.51 ms per token,   285.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1507.78 ms /    50 runs   (   30.16 ms per token,    33.16 tokens per second)\n",
      "llama_print_timings:       total time =  3612.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.66 ms /    53 runs   (    0.69 ms per token,  1445.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2095.44 ms /   582 tokens (    3.60 ms per token,   277.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1563.71 ms /    52 runs   (   30.07 ms per token,    33.25 tokens per second)\n",
      "llama_print_timings:       total time =  3752.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.56 ms /    52 runs   (    0.68 ms per token,  1462.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1964.19 ms /   568 tokens (    3.46 ms per token,   289.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1531.18 ms /    51 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  3588.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.18 ms /    42 runs   (    0.67 ms per token,  1490.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2097.35 ms /   598 tokens (    3.51 ms per token,   285.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1244.18 ms /    41 runs   (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:       total time =  3414.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    44.27 ms /    65 runs   (    0.68 ms per token,  1468.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1865.55 ms /   521 tokens (    3.58 ms per token,   279.27 tokens per second)\n",
      "llama_print_timings:        eval time =  1909.23 ms /    64 runs   (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_print_timings:       total time =  3887.45 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.02 ms /   256 runs   (    0.69 ms per token,  1454.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2293.91 ms /   648 tokens (    3.54 ms per token,   282.49 tokens per second)\n",
      "llama_print_timings:        eval time =  7863.41 ms /   255 runs   (   30.84 ms per token,    32.43 tokens per second)\n",
      "llama_print_timings:       total time = 10632.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.40 ms /    56 runs   (    0.69 ms per token,  1458.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2092.44 ms /   589 tokens (    3.55 ms per token,   281.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1657.95 ms /    55 runs   (   30.14 ms per token,    33.17 tokens per second)\n",
      "llama_print_timings:       total time =  3848.22 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.89 ms /    42 runs   (    0.69 ms per token,  1453.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2089.15 ms /   595 tokens (    3.51 ms per token,   284.80 tokens per second)\n",
      "llama_print_timings:        eval time =  1236.39 ms /    41 runs   (   30.16 ms per token,    33.16 tokens per second)\n",
      "llama_print_timings:       total time =  3400.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.33 ms /   256 runs   (    0.69 ms per token,  1451.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2010.11 ms /   575 tokens (    3.50 ms per token,   286.05 tokens per second)\n",
      "llama_print_timings:        eval time =  7764.22 ms /   255 runs   (   30.45 ms per token,    32.84 tokens per second)\n",
      "llama_print_timings:       total time = 10245.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.63 ms /    47 runs   (    0.69 ms per token,  1440.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1898.72 ms /   536 tokens (    3.54 ms per token,   282.30 tokens per second)\n",
      "llama_print_timings:        eval time =  1366.90 ms /    46 runs   (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_print_timings:       total time =  3350.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.03 ms /    40 runs   (    0.68 ms per token,  1479.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2133.14 ms /   604 tokens (    3.53 ms per token,   283.15 tokens per second)\n",
      "llama_print_timings:        eval time =  1180.86 ms /    39 runs   (   30.28 ms per token,    33.03 tokens per second)\n",
      "llama_print_timings:       total time =  3384.41 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.69 ms /    44 runs   (    0.70 ms per token,  1433.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2186.21 ms /   612 tokens (    3.57 ms per token,   279.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1291.74 ms /    43 runs   (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_print_timings:       total time =  3558.98 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.27 ms /    47 runs   (    0.69 ms per token,  1456.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2103.17 ms /   590 tokens (    3.56 ms per token,   280.53 tokens per second)\n",
      "llama_print_timings:        eval time =  1392.30 ms /    46 runs   (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_print_timings:       total time =  3580.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    57.40 ms /    83 runs   (    0.69 ms per token,  1446.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2203.81 ms /   610 tokens (    3.61 ms per token,   276.79 tokens per second)\n",
      "llama_print_timings:        eval time =  2489.09 ms /    82 runs   (   30.35 ms per token,    32.94 tokens per second)\n",
      "llama_print_timings:       total time =  4845.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.22 ms /    47 runs   (    0.69 ms per token,  1458.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2174.70 ms /   599 tokens (    3.63 ms per token,   275.44 tokens per second)\n",
      "llama_print_timings:        eval time =  1400.35 ms /    46 runs   (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_print_timings:       total time =  3659.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.61 ms /    44 runs   (    0.70 ms per token,  1437.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2211.09 ms /   625 tokens (    3.54 ms per token,   282.67 tokens per second)\n",
      "llama_print_timings:        eval time =  1297.28 ms /    43 runs   (   30.17 ms per token,    33.15 tokens per second)\n",
      "llama_print_timings:       total time =  3589.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.24 ms /    47 runs   (    0.69 ms per token,  1458.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2105.91 ms /   602 tokens (    3.50 ms per token,   285.86 tokens per second)\n",
      "llama_print_timings:        eval time =  1387.96 ms /    46 runs   (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3577.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.88 ms /    36 runs   (    0.69 ms per token,  1447.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2102.04 ms /   592 tokens (    3.55 ms per token,   281.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1055.26 ms /    35 runs   (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_print_timings:       total time =  3223.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.69 ms /    49 runs   (    0.69 ms per token,  1454.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2214.46 ms /   616 tokens (    3.59 ms per token,   278.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1449.30 ms /    48 runs   (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time =  3752.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.93 ms /    49 runs   (    0.69 ms per token,  1444.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2111.38 ms /   597 tokens (    3.54 ms per token,   282.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1444.23 ms /    48 runs   (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_print_timings:       total time =  3643.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    42 runs   (    0.69 ms per token,  1454.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2083.23 ms /   587 tokens (    3.55 ms per token,   281.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1238.42 ms /    41 runs   (   30.21 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:       total time =  3395.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.53 ms /    43 runs   (    0.69 ms per token,  1456.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2088.86 ms /   608 tokens (    3.44 ms per token,   291.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1271.77 ms /    42 runs   (   30.28 ms per token,    33.02 tokens per second)\n",
      "llama_print_timings:       total time =  3437.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.58 ms /    63 runs   (    0.69 ms per token,  1445.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2092.06 ms /   594 tokens (    3.52 ms per token,   283.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1875.52 ms /    62 runs   (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_print_timings:       total time =  4080.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.65 ms /    56 runs   (    0.69 ms per token,  1449.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2092.78 ms /   584 tokens (    3.58 ms per token,   279.05 tokens per second)\n",
      "llama_print_timings:        eval time =  1663.89 ms /    55 runs   (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_print_timings:       total time =  3857.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.22 ms /    49 runs   (    0.70 ms per token,  1432.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2114.65 ms /   588 tokens (    3.60 ms per token,   278.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1481.88 ms /    48 runs   (   30.87 ms per token,    32.39 tokens per second)\n",
      "llama_print_timings:       total time =  3690.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.25 ms /    59 runs   (    0.73 ms per token,  1364.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1981.58 ms /   551 tokens (    3.60 ms per token,   278.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1719.15 ms /    58 runs   (   29.64 ms per token,    33.74 tokens per second)\n",
      "llama_print_timings:       total time =  3817.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    57.29 ms /    83 runs   (    0.69 ms per token,  1448.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2027.69 ms /   575 tokens (    3.53 ms per token,   283.57 tokens per second)\n",
      "llama_print_timings:        eval time =  2456.61 ms /    82 runs   (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_print_timings:       total time =  4634.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.85 ms /    42 runs   (    0.69 ms per token,  1455.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1106.39 ms /   326 tokens (    3.39 ms per token,   294.65 tokens per second)\n",
      "llama_print_timings:        eval time =  1179.29 ms /    41 runs   (   28.76 ms per token,    34.77 tokens per second)\n",
      "llama_print_timings:       total time =  2359.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.73 ms /    43 runs   (    0.69 ms per token,  1446.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1889.12 ms /   530 tokens (    3.56 ms per token,   280.55 tokens per second)\n",
      "llama_print_timings:        eval time =  1247.76 ms /    42 runs   (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_print_timings:       total time =  3214.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.52 ms /    40 runs   (    0.69 ms per token,  1453.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1578.55 ms /   475 tokens (    3.32 ms per token,   300.91 tokens per second)\n",
      "llama_print_timings:        eval time =  1145.52 ms /    39 runs   (   29.37 ms per token,    34.05 tokens per second)\n",
      "llama_print_timings:       total time =  2794.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.22 ms /    50 runs   (    0.68 ms per token,  1461.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =   592.69 ms /   174 tokens (    3.41 ms per token,   293.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1385.48 ms /    49 runs   (   28.28 ms per token,    35.37 tokens per second)\n",
      "llama_print_timings:       total time =  2063.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    53.73 ms /    78 runs   (    0.69 ms per token,  1451.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =   321.89 ms /    69 tokens (    4.67 ms per token,   214.36 tokens per second)\n",
      "llama_print_timings:        eval time =  2145.89 ms /    77 runs   (   27.87 ms per token,    35.88 tokens per second)\n",
      "llama_print_timings:       total time =  2603.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.26 ms /    53 runs   (    0.68 ms per token,  1461.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   393.99 ms /   111 tokens (    3.55 ms per token,   281.73 tokens per second)\n",
      "llama_print_timings:        eval time =  1451.16 ms /    52 runs   (   27.91 ms per token,    35.83 tokens per second)\n",
      "llama_print_timings:       total time =  1936.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.60 ms /    46 runs   (    0.69 ms per token,  1455.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   205.26 ms /    33 tokens (    6.22 ms per token,   160.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1240.36 ms /    45 runs   (   27.56 ms per token,    36.28 tokens per second)\n",
      "llama_print_timings:       total time =  1525.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    46.03 ms /    67 runs   (    0.69 ms per token,  1455.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   334.92 ms /    95 tokens (    3.53 ms per token,   283.65 tokens per second)\n",
      "llama_print_timings:        eval time =  1847.22 ms /    66 runs   (   27.99 ms per token,    35.73 tokens per second)\n",
      "llama_print_timings:       total time =  2298.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.55 ms /   256 runs   (    0.69 ms per token,  1458.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   885.26 ms /   280 tokens (    3.16 ms per token,   316.29 tokens per second)\n",
      "llama_print_timings:        eval time =  7422.88 ms /   255 runs   (   29.11 ms per token,    34.35 tokens per second)\n",
      "llama_print_timings:       total time =  8770.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.85 ms /   256 runs   (    0.69 ms per token,  1447.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   775.46 ms /   242 tokens (    3.20 ms per token,   312.07 tokens per second)\n",
      "llama_print_timings:        eval time =  7506.31 ms /   255 runs   (   29.44 ms per token,    33.97 tokens per second)\n",
      "llama_print_timings:       total time =  8763.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.31 ms /    49 runs   (    0.68 ms per token,  1470.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   978.33 ms /   292 tokens (    3.35 ms per token,   298.47 tokens per second)\n",
      "llama_print_timings:        eval time =  1385.61 ms /    48 runs   (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_print_timings:       total time =  2449.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.25 ms /    45 runs   (    0.69 ms per token,  1439.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1654.01 ms /   485 tokens (    3.41 ms per token,   293.23 tokens per second)\n",
      "llama_print_timings:        eval time =  1307.95 ms /    44 runs   (   29.73 ms per token,    33.64 tokens per second)\n",
      "llama_print_timings:       total time =  3041.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.92 ms /    42 runs   (    0.69 ms per token,  1452.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =   895.06 ms /   274 tokens (    3.27 ms per token,   306.13 tokens per second)\n",
      "llama_print_timings:        eval time =  1179.36 ms /    41 runs   (   28.76 ms per token,    34.76 tokens per second)\n",
      "llama_print_timings:       total time =  2149.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.57 ms /    46 runs   (    0.69 ms per token,  1457.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   800.70 ms /   247 tokens (    3.24 ms per token,   308.48 tokens per second)\n",
      "llama_print_timings:        eval time =  1288.19 ms /    45 runs   (   28.63 ms per token,    34.93 tokens per second)\n",
      "llama_print_timings:       total time =  2170.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    40.81 ms /    59 runs   (    0.69 ms per token,  1445.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1008.10 ms /   312 tokens (    3.23 ms per token,   309.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1670.78 ms /    58 runs   (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_print_timings:       total time =  2784.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.56 ms /    53 runs   (    0.69 ms per token,  1449.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   488.22 ms /   135 tokens (    3.62 ms per token,   276.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1455.86 ms /    52 runs   (   28.00 ms per token,    35.72 tokens per second)\n",
      "llama_print_timings:       total time =  2038.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.63 ms /    45 runs   (    0.68 ms per token,  1468.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1919.72 ms /   581 tokens (    3.30 ms per token,   302.65 tokens per second)\n",
      "llama_print_timings:        eval time =  1328.40 ms /    44 runs   (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time =  3327.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    19.24 ms /    28 runs   (    0.69 ms per token,  1455.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2207.38 ms /   618 tokens (    3.57 ms per token,   279.97 tokens per second)\n",
      "llama_print_timings:        eval time =   819.60 ms /    27 runs   (   30.36 ms per token,    32.94 tokens per second)\n",
      "llama_print_timings:       total time =  3079.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.34 ms /    43 runs   (    0.68 ms per token,  1465.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1902.43 ms /   520 tokens (    3.66 ms per token,   273.33 tokens per second)\n",
      "llama_print_timings:        eval time =  1255.88 ms /    42 runs   (   29.90 ms per token,    33.44 tokens per second)\n",
      "llama_print_timings:       total time =  3235.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.61 ms /    43 runs   (    0.74 ms per token,  1360.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1698.70 ms /   510 tokens (    3.33 ms per token,   300.23 tokens per second)\n",
      "llama_print_timings:        eval time =  1260.01 ms /    42 runs   (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  3041.50 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.90 ms /    36 runs   (    0.69 ms per token,  1445.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1758.18 ms /   502 tokens (    3.50 ms per token,   285.52 tokens per second)\n",
      "llama_print_timings:        eval time =  1032.24 ms /    35 runs   (   29.49 ms per token,    33.91 tokens per second)\n",
      "llama_print_timings:       total time =  2854.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.31 ms /   256 runs   (    0.70 ms per token,  1435.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1612.31 ms /   480 tokens (    3.36 ms per token,   297.71 tokens per second)\n",
      "llama_print_timings:        eval time =  7600.40 ms /   255 runs   (   29.81 ms per token,    33.55 tokens per second)\n",
      "llama_print_timings:       total time =  9703.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.60 ms /    46 runs   (    0.69 ms per token,  1455.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   217.14 ms /    52 tokens (    4.18 ms per token,   239.47 tokens per second)\n",
      "llama_print_timings:        eval time =  1234.98 ms /    45 runs   (   27.44 ms per token,    36.44 tokens per second)\n",
      "llama_print_timings:       total time =  1535.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.21 ms /    39 runs   (    0.70 ms per token,  1433.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1593.06 ms /   451 tokens (    3.53 ms per token,   283.10 tokens per second)\n",
      "llama_print_timings:        eval time =  1108.00 ms /    38 runs   (   29.16 ms per token,    34.30 tokens per second)\n",
      "llama_print_timings:       total time =  2772.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.66 ms /    37 runs   (    0.69 ms per token,  1442.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1743.65 ms /   510 tokens (    3.42 ms per token,   292.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1061.84 ms /    36 runs   (   29.50 ms per token,    33.90 tokens per second)\n",
      "llama_print_timings:       total time =  2873.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.90 ms /    36 runs   (    0.69 ms per token,  1445.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   911.82 ms /   267 tokens (    3.42 ms per token,   292.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1004.62 ms /    35 runs   (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_print_timings:       total time =  1978.83 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.41 ms /    36 runs   (    0.68 ms per token,  1474.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =   889.45 ms /   258 tokens (    3.45 ms per token,   290.07 tokens per second)\n",
      "llama_print_timings:        eval time =   999.88 ms /    35 runs   (   28.57 ms per token,    35.00 tokens per second)\n",
      "llama_print_timings:       total time =  1952.00 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.14 ms /    29 runs   (    0.69 ms per token,  1439.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =   897.58 ms /   274 tokens (    3.28 ms per token,   305.27 tokens per second)\n",
      "llama_print_timings:        eval time =   802.35 ms /    28 runs   (   28.66 ms per token,    34.90 tokens per second)\n",
      "llama_print_timings:       total time =  1750.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.01 ms /    45 runs   (    0.69 ms per token,  1450.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1972.86 ms /   605 tokens (    3.26 ms per token,   306.66 tokens per second)\n",
      "llama_print_timings:        eval time =  1325.09 ms /    44 runs   (   30.12 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =  3377.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.96 ms /    43 runs   (    0.70 ms per token,  1435.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1983.05 ms /   563 tokens (    3.52 ms per token,   283.91 tokens per second)\n",
      "llama_print_timings:        eval time =  1248.81 ms /    42 runs   (   29.73 ms per token,    33.63 tokens per second)\n",
      "llama_print_timings:       total time =  3309.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.32 ms /    40 runs   (    0.68 ms per token,  1464.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1348.41 ms /   411 tokens (    3.28 ms per token,   304.80 tokens per second)\n",
      "llama_print_timings:        eval time =  1135.69 ms /    39 runs   (   29.12 ms per token,    34.34 tokens per second)\n",
      "llama_print_timings:       total time =  2554.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.90 ms /    36 runs   (    0.69 ms per token,  1445.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1117.45 ms /   323 tokens (    3.46 ms per token,   289.05 tokens per second)\n",
      "llama_print_timings:        eval time =  1011.07 ms /    35 runs   (   28.89 ms per token,    34.62 tokens per second)\n",
      "llama_print_timings:       total time =  2191.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.87 ms /    49 runs   (    0.69 ms per token,  1446.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =   484.96 ms /   130 tokens (    3.73 ms per token,   268.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1329.09 ms /    48 runs   (   27.69 ms per token,    36.11 tokens per second)\n",
      "llama_print_timings:       total time =  1904.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.58 ms /    63 runs   (    0.69 ms per token,  1445.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =   325.60 ms /    82 tokens (    3.97 ms per token,   251.85 tokens per second)\n",
      "llama_print_timings:        eval time =  1717.52 ms /    62 runs   (   27.70 ms per token,    36.10 tokens per second)\n",
      "llama_print_timings:       total time =  2154.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.00 ms /   256 runs   (    0.69 ms per token,  1446.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1014.52 ms /   305 tokens (    3.33 ms per token,   300.64 tokens per second)\n",
      "llama_print_timings:        eval time =  7505.26 ms /   255 runs   (   29.43 ms per token,    33.98 tokens per second)\n",
      "llama_print_timings:       total time =  8993.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.38 ms /    62 runs   (    0.70 ms per token,  1429.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1327.67 ms /   379 tokens (    3.50 ms per token,   285.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1778.04 ms /    61 runs   (   29.15 ms per token,    34.31 tokens per second)\n",
      "llama_print_timings:       total time =  3218.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.22 ms /    51 runs   (    0.71 ms per token,  1408.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   911.28 ms /   270 tokens (    3.38 ms per token,   296.29 tokens per second)\n",
      "llama_print_timings:        eval time =  1426.50 ms /    50 runs   (   28.53 ms per token,    35.05 tokens per second)\n",
      "llama_print_timings:       total time =  2436.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.02 ms /    29 runs   (    0.69 ms per token,  1448.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1271.83 ms /   362 tokens (    3.51 ms per token,   284.63 tokens per second)\n",
      "llama_print_timings:        eval time =   811.62 ms /    28 runs   (   28.99 ms per token,    34.50 tokens per second)\n",
      "llama_print_timings:       total time =  2136.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.36 ms /    40 runs   (    0.68 ms per token,  1461.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1634.48 ms /   463 tokens (    3.53 ms per token,   283.27 tokens per second)\n",
      "llama_print_timings:        eval time =  1153.45 ms /    39 runs   (   29.58 ms per token,    33.81 tokens per second)\n",
      "llama_print_timings:       total time =  2858.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.76 ms /    49 runs   (    0.69 ms per token,  1451.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1473.98 ms /   441 tokens (    3.34 ms per token,   299.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1405.08 ms /    48 runs   (   29.27 ms per token,    34.16 tokens per second)\n",
      "llama_print_timings:       total time =  2964.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.46 ms /    53 runs   (    0.69 ms per token,  1453.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1125.86 ms /   350 tokens (    3.22 ms per token,   310.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1500.71 ms /    52 runs   (   28.86 ms per token,    34.65 tokens per second)\n",
      "llama_print_timings:       total time =  2721.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.45 ms /    49 runs   (    0.68 ms per token,  1464.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   481.57 ms /   130 tokens (    3.70 ms per token,   269.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1346.71 ms /    48 runs   (   28.06 ms per token,    35.64 tokens per second)\n",
      "llama_print_timings:       total time =  1911.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    42.94 ms /    63 runs   (    0.68 ms per token,  1467.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   325.83 ms /    82 tokens (    3.97 ms per token,   251.66 tokens per second)\n",
      "llama_print_timings:        eval time =  1732.32 ms /    62 runs   (   27.94 ms per token,    35.79 tokens per second)\n",
      "llama_print_timings:       total time =  2166.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.51 ms /    44 runs   (    0.69 ms per token,  1442.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =   886.82 ms /   273 tokens (    3.25 ms per token,   307.84 tokens per second)\n",
      "llama_print_timings:        eval time =  1227.75 ms /    43 runs   (   28.55 ms per token,    35.02 tokens per second)\n",
      "llama_print_timings:       total time =  2191.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.38 ms /    52 runs   (    0.68 ms per token,  1469.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   807.29 ms /   251 tokens (    3.22 ms per token,   310.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1460.61 ms /    51 runs   (   28.64 ms per token,    34.92 tokens per second)\n",
      "llama_print_timings:       total time =  2356.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.67 ms /    46 runs   (    0.69 ms per token,  1452.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =   893.34 ms /   257 tokens (    3.48 ms per token,   287.68 tokens per second)\n",
      "llama_print_timings:        eval time =  1290.07 ms /    45 runs   (   28.67 ms per token,    34.88 tokens per second)\n",
      "llama_print_timings:       total time =  2263.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.53 ms /    46 runs   (    0.69 ms per token,  1459.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   989.17 ms /   289 tokens (    3.42 ms per token,   292.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1295.26 ms /    45 runs   (   28.78 ms per token,    34.74 tokens per second)\n",
      "llama_print_timings:       total time =  2364.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.30 ms /    42 runs   (    0.70 ms per token,  1433.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1126.50 ms /   344 tokens (    3.27 ms per token,   305.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1191.57 ms /    41 runs   (   29.06 ms per token,    34.41 tokens per second)\n",
      "llama_print_timings:       total time =  2390.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    19.86 ms /    29 runs   (    0.68 ms per token,  1460.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2214.31 ms /   622 tokens (    3.56 ms per token,   280.90 tokens per second)\n",
      "llama_print_timings:        eval time =   849.09 ms /    28 runs   (   30.32 ms per token,    32.98 tokens per second)\n",
      "llama_print_timings:       total time =  3113.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.67 ms /    29 runs   (    0.71 ms per token,  1403.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2186.18 ms /   629 tokens (    3.48 ms per token,   287.72 tokens per second)\n",
      "llama_print_timings:        eval time =   840.02 ms /    28 runs   (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  3080.58 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.04 ms /    45 runs   (    0.69 ms per token,  1449.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1568.22 ms /   469 tokens (    3.34 ms per token,   299.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1300.20 ms /    44 runs   (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_print_timings:       total time =  2947.08 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.20 ms /    41 runs   (    0.69 ms per token,  1453.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1090.49 ms /   322 tokens (    3.39 ms per token,   295.28 tokens per second)\n",
      "llama_print_timings:        eval time =  1169.83 ms /    40 runs   (   29.25 ms per token,    34.19 tokens per second)\n",
      "llama_print_timings:       total time =  2333.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.98 ms /    37 runs   (    0.70 ms per token,  1424.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1270.94 ms /   365 tokens (    3.48 ms per token,   287.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1085.04 ms /    36 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  2425.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.17 ms /    47 runs   (    0.68 ms per token,  1460.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1153.43 ms /   349 tokens (    3.30 ms per token,   302.58 tokens per second)\n",
      "llama_print_timings:        eval time =  1331.48 ms /    46 runs   (   28.95 ms per token,    34.55 tokens per second)\n",
      "llama_print_timings:       total time =  2568.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.63 ms /    36 runs   (    0.68 ms per token,  1461.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =   705.74 ms /   222 tokens (    3.18 ms per token,   314.56 tokens per second)\n",
      "llama_print_timings:        eval time =   985.42 ms /    35 runs   (   28.15 ms per token,    35.52 tokens per second)\n",
      "llama_print_timings:       total time =  1755.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.53 ms /    39 runs   (    0.68 ms per token,  1470.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   603.62 ms /   182 tokens (    3.32 ms per token,   301.52 tokens per second)\n",
      "llama_print_timings:        eval time =  1075.35 ms /    38 runs   (   28.30 ms per token,    35.34 tokens per second)\n",
      "llama_print_timings:       total time =  1746.53 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.42 ms /    35 runs   (    0.73 ms per token,  1377.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =   500.41 ms /   153 tokens (    3.27 ms per token,   305.75 tokens per second)\n",
      "llama_print_timings:        eval time =   949.42 ms /    34 runs   (   27.92 ms per token,    35.81 tokens per second)\n",
      "llama_print_timings:       total time =  1514.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    65.91 ms /    96 runs   (    0.69 ms per token,  1456.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =   489.73 ms /   132 tokens (    3.71 ms per token,   269.53 tokens per second)\n",
      "llama_print_timings:        eval time =  2678.82 ms /    95 runs   (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_print_timings:       total time =  3337.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.95 ms /    56 runs   (    0.70 ms per token,  1437.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   526.04 ms /   139 tokens (    3.78 ms per token,   264.24 tokens per second)\n",
      "llama_print_timings:        eval time =  1620.55 ms /    55 runs   (   29.46 ms per token,    33.94 tokens per second)\n",
      "llama_print_timings:       total time =  2249.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.83 ms /    45 runs   (    0.69 ms per token,  1459.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   426.29 ms /   121 tokens (    3.52 ms per token,   283.85 tokens per second)\n",
      "llama_print_timings:        eval time =  1226.20 ms /    44 runs   (   27.87 ms per token,    35.88 tokens per second)\n",
      "llama_print_timings:       total time =  1732.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.91 ms /    42 runs   (    0.71 ms per token,  1404.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =   406.24 ms /   121 tokens (    3.36 ms per token,   297.86 tokens per second)\n",
      "llama_print_timings:        eval time =  1134.70 ms /    41 runs   (   27.68 ms per token,    36.13 tokens per second)\n",
      "llama_print_timings:       total time =  1618.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.04 ms /    38 runs   (    0.69 ms per token,  1459.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =   413.62 ms /   118 tokens (    3.51 ms per token,   285.28 tokens per second)\n",
      "llama_print_timings:        eval time =  1040.89 ms /    37 runs   (   28.13 ms per token,    35.55 tokens per second)\n",
      "llama_print_timings:       total time =  1523.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    57.57 ms /    83 runs   (    0.69 ms per token,  1441.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   617.17 ms /   178 tokens (    3.47 ms per token,   288.41 tokens per second)\n",
      "llama_print_timings:        eval time =  2310.47 ms /    82 runs   (   28.18 ms per token,    35.49 tokens per second)\n",
      "llama_print_timings:       total time =  3083.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.78 ms /    38 runs   (    0.68 ms per token,  1474.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   511.21 ms /   151 tokens (    3.39 ms per token,   295.38 tokens per second)\n",
      "llama_print_timings:        eval time =  1044.75 ms /    37 runs   (   28.24 ms per token,    35.42 tokens per second)\n",
      "llama_print_timings:       total time =  1622.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.29 ms /    50 runs   (    0.69 ms per token,  1458.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =   406.42 ms /    97 tokens (    4.19 ms per token,   238.67 tokens per second)\n",
      "llama_print_timings:        eval time =  1374.28 ms /    49 runs   (   28.05 ms per token,    35.66 tokens per second)\n",
      "llama_print_timings:       total time =  1869.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.77 ms /    33 runs   (    0.69 ms per token,  1449.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =   408.67 ms /   120 tokens (    3.41 ms per token,   293.64 tokens per second)\n",
      "llama_print_timings:        eval time =   897.45 ms /    32 runs   (   28.05 ms per token,    35.66 tokens per second)\n",
      "llama_print_timings:       total time =  1363.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.66 ms /    50 runs   (    0.69 ms per token,  1442.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =   845.91 ms /   255 tokens (    3.32 ms per token,   301.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1405.50 ms /    49 runs   (   28.68 ms per token,    34.86 tokens per second)\n",
      "llama_print_timings:       total time =  2343.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.82 ms /    55 runs   (    0.69 ms per token,  1454.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   842.82 ms /   250 tokens (    3.37 ms per token,   296.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1545.36 ms /    54 runs   (   28.62 ms per token,    34.94 tokens per second)\n",
      "llama_print_timings:       total time =  2485.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.87 ms /    61 runs   (    0.69 ms per token,  1456.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1649.79 ms /   457 tokens (    3.61 ms per token,   277.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1775.91 ms /    60 runs   (   29.60 ms per token,    33.79 tokens per second)\n",
      "llama_print_timings:       total time =  3531.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.26 ms /    38 runs   (    0.69 ms per token,  1446.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1592.46 ms /   466 tokens (    3.42 ms per token,   292.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1087.61 ms /    37 runs   (   29.39 ms per token,    34.02 tokens per second)\n",
      "llama_print_timings:       total time =  2747.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    42.31 ms /    61 runs   (    0.69 ms per token,  1441.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1505.35 ms /   436 tokens (    3.45 ms per token,   289.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1764.45 ms /    60 runs   (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_print_timings:       total time =  3379.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.96 ms /    35 runs   (    0.68 ms per token,  1461.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1565.26 ms /   449 tokens (    3.49 ms per token,   286.85 tokens per second)\n",
      "llama_print_timings:        eval time =   997.55 ms /    34 runs   (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_print_timings:       total time =  2625.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.50 ms /    44 runs   (    0.69 ms per token,  1442.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1118.89 ms /   325 tokens (    3.44 ms per token,   290.47 tokens per second)\n",
      "llama_print_timings:        eval time =  1244.88 ms /    43 runs   (   28.95 ms per token,    34.54 tokens per second)\n",
      "llama_print_timings:       total time =  2442.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    19.16 ms /    28 runs   (    0.68 ms per token,  1461.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1363.45 ms /   404 tokens (    3.37 ms per token,   296.31 tokens per second)\n",
      "llama_print_timings:        eval time =   784.62 ms /    27 runs   (   29.06 ms per token,    34.41 tokens per second)\n",
      "llama_print_timings:       total time =  2199.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    83.78 ms /   121 runs   (    0.69 ms per token,  1444.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =   951.89 ms /   319 tokens (    2.98 ms per token,   335.12 tokens per second)\n",
      "llama_print_timings:        eval time =  3463.89 ms /   120 runs   (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_print_timings:       total time =  4641.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    45.42 ms /    66 runs   (    0.69 ms per token,  1453.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1047.47 ms /   304 tokens (    3.45 ms per token,   290.22 tokens per second)\n",
      "llama_print_timings:        eval time =  1880.36 ms /    65 runs   (   28.93 ms per token,    34.57 tokens per second)\n",
      "llama_print_timings:       total time =  3043.51 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.55 ms /    52 runs   (    0.68 ms per token,  1462.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =   602.08 ms /   167 tokens (    3.61 ms per token,   277.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1437.15 ms /    51 runs   (   28.18 ms per token,    35.49 tokens per second)\n",
      "llama_print_timings:       total time =  2131.73 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.23 ms /    50 runs   (    0.68 ms per token,  1460.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2041.32 ms /   547 tokens (    3.73 ms per token,   267.96 tokens per second)\n",
      "llama_print_timings:        eval time =  1478.65 ms /    49 runs   (   30.18 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3606.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.95 ms /   256 runs   (    0.70 ms per token,  1430.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   594.03 ms /   173 tokens (    3.43 ms per token,   291.23 tokens per second)\n",
      "llama_print_timings:        eval time =  7304.64 ms /   255 runs   (   28.65 ms per token,    34.91 tokens per second)\n",
      "llama_print_timings:       total time =  8373.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.67 ms /    41 runs   (    0.70 ms per token,  1429.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2130.53 ms /   599 tokens (    3.56 ms per token,   281.15 tokens per second)\n",
      "llama_print_timings:        eval time =  1220.68 ms /    40 runs   (   30.52 ms per token,    32.77 tokens per second)\n",
      "llama_print_timings:       total time =  3426.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.94 ms /    43 runs   (    0.70 ms per token,  1436.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1329.41 ms /   397 tokens (    3.35 ms per token,   298.63 tokens per second)\n",
      "llama_print_timings:        eval time =  1226.63 ms /    42 runs   (   29.21 ms per token,    34.24 tokens per second)\n",
      "llama_print_timings:       total time =  2631.63 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   142.09 ms /   203 runs   (    0.70 ms per token,  1428.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =   395.66 ms /   121 tokens (    3.27 ms per token,   305.82 tokens per second)\n",
      "llama_print_timings:        eval time =  5742.69 ms /   202 runs   (   28.43 ms per token,    35.18 tokens per second)\n",
      "llama_print_timings:       total time =  6520.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    43.45 ms /    62 runs   (    0.70 ms per token,  1427.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1688.20 ms /   482 tokens (    3.50 ms per token,   285.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1800.14 ms /    61 runs   (   29.51 ms per token,    33.89 tokens per second)\n",
      "llama_print_timings:       total time =  3602.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.36 ms /    49 runs   (    0.70 ms per token,  1426.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1221.09 ms /   355 tokens (    3.44 ms per token,   290.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1392.81 ms /    48 runs   (   29.02 ms per token,    34.46 tokens per second)\n",
      "llama_print_timings:       total time =  2702.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.31 ms /    46 runs   (    0.70 ms per token,  1423.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2151.88 ms /   602 tokens (    3.57 ms per token,   279.75 tokens per second)\n",
      "llama_print_timings:        eval time =  1362.97 ms /    45 runs   (   30.29 ms per token,    33.02 tokens per second)\n",
      "llama_print_timings:       total time =  3596.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.09 ms /    51 runs   (    0.71 ms per token,  1413.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2303.67 ms /   656 tokens (    3.51 ms per token,   284.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1526.60 ms /    50 runs   (   30.53 ms per token,    32.75 tokens per second)\n",
      "llama_print_timings:       total time =  3922.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.49 ms /    54 runs   (    0.69 ms per token,  1440.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2322.61 ms /   664 tokens (    3.50 ms per token,   285.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1615.38 ms /    53 runs   (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_print_timings:       total time =  4035.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    35.65 ms /    50 runs   (    0.71 ms per token,  1402.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2415.25 ms /   674 tokens (    3.58 ms per token,   279.06 tokens per second)\n",
      "llama_print_timings:        eval time =  1494.76 ms /    49 runs   (   30.51 ms per token,    32.78 tokens per second)\n",
      "llama_print_timings:       total time =  4008.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.80 ms /    41 runs   (    0.70 ms per token,  1423.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2270.50 ms /   621 tokens (    3.66 ms per token,   273.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1211.61 ms /    40 runs   (   30.29 ms per token,    33.01 tokens per second)\n",
      "llama_print_timings:       total time =  3557.17 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.15 ms /    53 runs   (    0.72 ms per token,  1389.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2338.59 ms /   671 tokens (    3.49 ms per token,   286.92 tokens per second)\n",
      "llama_print_timings:        eval time =  1582.45 ms /    52 runs   (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_print_timings:       total time =  4021.21 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.14 ms /    60 runs   (    0.69 ms per token,  1458.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2438.49 ms /   689 tokens (    3.54 ms per token,   282.55 tokens per second)\n",
      "llama_print_timings:        eval time =  1806.26 ms /    59 runs   (   30.61 ms per token,    32.66 tokens per second)\n",
      "llama_print_timings:       total time =  4352.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.54 ms /    53 runs   (    0.69 ms per token,  1450.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2475.93 ms /   675 tokens (    3.67 ms per token,   272.62 tokens per second)\n",
      "llama_print_timings:        eval time =  1589.72 ms /    52 runs   (   30.57 ms per token,    32.71 tokens per second)\n",
      "llama_print_timings:       total time =  4162.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.77 ms /    43 runs   (    0.69 ms per token,  1444.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2282.37 ms /   638 tokens (    3.58 ms per token,   279.53 tokens per second)\n",
      "llama_print_timings:        eval time =  1275.82 ms /    42 runs   (   30.38 ms per token,    32.92 tokens per second)\n",
      "llama_print_timings:       total time =  3636.97 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.87 ms /    45 runs   (    0.69 ms per token,  1457.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2510.23 ms /   695 tokens (    3.61 ms per token,   276.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1347.82 ms /    44 runs   (   30.63 ms per token,    32.65 tokens per second)\n",
      "llama_print_timings:       total time =  3939.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.88 ms /    48 runs   (    0.69 ms per token,  1459.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2191.05 ms /   604 tokens (    3.63 ms per token,   275.67 tokens per second)\n",
      "llama_print_timings:        eval time =  1427.85 ms /    47 runs   (   30.38 ms per token,    32.92 tokens per second)\n",
      "llama_print_timings:       total time =  3706.38 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.30 ms /    45 runs   (    0.70 ms per token,  1437.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2527.47 ms /   696 tokens (    3.63 ms per token,   275.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1345.29 ms /    44 runs   (   30.57 ms per token,    32.71 tokens per second)\n",
      "llama_print_timings:       total time =  3959.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.45 ms /    56 runs   (    0.69 ms per token,  1456.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2529.51 ms /   680 tokens (    3.72 ms per token,   268.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1682.37 ms /    55 runs   (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_print_timings:       total time =  4316.32 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.67 ms /    51 runs   (    0.68 ms per token,  1471.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2219.42 ms /   658 tokens (    3.37 ms per token,   296.47 tokens per second)\n",
      "llama_print_timings:        eval time =  1528.27 ms /    50 runs   (   30.57 ms per token,    32.72 tokens per second)\n",
      "llama_print_timings:       total time =  3837.23 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   131.55 ms /   190 runs   (    0.69 ms per token,  1444.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2569.81 ms /   697 tokens (    3.69 ms per token,   271.23 tokens per second)\n",
      "llama_print_timings:        eval time =  5852.99 ms /   189 runs   (   30.97 ms per token,    32.29 tokens per second)\n",
      "llama_print_timings:       total time =  8779.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.38 ms /    43 runs   (    0.68 ms per token,  1463.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2362.11 ms /   641 tokens (    3.69 ms per token,   271.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1274.74 ms /    42 runs   (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_print_timings:       total time =  3714.25 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.10 ms /    41 runs   (    0.69 ms per token,  1459.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2384.51 ms /   711 tokens (    3.35 ms per token,   298.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1223.44 ms /    40 runs   (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_print_timings:       total time =  3682.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.87 ms /    42 runs   (    0.69 ms per token,  1454.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2351.35 ms /   657 tokens (    3.58 ms per token,   279.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1248.52 ms /    41 runs   (   30.45 ms per token,    32.84 tokens per second)\n",
      "llama_print_timings:       total time =  3673.77 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.46 ms /    55 runs   (    0.68 ms per token,  1468.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2482.37 ms /   692 tokens (    3.59 ms per token,   278.77 tokens per second)\n",
      "llama_print_timings:        eval time =  1660.41 ms /    54 runs   (   30.75 ms per token,    32.52 tokens per second)\n",
      "llama_print_timings:       total time =  4238.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.34 ms /    41 runs   (    0.69 ms per token,  1446.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2422.52 ms /   678 tokens (    3.57 ms per token,   279.87 tokens per second)\n",
      "llama_print_timings:        eval time =  1223.20 ms /    40 runs   (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_print_timings:       total time =  3720.02 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.20 ms /    52 runs   (    0.70 ms per token,  1436.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2598.96 ms /   714 tokens (    3.64 ms per token,   274.73 tokens per second)\n",
      "llama_print_timings:        eval time =  1569.30 ms /    51 runs   (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_print_timings:       total time =  4262.07 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.50 ms /    45 runs   (    0.70 ms per token,  1428.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =   912.54 ms /   284 tokens (    3.21 ms per token,   311.22 tokens per second)\n",
      "llama_print_timings:        eval time =  1253.20 ms /    44 runs   (   28.48 ms per token,    35.11 tokens per second)\n",
      "llama_print_timings:       total time =  2248.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.68 ms /   256 runs   (    0.69 ms per token,  1440.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1933.44 ms /   524 tokens (    3.69 ms per token,   271.02 tokens per second)\n",
      "llama_print_timings:        eval time =  7701.40 ms /   255 runs   (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_print_timings:       total time = 10122.29 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.33 ms /    50 runs   (    0.69 ms per token,  1456.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2093.12 ms /   546 tokens (    3.83 ms per token,   260.86 tokens per second)\n",
      "llama_print_timings:        eval time =  1468.67 ms /    49 runs   (   29.97 ms per token,    33.36 tokens per second)\n",
      "llama_print_timings:       total time =  3651.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.42 ms /    50 runs   (    0.69 ms per token,  1452.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2008.82 ms /   549 tokens (    3.66 ms per token,   273.29 tokens per second)\n",
      "llama_print_timings:        eval time =  1466.66 ms /    49 runs   (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_print_timings:       total time =  3566.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.55 ms /    61 runs   (    0.68 ms per token,  1468.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1341.40 ms /   390 tokens (    3.44 ms per token,   290.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1758.85 ms /    60 runs   (   29.31 ms per token,    34.11 tokens per second)\n",
      "llama_print_timings:       total time =  3206.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.38 ms /   256 runs   (    0.69 ms per token,  1443.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =   496.54 ms /   159 tokens (    3.12 ms per token,   320.22 tokens per second)\n",
      "llama_print_timings:        eval time =  7271.89 ms /   255 runs   (   28.52 ms per token,    35.07 tokens per second)\n",
      "llama_print_timings:       total time =  8247.47 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.94 ms /    46 runs   (    0.69 ms per token,  1440.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1916.98 ms /   534 tokens (    3.59 ms per token,   278.56 tokens per second)\n",
      "llama_print_timings:        eval time =  1330.12 ms /    45 runs   (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_print_timings:       total time =  3333.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.16 ms /    53 runs   (    0.72 ms per token,  1388.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2007.42 ms /   565 tokens (    3.55 ms per token,   281.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1547.74 ms /    52 runs   (   29.76 ms per token,    33.60 tokens per second)\n",
      "llama_print_timings:       total time =  3657.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.97 ms /   256 runs   (    0.70 ms per token,  1438.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2002.45 ms /   575 tokens (    3.48 ms per token,   287.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7761.40 ms /   255 runs   (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_print_timings:       total time = 10241.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.09 ms /   256 runs   (    0.68 ms per token,  1462.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =   596.44 ms /   184 tokens (    3.24 ms per token,   308.50 tokens per second)\n",
      "llama_print_timings:        eval time =  7313.71 ms /   255 runs   (   28.68 ms per token,    34.87 tokens per second)\n",
      "llama_print_timings:       total time =  8373.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.84 ms /   256 runs   (    0.69 ms per token,  1447.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1888.28 ms /   572 tokens (    3.30 ms per token,   302.92 tokens per second)\n",
      "llama_print_timings:        eval time =  7755.45 ms /   255 runs   (   30.41 ms per token,    32.88 tokens per second)\n",
      "llama_print_timings:       total time = 10120.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.01 ms /   256 runs   (    0.70 ms per token,  1438.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1889.68 ms /   559 tokens (    3.38 ms per token,   295.82 tokens per second)\n",
      "llama_print_timings:        eval time =  7722.72 ms /   255 runs   (   30.29 ms per token,    33.02 tokens per second)\n",
      "llama_print_timings:       total time = 10089.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.39 ms /   256 runs   (    0.69 ms per token,  1443.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =   682.81 ms /   213 tokens (    3.21 ms per token,   311.94 tokens per second)\n",
      "llama_print_timings:        eval time =  7298.15 ms /   255 runs   (   28.62 ms per token,    34.94 tokens per second)\n",
      "llama_print_timings:       total time =  8464.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.11 ms /    47 runs   (    0.68 ms per token,  1463.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1938.17 ms /   572 tokens (    3.39 ms per token,   295.12 tokens per second)\n",
      "llama_print_timings:        eval time =  1387.88 ms /    46 runs   (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3410.09 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.25 ms /    41 runs   (    0.69 ms per token,  1451.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1509.31 ms /   481 tokens (    3.14 ms per token,   318.69 tokens per second)\n",
      "llama_print_timings:        eval time =  1188.12 ms /    40 runs   (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_print_timings:       total time =  2768.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    41.78 ms /    61 runs   (    0.68 ms per token,  1459.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1618.36 ms /   477 tokens (    3.39 ms per token,   294.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1782.93 ms /    60 runs   (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_print_timings:       total time =  3508.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.93 ms /    46 runs   (    0.69 ms per token,  1440.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1908.37 ms /   542 tokens (    3.52 ms per token,   284.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1342.47 ms /    45 runs   (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_print_timings:       total time =  3469.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    53.06 ms /    77 runs   (    0.69 ms per token,  1451.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1864.13 ms /   537 tokens (    3.47 ms per token,   288.07 tokens per second)\n",
      "llama_print_timings:        eval time =  2281.41 ms /    76 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  4281.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.66 ms /    40 runs   (    0.69 ms per token,  1446.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1695.37 ms /   510 tokens (    3.32 ms per token,   300.82 tokens per second)\n",
      "llama_print_timings:        eval time =  1164.33 ms /    39 runs   (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_print_timings:       total time =  2929.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.45 ms /    36 runs   (    0.68 ms per token,  1472.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1013.24 ms /   308 tokens (    3.29 ms per token,   303.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1007.97 ms /    35 runs   (   28.80 ms per token,    34.72 tokens per second)\n",
      "llama_print_timings:       total time =  2083.57 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.51 ms /    37 runs   (    0.69 ms per token,  1450.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =   308.16 ms /    65 tokens (    4.74 ms per token,   210.93 tokens per second)\n",
      "llama_print_timings:        eval time =   998.14 ms /    36 runs   (   27.73 ms per token,    36.07 tokens per second)\n",
      "llama_print_timings:       total time =  1370.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.58 ms /   256 runs   (    0.69 ms per token,  1458.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   794.77 ms /   237 tokens (    3.35 ms per token,   298.20 tokens per second)\n",
      "llama_print_timings:        eval time =  7399.06 ms /   255 runs   (   29.02 ms per token,    34.46 tokens per second)\n",
      "llama_print_timings:       total time =  8653.36 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.00 ms /    57 runs   (    0.68 ms per token,  1461.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =   323.54 ms /    78 tokens (    4.15 ms per token,   241.08 tokens per second)\n",
      "llama_print_timings:        eval time =  1561.60 ms /    56 runs   (   27.89 ms per token,    35.86 tokens per second)\n",
      "llama_print_timings:       total time =  1983.12 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.20 ms /    48 runs   (    0.69 ms per token,  1445.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =   702.36 ms /   217 tokens (    3.24 ms per token,   308.96 tokens per second)\n",
      "llama_print_timings:        eval time =  1343.47 ms /    47 runs   (   28.58 ms per token,    34.98 tokens per second)\n",
      "llama_print_timings:       total time =  2128.81 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   107.34 ms /   157 runs   (    0.68 ms per token,  1462.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   486.47 ms /   130 tokens (    3.74 ms per token,   267.23 tokens per second)\n",
      "llama_print_timings:        eval time =  4413.62 ms /   156 runs   (   28.29 ms per token,    35.35 tokens per second)\n",
      "llama_print_timings:       total time =  5176.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.37 ms /    56 runs   (    0.67 ms per token,  1498.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =   393.47 ms /    98 tokens (    4.02 ms per token,   249.07 tokens per second)\n",
      "llama_print_timings:        eval time =  1532.54 ms /    55 runs   (   27.86 ms per token,    35.89 tokens per second)\n",
      "llama_print_timings:       total time =  2020.96 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.04 ms /    36 runs   (    0.70 ms per token,  1437.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2315.38 ms /   610 tokens (    3.80 ms per token,   263.46 tokens per second)\n",
      "llama_print_timings:        eval time =  1065.02 ms /    35 runs   (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_print_timings:       total time =  3448.76 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    96.13 ms /   129 runs   (    0.75 ms per token,  1341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2221.41 ms /   584 tokens (    3.80 ms per token,   262.90 tokens per second)\n",
      "llama_print_timings:        eval time =  3838.16 ms /   128 runs   (   29.99 ms per token,    33.35 tokens per second)\n",
      "llama_print_timings:       total time =  6322.11 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    38.77 ms /    56 runs   (    0.69 ms per token,  1444.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2569.66 ms /   688 tokens (    3.73 ms per token,   267.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1672.93 ms /    55 runs   (   30.42 ms per token,    32.88 tokens per second)\n",
      "llama_print_timings:       total time =  4344.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.03 ms /    48 runs   (    0.69 ms per token,  1453.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2587.91 ms /   713 tokens (    3.63 ms per token,   275.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1438.18 ms /    47 runs   (   30.60 ms per token,    32.68 tokens per second)\n",
      "llama_print_timings:       total time =  4114.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.11 ms /    44 runs   (    0.71 ms per token,  1414.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2571.29 ms /   710 tokens (    3.62 ms per token,   276.13 tokens per second)\n",
      "llama_print_timings:        eval time =  1301.95 ms /    43 runs   (   30.28 ms per token,    33.03 tokens per second)\n",
      "llama_print_timings:       total time =  3957.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.57 ms /    37 runs   (    0.69 ms per token,  1447.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2408.57 ms /   655 tokens (    3.68 ms per token,   271.95 tokens per second)\n",
      "llama_print_timings:        eval time =  1094.83 ms /    36 runs   (   30.41 ms per token,    32.88 tokens per second)\n",
      "llama_print_timings:       total time =  3571.65 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.52 ms /    47 runs   (    0.69 ms per token,  1445.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =   918.23 ms /   264 tokens (    3.48 ms per token,   287.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1316.60 ms /    46 runs   (   28.62 ms per token,    34.94 tokens per second)\n",
      "llama_print_timings:       total time =  2317.61 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.40 ms /    46 runs   (    0.68 ms per token,  1464.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   615.40 ms /   188 tokens (    3.27 ms per token,   305.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1263.53 ms /    45 runs   (   28.08 ms per token,    35.61 tokens per second)\n",
      "llama_print_timings:       total time =  1960.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.32 ms /    31 runs   (    0.69 ms per token,  1454.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1169.21 ms /   350 tokens (    3.34 ms per token,   299.35 tokens per second)\n",
      "llama_print_timings:        eval time =   878.23 ms /    30 runs   (   29.27 ms per token,    34.16 tokens per second)\n",
      "llama_print_timings:       total time =  2100.44 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.82 ms /    39 runs   (    0.69 ms per token,  1454.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1538.40 ms /   427 tokens (    3.60 ms per token,   277.56 tokens per second)\n",
      "llama_print_timings:        eval time =  1119.90 ms /    38 runs   (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_print_timings:       total time =  2728.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.71 ms /    42 runs   (    0.68 ms per token,  1463.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1252.88 ms /   370 tokens (    3.39 ms per token,   295.32 tokens per second)\n",
      "llama_print_timings:        eval time =  1193.95 ms /    41 runs   (   29.12 ms per token,    34.34 tokens per second)\n",
      "llama_print_timings:       total time =  2520.90 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.28 ms /    34 runs   (    0.68 ms per token,  1460.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1519.29 ms /   437 tokens (    3.48 ms per token,   287.63 tokens per second)\n",
      "llama_print_timings:        eval time =   975.34 ms /    33 runs   (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_print_timings:       total time =  2552.06 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.36 ms /    33 runs   (    0.68 ms per token,  1475.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1752.29 ms /   534 tokens (    3.28 ms per token,   304.74 tokens per second)\n",
      "llama_print_timings:        eval time =   957.77 ms /    32 runs   (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_print_timings:       total time =  2767.18 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.29 ms /    34 runs   (    0.69 ms per token,  1459.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1352.37 ms /   389 tokens (    3.48 ms per token,   287.64 tokens per second)\n",
      "llama_print_timings:        eval time =   963.43 ms /    33 runs   (   29.19 ms per token,    34.25 tokens per second)\n",
      "llama_print_timings:       total time =  2374.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.66 ms /    40 runs   (    0.69 ms per token,  1446.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1260.26 ms /   375 tokens (    3.36 ms per token,   297.56 tokens per second)\n",
      "llama_print_timings:        eval time =  1135.51 ms /    39 runs   (   29.12 ms per token,    34.35 tokens per second)\n",
      "llama_print_timings:       total time =  2466.37 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.89 ms /    46 runs   (    0.69 ms per token,  1442.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1639.20 ms /   468 tokens (    3.50 ms per token,   285.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1351.35 ms /    45 runs   (   30.03 ms per token,    33.30 tokens per second)\n",
      "llama_print_timings:       total time =  3073.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.72 ms /    34 runs   (    0.70 ms per token,  1433.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1686.58 ms /   469 tokens (    3.60 ms per token,   278.08 tokens per second)\n",
      "llama_print_timings:        eval time =  1043.88 ms /    33 runs   (   31.63 ms per token,    31.61 tokens per second)\n",
      "llama_print_timings:       total time =  2793.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.21 ms /    36 runs   (    0.70 ms per token,  1427.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1350.43 ms /   371 tokens (    3.64 ms per token,   274.73 tokens per second)\n",
      "llama_print_timings:        eval time =  1057.60 ms /    35 runs   (   30.22 ms per token,    33.09 tokens per second)\n",
      "llama_print_timings:       total time =  2476.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.04 ms /    40 runs   (    0.70 ms per token,  1426.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1538.98 ms /   418 tokens (    3.68 ms per token,   271.61 tokens per second)\n",
      "llama_print_timings:        eval time =  1193.36 ms /    39 runs   (   30.60 ms per token,    32.68 tokens per second)\n",
      "llama_print_timings:       total time =  2807.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.12 ms /    35 runs   (    0.69 ms per token,  1451.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2023.88 ms /   534 tokens (    3.79 ms per token,   263.85 tokens per second)\n",
      "llama_print_timings:        eval time =  1017.38 ms /    34 runs   (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_print_timings:       total time =  3105.78 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.07 ms /    42 runs   (    0.69 ms per token,  1444.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2365.16 ms /   623 tokens (    3.80 ms per token,   263.41 tokens per second)\n",
      "llama_print_timings:        eval time =  1240.44 ms /    41 runs   (   30.25 ms per token,    33.05 tokens per second)\n",
      "llama_print_timings:       total time =  3684.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.56 ms /    34 runs   (    0.69 ms per token,  1443.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2030.12 ms /   583 tokens (    3.48 ms per token,   287.17 tokens per second)\n",
      "llama_print_timings:        eval time =  1029.62 ms /    33 runs   (   31.20 ms per token,    32.05 tokens per second)\n",
      "llama_print_timings:       total time =  3125.72 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.43 ms /    42 runs   (    0.70 ms per token,  1427.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2014.57 ms /   599 tokens (    3.36 ms per token,   297.33 tokens per second)\n",
      "llama_print_timings:        eval time =  1237.00 ms /    41 runs   (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3327.03 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.73 ms /    45 runs   (    0.68 ms per token,  1464.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1744.15 ms /   491 tokens (    3.55 ms per token,   281.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1306.87 ms /    44 runs   (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_print_timings:       total time =  3129.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.88 ms /    34 runs   (    0.70 ms per token,  1423.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1484.00 ms /   437 tokens (    3.40 ms per token,   294.47 tokens per second)\n",
      "llama_print_timings:        eval time =   985.41 ms /    33 runs   (   29.86 ms per token,    33.49 tokens per second)\n",
      "llama_print_timings:       total time =  2533.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.59 ms /    36 runs   (    0.68 ms per token,  1464.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1305.35 ms /   369 tokens (    3.54 ms per token,   282.68 tokens per second)\n",
      "llama_print_timings:        eval time =  1022.93 ms /    35 runs   (   29.23 ms per token,    34.22 tokens per second)\n",
      "llama_print_timings:       total time =  2390.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.78 ms /    33 runs   (    0.69 ms per token,  1448.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1538.69 ms /   432 tokens (    3.56 ms per token,   280.76 tokens per second)\n",
      "llama_print_timings:        eval time =   943.96 ms /    32 runs   (   29.50 ms per token,    33.90 tokens per second)\n",
      "llama_print_timings:       total time =  2540.80 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.88 ms /    39 runs   (    0.69 ms per token,  1450.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1775.11 ms /   543 tokens (    3.27 ms per token,   305.90 tokens per second)\n",
      "llama_print_timings:        eval time =  1131.92 ms /    38 runs   (   29.79 ms per token,    33.57 tokens per second)\n",
      "llama_print_timings:       total time =  2979.24 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.88 ms /    36 runs   (    0.69 ms per token,  1447.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1397.85 ms /   404 tokens (    3.46 ms per token,   289.01 tokens per second)\n",
      "llama_print_timings:        eval time =  1029.73 ms /    35 runs   (   29.42 ms per token,    33.99 tokens per second)\n",
      "llama_print_timings:       total time =  2490.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.45 ms /    48 runs   (    0.70 ms per token,  1434.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1288.00 ms /   376 tokens (    3.43 ms per token,   291.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1369.69 ms /    47 runs   (   29.14 ms per token,    34.31 tokens per second)\n",
      "llama_print_timings:       total time =  2746.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.81 ms /    33 runs   (    0.69 ms per token,  1446.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1692.52 ms /   468 tokens (    3.62 ms per token,   276.51 tokens per second)\n",
      "llama_print_timings:        eval time =   951.89 ms /    32 runs   (   29.75 ms per token,    33.62 tokens per second)\n",
      "llama_print_timings:       total time =  2704.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.35 ms /    42 runs   (    0.70 ms per token,  1431.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1683.76 ms /   474 tokens (    3.55 ms per token,   281.51 tokens per second)\n",
      "llama_print_timings:        eval time =  1218.02 ms /    41 runs   (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_print_timings:       total time =  2983.42 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.89 ms /    36 runs   (    0.69 ms per token,  1446.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1322.87 ms /   371 tokens (    3.57 ms per token,   280.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1018.76 ms /    35 runs   (   29.11 ms per token,    34.36 tokens per second)\n",
      "llama_print_timings:       total time =  2412.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.83 ms /    32 runs   (    0.71 ms per token,  1401.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1559.95 ms /   409 tokens (    3.81 ms per token,   262.19 tokens per second)\n",
      "llama_print_timings:        eval time =   920.47 ms /    31 runs   (   29.69 ms per token,    33.68 tokens per second)\n",
      "llama_print_timings:       total time =  2545.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.50 ms /    34 runs   (    0.69 ms per token,  1446.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2254.80 ms /   520 tokens (    4.34 ms per token,   230.62 tokens per second)\n",
      "llama_print_timings:        eval time =   988.04 ms /    33 runs   (   29.94 ms per token,    33.40 tokens per second)\n",
      "llama_print_timings:       total time =  3309.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.39 ms /    31 runs   (    0.72 ms per token,  1384.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2342.70 ms /   609 tokens (    3.85 ms per token,   259.96 tokens per second)\n",
      "llama_print_timings:        eval time =   913.47 ms /    30 runs   (   30.45 ms per token,    32.84 tokens per second)\n",
      "llama_print_timings:       total time =  3320.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.71 ms /    43 runs   (    0.71 ms per token,  1400.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2534.85 ms /   592 tokens (    4.28 ms per token,   233.54 tokens per second)\n",
      "llama_print_timings:        eval time =  1377.24 ms /    42 runs   (   32.79 ms per token,    30.50 tokens per second)\n",
      "llama_print_timings:       total time =  4000.04 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.07 ms /    45 runs   (    0.69 ms per token,  1448.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2510.22 ms /   612 tokens (    4.10 ms per token,   243.80 tokens per second)\n",
      "llama_print_timings:        eval time =  1342.73 ms /    44 runs   (   30.52 ms per token,    32.77 tokens per second)\n",
      "llama_print_timings:       total time =  3933.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.71 ms /    48 runs   (    0.68 ms per token,  1467.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2053.53 ms /   547 tokens (    3.75 ms per token,   266.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1409.52 ms /    47 runs   (   29.99 ms per token,    33.34 tokens per second)\n",
      "llama_print_timings:       total time =  3549.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.22 ms /    31 runs   (    0.68 ms per token,  1461.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2595.36 ms /   682 tokens (    3.81 ms per token,   262.78 tokens per second)\n",
      "llama_print_timings:        eval time =   921.84 ms /    30 runs   (   30.73 ms per token,    32.54 tokens per second)\n",
      "llama_print_timings:       total time =  3573.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.72 ms /    30 runs   (    0.69 ms per token,  1447.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2539.48 ms /   685 tokens (    3.71 ms per token,   269.74 tokens per second)\n",
      "llama_print_timings:        eval time =   893.82 ms /    29 runs   (   30.82 ms per token,    32.45 tokens per second)\n",
      "llama_print_timings:       total time =  3489.35 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.63 ms /    57 runs   (    0.70 ms per token,  1438.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2137.69 ms /   562 tokens (    3.80 ms per token,   262.90 tokens per second)\n",
      "llama_print_timings:        eval time =  1694.24 ms /    56 runs   (   30.25 ms per token,    33.05 tokens per second)\n",
      "llama_print_timings:       total time =  3934.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.31 ms /   256 runs   (    0.70 ms per token,  1435.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1727.84 ms /   485 tokens (    3.56 ms per token,   280.70 tokens per second)\n",
      "llama_print_timings:        eval time =  7708.10 ms /   255 runs   (   30.23 ms per token,    33.08 tokens per second)\n",
      "llama_print_timings:       total time =  9907.55 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.94 ms /    46 runs   (    0.69 ms per token,  1440.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =   215.21 ms /    44 tokens (    4.89 ms per token,   204.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1251.00 ms /    45 runs   (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_print_timings:       total time =  1545.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   148.85 ms /   213 runs   (    0.70 ms per token,  1430.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =   608.22 ms /   182 tokens (    3.34 ms per token,   299.23 tokens per second)\n",
      "llama_print_timings:        eval time =  6099.76 ms /   212 runs   (   28.77 ms per token,    34.76 tokens per second)\n",
      "llama_print_timings:       total time =  7098.54 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   118.78 ms /   172 runs   (    0.69 ms per token,  1448.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1763.90 ms /   542 tokens (    3.25 ms per token,   307.27 tokens per second)\n",
      "llama_print_timings:        eval time =  5187.99 ms /   171 runs   (   30.34 ms per token,    32.96 tokens per second)\n",
      "llama_print_timings:       total time =  7260.52 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.45 ms /    41 runs   (    0.69 ms per token,  1440.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1900.02 ms /   530 tokens (    3.58 ms per token,   278.94 tokens per second)\n",
      "llama_print_timings:        eval time =  1202.38 ms /    40 runs   (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_print_timings:       total time =  3174.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   179.08 ms /   256 runs   (    0.70 ms per token,  1429.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1573.25 ms /   460 tokens (    3.42 ms per token,   292.39 tokens per second)\n",
      "llama_print_timings:        eval time =  7703.59 ms /   255 runs   (   30.21 ms per token,    33.10 tokens per second)\n",
      "llama_print_timings:       total time =  9748.46 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.09 ms /    39 runs   (    0.69 ms per token,  1439.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1345.82 ms /   416 tokens (    3.24 ms per token,   309.10 tokens per second)\n",
      "llama_print_timings:        eval time =  1116.76 ms /    38 runs   (   29.39 ms per token,    34.03 tokens per second)\n",
      "llama_print_timings:       total time =  2532.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    60.88 ms /    85 runs   (    0.72 ms per token,  1396.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1485.87 ms /   439 tokens (    3.38 ms per token,   295.45 tokens per second)\n",
      "llama_print_timings:        eval time =  2492.25 ms /    84 runs   (   29.67 ms per token,    33.70 tokens per second)\n",
      "llama_print_timings:       total time =  4135.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    47.78 ms /    69 runs   (    0.69 ms per token,  1444.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1335.18 ms /   417 tokens (    3.20 ms per token,   312.32 tokens per second)\n",
      "llama_print_timings:        eval time =  2004.11 ms /    68 runs   (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_print_timings:       total time =  3461.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.77 ms /    40 runs   (    0.69 ms per token,  1440.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1011.68 ms /   295 tokens (    3.43 ms per token,   291.60 tokens per second)\n",
      "llama_print_timings:        eval time =  1129.58 ms /    39 runs   (   28.96 ms per token,    34.53 tokens per second)\n",
      "llama_print_timings:       total time =  2210.74 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.31 ms /    45 runs   (    0.72 ms per token,  1392.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1018.88 ms /   292 tokens (    3.49 ms per token,   286.59 tokens per second)\n",
      "llama_print_timings:        eval time =  1268.77 ms /    44 runs   (   28.84 ms per token,    34.68 tokens per second)\n",
      "llama_print_timings:       total time =  2370.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    27.73 ms /    40 runs   (    0.69 ms per token,  1442.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1623.95 ms /   461 tokens (    3.52 ms per token,   283.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1157.62 ms /    39 runs   (   29.68 ms per token,    33.69 tokens per second)\n",
      "llama_print_timings:       total time =  2852.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.31 ms /    45 runs   (    0.70 ms per token,  1437.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1621.83 ms /   476 tokens (    3.41 ms per token,   293.50 tokens per second)\n",
      "llama_print_timings:        eval time =  1313.02 ms /    44 runs   (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_print_timings:       total time =  3017.31 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.51 ms /    38 runs   (    0.78 ms per token,  1287.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1023.14 ms /   298 tokens (    3.43 ms per token,   291.26 tokens per second)\n",
      "llama_print_timings:        eval time =  1064.23 ms /    37 runs   (   28.76 ms per token,    34.77 tokens per second)\n",
      "llama_print_timings:       total time =  2163.92 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    26.73 ms /    38 runs   (    0.70 ms per token,  1421.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =   815.45 ms /   245 tokens (    3.33 ms per token,   300.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1099.95 ms /    37 runs   (   29.73 ms per token,    33.64 tokens per second)\n",
      "llama_print_timings:       total time =  1987.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.43 ms /   256 runs   (    0.70 ms per token,  1434.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1939.44 ms /   570 tokens (    3.40 ms per token,   293.90 tokens per second)\n",
      "llama_print_timings:        eval time =  7696.43 ms /   255 runs   (   30.18 ms per token,    33.13 tokens per second)\n",
      "llama_print_timings:       total time = 10138.88 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   178.36 ms /   256 runs   (    0.70 ms per token,  1435.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2041.81 ms /   541 tokens (    3.77 ms per token,   264.96 tokens per second)\n",
      "llama_print_timings:        eval time =  7742.88 ms /   255 runs   (   30.36 ms per token,    32.93 tokens per second)\n",
      "llama_print_timings:       total time = 10272.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    25.39 ms /    37 runs   (    0.69 ms per token,  1457.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1948.49 ms /   538 tokens (    3.62 ms per token,   276.11 tokens per second)\n",
      "llama_print_timings:        eval time =  1074.43 ms /    36 runs   (   29.85 ms per token,    33.51 tokens per second)\n",
      "llama_print_timings:       total time =  3089.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.43 ms /    31 runs   (    0.69 ms per token,  1446.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1575.14 ms /   451 tokens (    3.49 ms per token,   286.32 tokens per second)\n",
      "llama_print_timings:        eval time =   878.50 ms /    30 runs   (   29.28 ms per token,    34.15 tokens per second)\n",
      "llama_print_timings:       total time =  2510.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.38 ms /    30 runs   (    0.68 ms per token,  1471.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2030.48 ms /   561 tokens (    3.62 ms per token,   276.29 tokens per second)\n",
      "llama_print_timings:        eval time =   865.64 ms /    29 runs   (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_print_timings:       total time =  2952.01 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.79 ms /   256 runs   (    0.69 ms per token,  1439.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2031.26 ms /   573 tokens (    3.54 ms per token,   282.09 tokens per second)\n",
      "llama_print_timings:        eval time =  7819.07 ms /   255 runs   (   30.66 ms per token,    32.61 tokens per second)\n",
      "llama_print_timings:       total time = 10345.15 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.87 ms /    36 runs   (    0.69 ms per token,  1447.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2120.78 ms /   546 tokens (    3.88 ms per token,   257.45 tokens per second)\n",
      "llama_print_timings:        eval time =  1056.17 ms /    35 runs   (   30.18 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3244.16 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.98 ms /    49 runs   (    0.69 ms per token,  1442.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =   712.11 ms /   195 tokens (    3.65 ms per token,   273.83 tokens per second)\n",
      "llama_print_timings:        eval time =  1368.57 ms /    48 runs   (   28.51 ms per token,    35.07 tokens per second)\n",
      "llama_print_timings:       total time =  2173.60 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    45.89 ms /    66 runs   (    0.70 ms per token,  1438.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =   627.13 ms /   171 tokens (    3.67 ms per token,   272.67 tokens per second)\n",
      "llama_print_timings:        eval time =  1853.39 ms /    65 runs   (   28.51 ms per token,    35.07 tokens per second)\n",
      "llama_print_timings:       total time =  2606.34 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.88 ms /    34 runs   (    0.70 ms per token,  1423.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1888.99 ms /   509 tokens (    3.71 ms per token,   269.46 tokens per second)\n",
      "llama_print_timings:        eval time =   984.75 ms /    33 runs   (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_print_timings:       total time =  2939.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.83 ms /    36 runs   (    0.69 ms per token,  1449.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2074.61 ms /   535 tokens (    3.88 ms per token,   257.88 tokens per second)\n",
      "llama_print_timings:        eval time =  1056.14 ms /    35 runs   (   30.18 ms per token,    33.14 tokens per second)\n",
      "llama_print_timings:       total time =  3198.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    46.45 ms /    67 runs   (    0.69 ms per token,  1442.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1879.38 ms /   514 tokens (    3.66 ms per token,   273.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1981.04 ms /    66 runs   (   30.02 ms per token,    33.32 tokens per second)\n",
      "llama_print_timings:       total time =  3986.64 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    56.04 ms /    82 runs   (    0.68 ms per token,  1463.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1814.30 ms /   491 tokens (    3.70 ms per token,   270.63 tokens per second)\n",
      "llama_print_timings:        eval time =  2438.69 ms /    81 runs   (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =  4403.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.99 ms /    42 runs   (    0.69 ms per token,  1448.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1564.56 ms /   433 tokens (    3.61 ms per token,   276.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1213.10 ms /    41 runs   (   29.59 ms per token,    33.80 tokens per second)\n",
      "llama_print_timings:       total time =  2853.19 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    21.51 ms /    31 runs   (    0.69 ms per token,  1441.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1310.80 ms /   381 tokens (    3.44 ms per token,   290.66 tokens per second)\n",
      "llama_print_timings:        eval time =   945.67 ms /    30 runs   (   31.52 ms per token,    31.72 tokens per second)\n",
      "llama_print_timings:       total time =  2311.94 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.29 ms /    42 runs   (    0.70 ms per token,  1434.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1587.90 ms /   433 tokens (    3.67 ms per token,   272.69 tokens per second)\n",
      "llama_print_timings:        eval time =  1221.16 ms /    41 runs   (   29.78 ms per token,    33.57 tokens per second)\n",
      "llama_print_timings:       total time =  2883.99 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   176.62 ms /   256 runs   (    0.69 ms per token,  1449.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1786.43 ms /   510 tokens (    3.50 ms per token,   285.49 tokens per second)\n",
      "llama_print_timings:        eval time =  7761.58 ms /   255 runs   (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_print_timings:       total time = 10004.49 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.90 ms /    55 runs   (    0.69 ms per token,  1451.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =   996.67 ms /   292 tokens (    3.41 ms per token,   292.98 tokens per second)\n",
      "llama_print_timings:        eval time =  1561.69 ms /    54 runs   (   28.92 ms per token,    34.58 tokens per second)\n",
      "llama_print_timings:       total time =  2653.85 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   107.52 ms /   157 runs   (    0.68 ms per token,  1460.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =   396.52 ms /   113 tokens (    3.51 ms per token,   284.98 tokens per second)\n",
      "llama_print_timings:        eval time =  4418.01 ms /   156 runs   (   28.32 ms per token,    35.31 tokens per second)\n",
      "llama_print_timings:       total time =  5089.87 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    20.04 ms /    29 runs   (    0.69 ms per token,  1447.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2010.39 ms /   553 tokens (    3.64 ms per token,   275.07 tokens per second)\n",
      "llama_print_timings:        eval time =   843.79 ms /    28 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  2905.33 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   177.31 ms /   256 runs   (    0.69 ms per token,  1443.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   707.23 ms /   221 tokens (    3.20 ms per token,   312.49 tokens per second)\n",
      "llama_print_timings:        eval time =  7469.42 ms /   255 runs   (   29.29 ms per token,    34.14 tokens per second)\n",
      "llama_print_timings:       total time =  8650.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.59 ms /    50 runs   (    0.69 ms per token,  1445.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1047.38 ms /   307 tokens (    3.41 ms per token,   293.11 tokens per second)\n",
      "llama_print_timings:        eval time =  1405.95 ms /    49 runs   (   28.69 ms per token,    34.85 tokens per second)\n",
      "llama_print_timings:       total time =  2546.75 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    28.78 ms /    42 runs   (    0.69 ms per token,  1459.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =   217.96 ms /    56 tokens (    3.89 ms per token,   256.93 tokens per second)\n",
      "llama_print_timings:        eval time =  1139.95 ms /    41 runs   (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_print_timings:       total time =  1429.20 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    39.20 ms /    58 runs   (    0.68 ms per token,  1479.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =   506.14 ms /   157 tokens (    3.22 ms per token,   310.19 tokens per second)\n",
      "llama_print_timings:        eval time =  1617.56 ms /    57 runs   (   28.38 ms per token,    35.24 tokens per second)\n",
      "llama_print_timings:       total time =  2224.48 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.90 ms /    48 runs   (    0.69 ms per token,  1459.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1543.81 ms /   431 tokens (    3.58 ms per token,   279.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1389.01 ms /    47 runs   (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_print_timings:       total time =  3015.70 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    73.40 ms /   107 runs   (    0.69 ms per token,  1457.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1982.28 ms /   531 tokens (    3.73 ms per token,   267.87 tokens per second)\n",
      "llama_print_timings:        eval time =  3195.93 ms /   106 runs   (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_print_timings:       total time =  5365.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   174.50 ms /   252 runs   (    0.69 ms per token,  1444.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1921.79 ms /   528 tokens (    3.64 ms per token,   274.74 tokens per second)\n",
      "llama_print_timings:        eval time =  7627.57 ms /   251 runs   (   30.39 ms per token,    32.91 tokens per second)\n",
      "llama_print_timings:       total time = 10012.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.60 ms /   256 runs   (    0.69 ms per token,  1457.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1908.98 ms /   527 tokens (    3.62 ms per token,   276.06 tokens per second)\n",
      "llama_print_timings:        eval time =  7748.33 ms /   255 runs   (   30.39 ms per token,    32.91 tokens per second)\n",
      "llama_print_timings:       total time = 10122.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    48.20 ms /    71 runs   (    0.68 ms per token,  1473.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1484.98 ms /   436 tokens (    3.41 ms per token,   293.61 tokens per second)\n",
      "llama_print_timings:        eval time =  2071.66 ms /    70 runs   (   29.60 ms per token,    33.79 tokens per second)\n",
      "llama_print_timings:       total time =  3679.89 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    34.95 ms /    51 runs   (    0.69 ms per token,  1459.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2020.24 ms /   566 tokens (    3.57 ms per token,   280.16 tokens per second)\n",
      "llama_print_timings:        eval time =  1513.30 ms /    50 runs   (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_print_timings:       total time =  3623.62 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    24.22 ms /    35 runs   (    0.69 ms per token,  1444.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1997.75 ms /   547 tokens (    3.65 ms per token,   273.81 tokens per second)\n",
      "llama_print_timings:        eval time =  1020.57 ms /    34 runs   (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_print_timings:       total time =  3079.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.65 ms /   256 runs   (    0.69 ms per token,  1457.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1923.51 ms /   536 tokens (    3.59 ms per token,   278.66 tokens per second)\n",
      "llama_print_timings:        eval time =  7777.45 ms /   255 runs   (   30.50 ms per token,    32.79 tokens per second)\n",
      "llama_print_timings:       total time = 10162.69 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.33 ms /    43 runs   (    0.68 ms per token,  1465.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1725.88 ms /   491 tokens (    3.52 ms per token,   284.49 tokens per second)\n",
      "llama_print_timings:        eval time =  1255.61 ms /    42 runs   (   29.90 ms per token,    33.45 tokens per second)\n",
      "llama_print_timings:       total time =  3054.95 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.19 ms /    53 runs   (    0.68 ms per token,  1464.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1934.41 ms /   518 tokens (    3.73 ms per token,   267.78 tokens per second)\n",
      "llama_print_timings:        eval time =  1558.18 ms /    52 runs   (   29.96 ms per token,    33.37 tokens per second)\n",
      "llama_print_timings:       total time =  3585.91 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    53.02 ms /    78 runs   (    0.68 ms per token,  1471.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2014.88 ms /   552 tokens (    3.65 ms per token,   273.96 tokens per second)\n",
      "llama_print_timings:        eval time =  2320.62 ms /    77 runs   (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_print_timings:       total time =  4471.30 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    40.28 ms /    59 runs   (    0.68 ms per token,  1464.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1737.46 ms /   486 tokens (    3.58 ms per token,   279.72 tokens per second)\n",
      "llama_print_timings:        eval time =  1733.11 ms /    58 runs   (   29.88 ms per token,    33.47 tokens per second)\n",
      "llama_print_timings:       total time =  3574.10 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    32.11 ms /    47 runs   (    0.68 ms per token,  1463.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1374.22 ms /   415 tokens (    3.31 ms per token,   301.99 tokens per second)\n",
      "llama_print_timings:        eval time =  1357.48 ms /    46 runs   (   29.51 ms per token,    33.89 tokens per second)\n",
      "llama_print_timings:       total time =  2813.56 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   174.86 ms /   256 runs   (    0.68 ms per token,  1464.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1665.73 ms /   480 tokens (    3.47 ms per token,   288.16 tokens per second)\n",
      "llama_print_timings:        eval time =  7713.51 ms /   255 runs   (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_print_timings:       total time =  9839.39 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    33.08 ms /    48 runs   (    0.69 ms per token,  1451.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1748.78 ms /   490 tokens (    3.57 ms per token,   280.20 tokens per second)\n",
      "llama_print_timings:        eval time =  1405.37 ms /    47 runs   (   29.90 ms per token,    33.44 tokens per second)\n",
      "llama_print_timings:       total time =  3236.79 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    23.96 ms /    35 runs   (    0.68 ms per token,  1460.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =   502.40 ms /   154 tokens (    3.26 ms per token,   306.53 tokens per second)\n",
      "llama_print_timings:        eval time =   958.55 ms /    34 runs   (   28.19 ms per token,    35.47 tokens per second)\n",
      "llama_print_timings:       total time =  1520.86 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.40 ms /   256 runs   (    0.69 ms per token,  1459.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1390.13 ms /   408 tokens (    3.41 ms per token,   293.50 tokens per second)\n",
      "llama_print_timings:        eval time =  7629.23 ms /   255 runs   (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_print_timings:       total time =  9480.84 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.65 ms /    33 runs   (    0.69 ms per token,  1457.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =   617.43 ms /   180 tokens (    3.43 ms per token,   291.53 tokens per second)\n",
      "llama_print_timings:        eval time =   909.59 ms /    32 runs   (   28.42 ms per token,    35.18 tokens per second)\n",
      "llama_print_timings:       total time =  1584.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    36.06 ms /    53 runs   (    0.68 ms per token,  1469.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1033.07 ms /   293 tokens (    3.53 ms per token,   283.62 tokens per second)\n",
      "llama_print_timings:        eval time =  1510.56 ms /    52 runs   (   29.05 ms per token,    34.42 tokens per second)\n",
      "llama_print_timings:       total time =  2634.27 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.61 ms /   256 runs   (    0.69 ms per token,  1457.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1979.89 ms /   521 tokens (    3.80 ms per token,   263.15 tokens per second)\n",
      "llama_print_timings:        eval time =  7775.69 ms /   255 runs   (   30.49 ms per token,    32.79 tokens per second)\n",
      "llama_print_timings:       total time = 10215.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =   175.81 ms /   256 runs   (    0.69 ms per token,  1456.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1953.57 ms /   527 tokens (    3.71 ms per token,   269.76 tokens per second)\n",
      "llama_print_timings:        eval time =  7767.15 ms /   255 runs   (   30.46 ms per token,    32.83 tokens per second)\n",
      "llama_print_timings:       total time = 10184.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    60.72 ms /    87 runs   (    0.70 ms per token,  1432.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2033.96 ms /   555 tokens (    3.66 ms per token,   272.87 tokens per second)\n",
      "llama_print_timings:        eval time =  2596.92 ms /    86 runs   (   30.20 ms per token,    33.12 tokens per second)\n",
      "llama_print_timings:       total time =  4787.68 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.64 ms /    33 runs   (    0.69 ms per token,  1457.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1954.26 ms /   534 tokens (    3.66 ms per token,   273.25 tokens per second)\n",
      "llama_print_timings:        eval time =   960.16 ms /    32 runs   (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_print_timings:       total time =  2972.82 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    29.26 ms /    43 runs   (    0.68 ms per token,  1469.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =   493.96 ms /   149 tokens (    3.32 ms per token,   301.64 tokens per second)\n",
      "llama_print_timings:        eval time =  1185.86 ms /    42 runs   (   28.23 ms per token,    35.42 tokens per second)\n",
      "llama_print_timings:       total time =  1754.43 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.68 ms /    46 runs   (    0.69 ms per token,  1451.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =  2073.89 ms /   565 tokens (    3.67 ms per token,   272.44 tokens per second)\n",
      "llama_print_timings:        eval time =  1360.60 ms /    45 runs   (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_print_timings:       total time =  3516.67 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    37.04 ms /    54 runs   (    0.69 ms per token,  1458.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1140.18 ms /   332 tokens (    3.43 ms per token,   291.18 tokens per second)\n",
      "llama_print_timings:        eval time =  1545.16 ms /    53 runs   (   29.15 ms per token,    34.30 tokens per second)\n",
      "llama_print_timings:       total time =  2778.26 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    30.48 ms /    44 runs   (    0.69 ms per token,  1443.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =   218.39 ms /    49 tokens (    4.46 ms per token,   224.37 tokens per second)\n",
      "llama_print_timings:        eval time =  1189.94 ms /    43 runs   (   27.67 ms per token,    36.14 tokens per second)\n",
      "llama_print_timings:       total time =  1486.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    22.54 ms /    33 runs   (    0.68 ms per token,  1464.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1808.71 ms /   506 tokens (    3.57 ms per token,   279.76 tokens per second)\n",
      "llama_print_timings:        eval time =   963.47 ms /    32 runs   (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_print_timings:       total time =  2829.05 ms\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  1914.18 ms\n",
      "llama_print_timings:      sample time =    31.43 ms /    46 runs   (    0.68 ms per token,  1463.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =  1546.76 ms /   442 tokens (    3.50 ms per token,   285.76 tokens per second)\n",
      "llama_print_timings:        eval time =  1337.50 ms /    45 runs   (   29.72 ms per token,    33.64 tokens per second)\n",
      "llama_print_timings:       total time =  2964.33 ms\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(\n",
    "    documents=documents,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d70f6d",
   "metadata": {},
   "source": [
    "# Create Vector index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e4778e",
   "metadata": {},
   "source": [
    "### Create the vectors for our Nodes and store them in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73ba79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, node in enumerate(nodes):\n",
    "    if \"\\x00\" in node.text:\n",
    "        print(f\"Found in node {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "179fcffe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e696924a5fc24be59a223775241739ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/642 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes,\n",
    "    service_context=service_context,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f169a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "612fb916",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =  9314.94 ms\n",
      "llama_print_timings:      sample time =   140.84 ms /   202 runs   (    0.70 ms per token,  1434.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:        eval time =  9774.27 ms /   202 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_print_timings:       total time = 10138.87 ms\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Where can I find a command on how to encode video with ffmpeg?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ae098e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sure! Based on the given context, here's the answer to your query:  To encode video with ffmpeg,\n",
      "you can use the following command: ```css ffmpeg -i input.mp4 -c:v libx264 -crf 18 output.mp4 ```\n",
      "This command will encode the input video file (input.mp4) using the H.264 codec with a constant rate\n",
      "factor (CRF) of 18, and output the encoded video to a new file (output.mp4).  You can also specify\n",
      "other options to customize the encoding process, such as the input and output color spaces,\n",
      "framerate, and other settings. For more information, you can refer to the ffmpeg documentation or\n",
      "the x264 settings documentation.  I hope this helps! Let me know if you have any further questions\n",
      "or if there's anything else I can help with.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9e302",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
